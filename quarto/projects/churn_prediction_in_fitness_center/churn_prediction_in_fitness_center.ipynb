{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "description_for_list: \"Сеть фитнес-центров анализирует данные для снижения оттока клиентов. Необходимо прогнозировать отток, сегментировать клиентов, выявить ключевые факторы, влияющие на отток.\"\n",
    "\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "    fontsize: 16px\n",
    "    smooth-scroll: true\n",
    "    toc: true\n",
    "    toc-location: left\n",
    "    toc-title: Оглавление\n",
    "    grid:\n",
    "      body-width: 1100px\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование оттока клиентов сети фитнес-центров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Автор:**  \n",
    "\n",
    "Григорьев Павел\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание проекта:**   \n",
    "\n",
    "Сеть фитнес-центров разрабатывает стратегию взаимодействия с клиентами на основе аналитических данных. Распространённая проблема фитнес-клубов и других сервисов - отток клиентов. Чтобы бороться с оттоком, отдел по работе с клиентами перевёл в электронный вид множество клиентских анкет. Необходимо провести анализ и подготовить план действий по удержанию клиентов.   \n",
    "А именно:\n",
    "- научиться прогнозировать вероятность оттока (на уровне следующего месяца) для каждого клиента;\n",
    "- сформировать типичные портреты клиентов: выделить несколько наиболее ярких групп и охарактеризовать их основные свойства;\n",
    "- проанализировать основные признаки, наиболее сильно влияющие на отток;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель:**  \n",
    "\n",
    "Разработать стратегию удержания клиентов сети фитнес-центров на основе анализа данных, включая прогнозирование вероятности оттока, сегментацию клиентов и выявление ключевых факторов, влияющих на отток."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Источники данных:**  \n",
    "\n",
    "Данные предоставленны фитнес-центром. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условия проведения анализа данных:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Главные выводы:**  \n",
    "тут помещаем самое главное из общего вывода, примерно до полустраницы, чтобы не было сильно много и при этом указать все главные выводы\n",
    "Будет идеально, елси выводы на похожие темы будут рядом, то есть елси мы имеем несколько выводов о доходе, то лушче поместить их рядом\n",
    "\n",
    "- Женщины чаще возвращают кредит, чем мужчины.\n",
    "- Долги присутствуют у людей с разным доходом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекомендации:**\n",
    "\n",
    "- Добавить контроль данных, чтобы не дублировались значения с разными регистрами в колонке с образованием.\n",
    "- Добавить уникальный идентификатор клиента, чтобы избежать дублирования строк.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка библиотек <skip>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pagri_data_tools  # type: ignore\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание и изучение данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - children - количество детей в семье\n",
    "> - days_employed - общий трудовой стаж в днях\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> сначала грузим 5-10 строк (указываем в `pd.read_csv` `nrow`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Изучаем данные и определяемся с типами, потом их указваем в `pd.read`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно привести названия столбцов к нижнему регистру, убрать пробелы (заменить их на \\_),  \n",
    "> так как в том же merge могту быть проблемы, если это не сделать и вообще будет удобнее работать\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если после попытки привести тип к нужному, мы получили ошибку,  \n",
    "> то обязательно изучаем эти строки. Именно строки, не только сами занчения, которые не можем преобразовать.  \n",
    "> Часто бывает у нас в ругих столбцах есть категория например, которая портит все,  \n",
    "> и при этом это выброс может быть. Поэтому обязательно првоеряем строки, в которых строки не преобразуются в нужный тип.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Очень важно писать код, чтобы не учитывался порядок столбцов. Чтобы если порядок изменится, то наш скрипт будет работать верно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Также важно категориальные столбцы привести к типу `category` и для столбцов, которые имеют малый диапазон значений заменить на меньший тип,  \n",
    "> например на `int8`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Делаем названия колонок краткими, но понятными.  \n",
    "> Если у нас непонятное название типа, dob_years, то меняем его на более понятное, например, age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение переменных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если таблиц больше 1, то делаем разделы по названию таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Таблица users (информация о пользователях)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные и задаем типы данных для столбцов, где это возможно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>education_id</th>\n",
       "      <th>family_status</th>\n",
       "      <th>family_status_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>1</td>\n",
       "      <td>-2885.142188</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>80236.028323</td>\n",
       "      <td>приобретение автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>2</td>\n",
       "      <td>-1803.080913</td>\n",
       "      <td>36</td>\n",
       "      <td>Среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>163292.220004</td>\n",
       "      <td>строительство собственной недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>1</td>\n",
       "      <td>-305.540665</td>\n",
       "      <td>27</td>\n",
       "      <td>СРЕДНЕЕ</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>69799.488812</td>\n",
       "      <td>ремонт жилью</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>1</td>\n",
       "      <td>-1593.946336</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>1</td>\n",
       "      <td>107486.332934</td>\n",
       "      <td>на покупку подержанного автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>0</td>\n",
       "      <td>-1025.402943</td>\n",
       "      <td>64</td>\n",
       "      <td>высшее</td>\n",
       "      <td>0</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>госслужащий</td>\n",
       "      <td>0</td>\n",
       "      <td>706401.475790</td>\n",
       "      <td>профильное образование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  days_employed  dob_years education  education_id  \\\n",
       "4042          1   -2885.142188         50   среднее             1   \n",
       "19177         2   -1803.080913         36   Среднее             1   \n",
       "7372          1    -305.540665         27   СРЕДНЕЕ             1   \n",
       "16245         1   -1593.946336         50   среднее             1   \n",
       "11563         0   -1025.402943         64    высшее             0   \n",
       "\n",
       "          family_status  family_status_id gender  income_type  debt  \\\n",
       "4042    женат / замужем                 0      F    сотрудник     0   \n",
       "19177   женат / замужем                 0      F    сотрудник     0   \n",
       "7372   гражданский брак                 1      F    сотрудник     0   \n",
       "16245   женат / замужем                 0      F    сотрудник     1   \n",
       "11563   женат / замужем                 0      M  госслужащий     0   \n",
       "\n",
       "        total_income                                 purpose  \n",
       "4042    80236.028323                 приобретение автомобиля  \n",
       "19177  163292.220004  строительство собственной недвижимости  \n",
       "7372    69799.488812                            ремонт жилью  \n",
       "16245  107486.332934      на покупку подержанного автомобиля  \n",
       "11563  706401.475790                  профильное образование  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {'is_apartment': 'category', 'studio': 'category', 'open_plan': 'category'}\n",
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/gym_churn.csv') #, dtype=dtype, nrows = 5\n",
    "                # , parse_dates=['first_day_exposition'], date_format='%Y-%m-%dT%H:%M:%S')\n",
    "# df.rename(columns={'cityCenters_nearest': 'city_centers_nearest'}, inplace=True)\n",
    "df.sample(5, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим типы переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть столбец, в котором могут быть неявные дубликаты. Нарпимер, разные названия и прочее.  \n",
    "После изучения столбца сразу убираем эти дубликаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы исключить неявных дубликатов, переведем наименования в нижний регистр и удалить символы ',', '«', '»', '(', ')', '\"', ' '."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно проверить, что после нормализации категориальный тип остался прежний\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "среднее                15233\n",
       "высшее                  5260\n",
       "неоконченное высшее      744\n",
       "начальное                282\n",
       "ученая степень             6\n",
       "Name: education, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.education = pagri_data_tools.normalize_string_series(df.education)\n",
    "df.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.education.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас в столбце, который должен быть числоым стоят не числа и мы хотим из заменить на na и сделать столбец числовым, то делаем так"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tbd означает \"to be determined\" - \"будет определено позже\"  \n",
    "Так как нам нужен этот столбец в числовом виде, то заменим tbd на na."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6701)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.user_score.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2424)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.user_score == 'tbd').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_score'] = df['user_score'].replace('tbd', pd.NA)\n",
    "df['user_score'] = pd.to_numeric(df['user_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(9125)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.user_score.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.user_score == 'tbd').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сразу меняем название колонок, которые имеют непонятные названия.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'dob_years': 'age'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем верменный файл, в который заносим потенциальные выбросы, чтобы их потом отдельно изучить в разаделе изучения выбросов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот же файл сразу записываем важные наблюдения, из которых потом выберем наблюдения для промежуточных выводов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в начало файла поместить описание переменных, чтобы не прыгать в начало отчета, так как вряд ли все названия и описание запомняться.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наблюдения обязательно записываем то, что будет копироваться в выводы, например наличие пропусков.  \n",
    "Так как когда будем проходить и собирать наблюдения для выводов, то сами результаты смотреть не будем, поэтому  \n",
    "важно все важно помещать в наблюдения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И важно сразу писать наблюдения с привязкой к названию столбца.  \n",
    "То есть не писать видно 10 процентов пропусков и прочее, а писать что видно 10 процентов пропусков в столбце возраста и так далее.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "чтобы далее было удобно совздавать выводы, сразу стараемся важные выводы писать правильно, чтобы потом не нужно было проходить и их менять.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Пока изучаем отдельные столбца просто пишем наблюдения.  \n",
    "- Далее перед изучением дубликатов копируем в temp.ipynb и делим на наблюдения. выбросы, пропуски, дубли.  \n",
    "- И далее когда изучаем смотрим на эти записи.  \n",
    "- Во время изучения пишем просто наблюдения.\n",
    "- И далее проходим и собираем все наблюдеия от изучения дублей, пропусков и остального. \n",
    "- Помещаем во временный файл. \n",
    "- Копируем все в промежуточный вывод и также копию оставляем в temp.ipynb.\n",
    "- И далее при предобработке обращаемся к temp.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема такая  \n",
    "- мы пишем наблюдения под таблицей или графиком.  \n",
    "Пишем только то, что имеет смысл, то есть если выбросов нет, то не нужно это писать.  \n",
    "- далее мы важные наблюдения копируем в промежуточный вывод и затем копируем в основной вывод.  \n",
    "- не меняем тест выводов, пока не сделаем ссылки\n",
    "- далее можно менять текст выводов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "Когда мы видим таблицу или график, то мы придумываем вопросы к результату.  \n",
    "Все возможные вопросы прочие вопрсоы)\n",
    "И отвечая на эти вопросы мы получаем наблюдения и выводы\n",
    "И чтобы задавать правильные вопросы, мы должны сначала подумать о физике параметров, которые мы видим.\n",
    "Схема такая  \n",
    "- строим очередную колонку  \n",
    "- сначала понимаем физику этого параметра, думаем что с ним связано, что он описывает, какие могут быть у него значения  \n",
    "- это важно, чтобы посмотреть на данные и сделать правильные выводы  \n",
    "- например, у нас в колонке количество дней продажи. Мы подумали и поняли, что тут важно длительность продажи, как долго шли продажи и так далее  \n",
    "- это очень важно, не только просто смотреть как на столбец, а держать в голове его физику и думать какие вопросы ему задать.  \n",
    "- в анализе самое главное это задавать правильные вопросы данным, а чтобы это сделать, нужно понять природу параметра"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопросы (важно мы не пишем все наблюдения, а только те, которые могут быть важны для анализа, то есть мы смотрим, задаем вопросы данным и   \n",
    "и если ответ важен, то мы записываем наблюдения)\n",
    "- насколько уникальные значения\n",
    "- какие значения чаще всего встречаются, какие редко, какие не встречаются, какие должны встречаться, но их нет (думаем какие значения могут быть у параметра и смотрим есть ли они в данных)\n",
    "- сколько дубликатов, нулей, отрицательных занчений, допустимы ли они в этом столбце\n",
    "- какие максимальные и минимальные значения, реальные ли они, совпадают ли с физикой параметра, каковы причины макс и мин значений\n",
    "- какой размах значений между макс и мин, какой размах внутри квантилей, в каких квантилях больше размах, а в каких меньше\n",
    "- сравниваем моду, медиану и среднее и смотрим на гистограмму, какое распределение у нас, какое должно быть у этого параметра\n",
    "смотрим на пики на гистограмме, почему они появились.\n",
    "- какая мера центральной тенденции лушче подходит для этого параметра (обязательно записываем это во верменный файл, чтобы далее использовать при анализе)\n",
    "- смотрим на std большое ли оно, какое оно должно быть у этого параметра\n",
    "- смотрим на самые частые значения, какие они, какие они должны быть, почему это значение чаще всего встречается, так и должно быть\n",
    "- смотрим на выбросы, насколько они реально могут быть у данного параметра (если сомневаемся в реальности, то записываем во временный файл для изучения далее)\n",
    "- как, почему, зачем, сколько, как долго, быстро ли, медленно ли, важно ли это, из-за чего это и "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод `my_info` или `info_gen` для вывода информации о датасете и колонках\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "если заметил выброс в колонке, то записываем не только в наблюдения.  \n",
    "Задача все выбросы записать и вставить в блок где будем обрабатывать выбросы и в блок изучения выбросов.  \n",
    "Это очень важно, так как потом можно забыть, что в какой-то колонке было некорректное значение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача изучения не только найти аномалии и записать их для выводов.  \n",
    "Важно срауз думать как мы будем обрабатывать найденные аномалии.  \n",
    "И выдвигать и проверять гипотезы, и если нашли что-то важно или пришло в головку,  \n",
    "что поможет обработать, то это записываем во временный файл.  \n",
    "То есть мы уже начинаем этап обработки в процессе изучения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следим за аномалиями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем смотреть на количество мод. Если у нас распределение с 2 и более модами, то это может сигнализировать о проблемах.  \n",
    "Например, мы так можем определить что у нас часть данных в секунадх, а часть в минутах. Это проявляется в двух разных пиках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных переменных записываем сколько элементов в каждой группе этой категориальной переменной.  \n",
    "Важное из этого распределения количества внутри групп берем в выводы, и также сохраняем количество элементов,  \n",
    "чтобы по ходу анализа можно было посмоттреть сколько элементов в определенной группе\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавить вторую гистограмму рядом с первой.  \n",
    "На этой гистограмме изображаем данные без выбросов.  \n",
    "То есть обрезаем по 5 и 95 квантилям.  \n",
    "Это позволит посмотреть сразу на картину без выбросов.  \n",
    "Часто гистограмма кажется другой форме, так как сильно много выбросов.  \n",
    "И получается как бы растянутая.  \n",
    "Мы выбираем кусок без выбросов и увидем его в увеличенном виде.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "- в наблюдения пишем обязательно диапазон значений столбца.  \n",
    "Рынок жилья представлен объектами общей площадью от 12 до 900 кв.м. \n",
    "- пишем медианное занчение и по гистограмме и по квантилям определяем оснвоной диапазон.  \n",
    "В основном это жилье от 30 до 100 кв.м. с пиком в сегменте 30-75 кв.м  \n",
    "Это все нужно, чтобы потом сформулировать вот такой вывод (в оснвоном выводе отчета), то есть мы для разных столбцов пишем диапазоны,  \n",
    "основной дипазаон, медианы, моды, а потом уже собираем это в 1 или несколько выводов,  \n",
    "Например.  \n",
    "Рынок жилья представлен объектами общей площадью от 12 до 900 кв.м. В основном это жилье от 30 до 100 кв.м. с пиком в сегменте 30-75 кв.м. В жилой площади квартиры преобладает диапазон 15-50 кв.м. Размер площади кухни-от 5 до 15 кв.м., с пиком 9 кв.м. Это стандартные небольшие квартиры эконом-класса. Подавляющее большинство квартир- 1-3 комнатные, с высотой потолка 2,6-2,7 м., но встречаются редкие варианты до 19 комнат и высотой потолка до 20 кв.м. (либо ошибка, либо свободная планировка с возможностью многоуровневости).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- В колонке с длительностью звонка 20 процентов нулей.\n",
    "- Максимальная длительность звонка 38 минут.\n",
    "- Длительность звонка варьируется от 0 до 38 минут.\n",
    "- В основном длительность звонка находится в диапазоне от 1.3 до 10.7 минут.\n",
    "- Чаще всего звонок составляет 0 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "не забываем для каждого столбца смотреть, чтобы значнеия были физически возможны.  \n",
    "Так как иначе мы пропустим и не изучим эти выбросы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим каждый столбец отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНо  \n",
    "для каждого столбца делаем так\n",
    "- смотрим на пропуски, дубли, нули, отрицательные значения, записываем если что-то из этого есть\n",
    "- далее смотрим на максимальное и минимальное значение и думаем эти значения могли быть физически. Если нет, то сразу пишем, что это ошибки.  \n",
    "- Далее записываем диапазон от мин до макс\n",
    "- далее записываем основной диапазон от 25 до 75 процентилей\n",
    "- Далее смотрим на статистики\n",
    "- Смотрим на гистограмму\n",
    "- Смотрим на самые часто встречающиеся занчения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Для каждой категориальной переменной изучаем значения на адекватность, особенно всякие рейтинги в виде букв и прочие кодировки.  \n",
    "Нужно убедиться, что значения правильные и такие существуют. Если есть занчения, которых не должно быть, то отмечаем это.  \n",
    "Это также является ошибкой и аномалией. Которую потом нужно будет изучить и обработать.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "Для категориальных переменных смотрим на количество уникальных значений и сколкьо у нас показывается в top n  \n",
    "Если значений больше, то нуно ниже перед наблюдениями вывести все значения и проверить их на адектватность и реальность таких значений.  \n",
    "Задача все категориальные переменные проверить на адекватность и реальность.  \n",
    "И нужно посмотреть на все значения, если это возможно.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.value_counts_table(df, 'platform', chunk_size = 5, tables_in_row = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы было удобно, считаем сколько у нас столбцов, копируем next и ячейку наблюдения и вставляем столко раз, сколько у нас колонок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим по отдельности каждый столбец."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.info_gen(df)\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно построить 2 гистограммы (полную и обрезанную по 1 и 99 квантилю)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.next('dual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- В колонке цель кредита пропусков нет\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО  \n",
    "> Если увидели, что у нас в категориальной переменной одни и те же значения, но записанные с большой и с маленькой буквы, например,  \n",
    "> или другие проблемы с написанием одно и того же слова, что приводит к увеличению значений в категории.  \n",
    "> То нужно сразу это убирать, так как дальнейший анализ будет страдать.  \n",
    "> Для дальнейшего анализа срауз приведем колонку education к нижнему регистру и удалим лишние пробелы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> сделать предположения, почему могло так произойти, выдвигаем гипотезы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> придумать способы проверки выдвинутых гипотез и записать\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> если у нас по оси x время, то проанализировать сезонность\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> подумать а так и должно было получиться, основываясь на понимании физики параметра\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> зафиксировать возможные рекомендации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для гистограмм, нужно понять почему именно такое распределение метрики.  \n",
    "> Совпадет это с логикой этой метрики.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Также когда строим гистограммы и вайолин плот, то не просто фиксируем, что есть тяжелые хвосты, разброс между квартилями такой-то.  \n",
    "> А думаем почему так, пытаемся связать это с физикой параметра. Должно быть физическое объяснение всех аномалий.  \n",
    "> Если объяснения нет, то возможно это инсайт.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно убедиться, что у нас есть данные на все источники, которые заявлены. Например, мы изучаем источники трафика и у нас они в разных таблицах.  \n",
    "> Нужно убедиться, что во всех таблицах есть все источники, и проверить нет ли аномалий, возможно какой-то сильно выбивается или какого-то вообще где-то нет.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> И очень важно сверить, что периоды в разных таблицах (если у нас больше одной таблицы) совпадают.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно проверить соответствуют ли временной период данных тому, который заявлен в задании,  \n",
    "> определиться что будем делать с неполными периодами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Вообще, когда у нас несколько таблиц и там есть категориальные переменные или время, то  \n",
    "> мы должны взять уникальные значения категориальных переменных из каждой таблицы (одниаковые переменные) и сравнить.  \n",
    "> Количество уникальных должно совпадать, иначе нужно разбираться  \n",
    "> И с верменем как минимум мин и макс даты должны совпадать до дня, а лушше до минуты часа\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Очень важно, если у нас есть стартовая дата чего-то и конечная, то обязательно нужно проверить,  \n",
    "> нет ли у нас записей, где конечная дата меньше стартовой.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важная проверка, если у нас есть категории и даты, то сгруппировать по категориями и\n",
    "> вывести количество занчений, минимальную и максимальную дату  \n",
    "> Таким образом мы сразу поймем распределение в категории и  \n",
    "> увидем какие временные интервалы у каждой категории  \n",
    "> Если у нас все категории должны быть в один день, то мы поймем нет ли багов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Вообще очень важно смотреть не только на аномалии в значениях, но и аномалии в категориальных переменных.  \n",
    "> А тут аномалией будет отстутствие какого-то значения, хотя в описании или поставновке задачи оно есть.  \n",
    "> Также совпадение количества значений категориальных переменных в разных таблицах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Внимательно посмотреть на столбцы, если есть столбцы, в которых могут быть потенциальные анамали, то проверить их.  \n",
    "> Например, есть столбец возрасти стаж работы, проверить, что возраст больше стажа.  \n",
    "> И подобные случаи.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверка на нарушения уникальности  \n",
    "> Убедить, что столбцы, значения в которых не должны повторяться и должны быть уникальными, такие в действительности.  \n",
    "> Смотрим на результат функции `my_info`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверка на ошибки целостности  \n",
    "> Если у нас есть столбцы, в которых значения должны совпдаать попарно, то проверяем на это  \n",
    "> `get_non_matching_rows`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть в том, что мы смотрим, чтобы для одного уникального значения в колонке col1 было одно уникальное занчение в колонке col2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.get_non_matching_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нашли такие значения, то смотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.name == 'Battlezone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверка условий  \n",
    "> Проверьте, что данные в датафрейме удовлетворяют определенным условиям, таким как \"возраст > 18\" или \"страна == 'Россия'\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим и собираем наблюдения и выбросы в файл temp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "сразу делим на аномалии и наблюдения, чтобы потом не делить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас несколько датафреймов, то в temp.ipynb записываем отдельно  \n",
    "список категориальных переменных (с описанием)  \n",
    "и список числовых переменных (с описанием)  \n",
    "Чтобы далее можно было из этого списка сверять и изучать, что нужно "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем все датафреймы в словарь для удобства дальнейшей работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dict(\n",
    "    users = df_users\n",
    "    , calls = df_calls\n",
    "    , messages = df_messages\n",
    "    , internet = df_internet\n",
    "    , tariffs = df_tariffs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение дубликатов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть временная переменная, то нуно посмотреть количество дублей, выбросов, пропусков в столбце во времени.  \n",
    "Мы так сможем определить есть ли зависимсть от времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "для всех разделов дальше  \n",
    "Если у нас много таблиц и мы их не можем просто соеденить и посмотреть в разрезе категорий.  \n",
    "То берем все категориальные перменные и думаем, в разрезе каких их них будет полезно посмотреть   \n",
    "наши аномалии (дубли, пропуски, выбросы, нули, отрицательные числа).  \n",
    "И далее объединаям таблицы так, чтобы у нас получился датафрейм в котором столбец с нашей колонкой с аномалиями и столбец с категорией.  \n",
    "И изучаем. И так по каждой категории.  \n",
    "Нужно написать автоматизацию для этого.  \n",
    "Когда мерджим таблицы, то из каждой берем только необходимые поля.  \n",
    "Прям внутри pd.merge пишем не df, а df[columns], где columns указываем нужные колонки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_zeros_calls = pagri_data_tools.find_columns_with_zeros_values(df_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_zeros_internet = pagri_data_tools.find_columns_with_zeros_values(df_internet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас нули в длительности звонков и в объеме интернет-трафика.  \n",
    "При изучении каждой из этих колонок было замечено, что у них похожие распределения. Это интересно.  \n",
    "Объеденим эти два датафрейма, чтобы посмотреть у одних и тех же ли пользователей были нули в этих колонках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_zeros = series_zeros_calls['duration']\n",
    "mb_used_zeros = series_zeros_internet['mb_used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "common_users_with_zeros = set(duration_zeros['user_id']).intersection(set(df_internet['user_id']))\n",
    "len(common_users_with_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим в разрезе названия тарифа на нулевые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_merged = pd.merge(duration_zeros[['user_id', 'duration']], df_users[['user_id', 'tariff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tariff</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smart</th>\n",
       "      <td>25669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ultra</th>\n",
       "      <td>13944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "tariff       \n",
       "smart   25669\n",
       "ultra   13944"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duration_merged.groupby('tariff', observed=True).size().to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас несколько датафреймов.  Далее во всех разделах изучения (дубли, пропуски, выбросы, отрицательные значения, нули) смотрим, если у нас для каждой таблицы  \n",
    "будет много информации, то для каждой таблицы создаем подразделы.  \n",
    "А если информации мало, то помещаем все в одни раздел как для одного датафрейма.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем из временного файла названия таблиц, помещаем в ячейку и далее идем для каждой таблицы выполняем код  \n",
    "Если в итоге кода много, то просто вместо ячейки с текстом, делаем ячейку с подразделом (добавляем несколько #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users Таблица users (информация о пользователях)\n",
    "df_calls Таблица calls (информация о звонках)\n",
    "df_messages Таблица messages (информация о сообщениях)\n",
    "df_internet Таблица internet (информация об интернет-сессиях)\n",
    "df_tariffs Таблица tariffs (информация о тарифах)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "в временный файл записываем наблюдения по дубликатам, выбросам, нулевым, отрицательным значениям и пропусах,  \n",
    "которые нужны для обработки. Чтобы потом не бегать по отчету.  \n",
    "Записываем наблюдения, которые нужны для обработки, нарпимер, у нас есть записи с 0 комнат и мы их  \n",
    "изучили в разрезе площади и увидели что все они скорее всего студии и однокомнатыне.  \n",
    "Это нужно записать, чтобы в обработке заменить 0 на 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще основная задача этого этапа изучения данных не только обнаружить дубли, аномалии, пропуски,  \n",
    "но и сформулировать гипотезы, которые помогут нам в обработке.   \n",
    "Поэтому думаем не только что видим, а думаем сразу как будем обрабатывать и как можно проверить гипотезы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальшейших разделах изучения данных схема такая \n",
    "- смотрим каждый столбец \n",
    "- изучаем его аномалии по категориям\n",
    "- в процессе изучения по категориям стараемся определить закономерности, которые помогут обработать аномалии\n",
    "- для каждого столбца думаем как можно обработать аномалии, какие другие столбцы могут помочь определить закономерности.  \n",
    "- если определили числовой столбец, который может помочь, то сразу выдвигаем и проверяем гипотезу.  \n",
    "- и все записываем во временный файл, чтобы потом обрабатывать столбцы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про ИИ.  \n",
    "> Пишем список столбцов (именно что они значат, то есть образование, пол и прочее), говорим, что есть дубли.  \n",
    "> И просим предложить причины этих дублей. Если видим важное, то используем для рекомендаций, выводов и замены дублей в предобработке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверяем на дубли\n",
    "\n",
    "- Важно помнить, что если у нас есть id и название товара, то названия товара все равно нужно проверить на дубли,\n",
    "  > возможно у нас 2 ай ди с одним названием.\n",
    "- Также важно в каждой отдельной колонке проверить дубли и если их много, то посмотреть на соседние колонки, что там происходит\n",
    "- Дубликаты часто носят скрытый характер.\n",
    "  > То есть это могут быть поля, которые записаны по разному, но относятся к одному и тому же.  \n",
    "  > Поэтому важно, если у нас категориальный признак, изучить нет ли повторящихся категорий, которые записаны немного по разному.  \n",
    "  > Так как это создает шум, мы по сути имеем две разные категории, но на самом деле это одна. Нужно собрать их в одну.\n",
    "- И очень важно, если мы не подтвердили, что это действительно дубликат (например у нас нет ай ди клиента и мы не смогли выяснить один и тот же ли это человек),\n",
    "  > то нужно аккуратно удалять их. Но и оставлять много дублей плохо, так как они вносят шумы и искажения.\n",
    "- Помним, что наличие дубликата не говорит точно, что это дубль, возможно у нас нет ещё колонок, котоыре бы детализировали и разделили эти дубли.\n",
    "  > Поэтому тут могут быть рекомендации, чтобы добавли в фрейм доп колонки, которые помогут убрать дубли (либо сам ищешь ещё поля)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Когда смотрим на дубли, то нужно ответить на вопрос так и должно быть, это нормально, что дубли в этих колонках.  \n",
    "> Например у нас дубли во всех строках таблицы, нам нужно понять это может быть или этого не может быть, и нужно разбираться.  \n",
    "> Аналогично когда смотрим колонки по 2, 3 и так далее, то самое главное, ответить на вопрос дубли могут быть в этих колонках.  \n",
    "> Также когда разбиваем по категориям, задаем себе вопрос так могли распреедлеиться дубли.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `check_duplicated`  \n",
    "> `check_duplicated_combinations_gen`  \n",
    "> В первую функцию можно передавать весь датафрейм и можно выбирать нужные столбцы для проверки на дубли и передавать их.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на дубли во всех датафреймах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'users - no duplicates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'calls - no duplicates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'messages - no duplicates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'internet - no duplicates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tariffs - no duplicates'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, df in dfs.items():\n",
    "    display(f'{key} - {pagri_data_tools.check_duplicated(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если мы нашли колонки в которых дубликатов не должно быть, то нужно изучить эти дубликаты по категориальным переменным в нашем датафрейме  \n",
    "> `pagri_data_tools.analyze_anomaly_by_category`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.analyze_anomaly_by_category(df, series_zeros, \"by_category\", \"rooms\", 'studio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**\n",
    "\n",
    "- Особых перекосов в сторону определенного значения в категории не наблюдается\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Идем по порядку с помощью next(gen)  \n",
    "> если в выводе нет ничего интересного, то выше помещаем ячейку с таким содержимым\n",
    "> %%capture  \n",
    "> next(gen)  \n",
    "> снова выполняем next(gen), если снова ничего интересного то, к ячейке выше добавляем next(gen) будет так  \n",
    "> %%capture  \n",
    "> next(gen);next(gen)  \n",
    "> и так далее, пока не появится важная ячейка  \n",
    "> далее оставляем эту важную ячейку и снова повторяем с первого пункта,  \n",
    "> в итоге между ячейками с нужным выводом будут ячейки с запрещенным выводом и можно будет прогонять ноутбук весь целиком и выводы будут в нужнфх местах\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на дубли во всем датафрейме\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_duplicated(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датафрейме полных строк дубликатов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если строк дублей мало, то можно их просто изучить в таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'].isna() | df['genre'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfs.items():\n",
    "    display(f'{key} - {pagri_data_tools.check_duplicated(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько у нас дублей в каждой колонке\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_duplicated = pagri_data_tools.find_columns_with_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfs.items():\n",
    "    print(key)\n",
    "    series_duplicated = pagri_data_tools.find_columns_with_duplicates(df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас нет столбцов, в которых значения долны быть уникльыми. Поэтом все впорядке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим есть ли дубликаты одновременно в названии игры, жанре и платформе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_duplicated(df[['name', 'platform', 'genre']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть топ 10 по какой-то переменной и изучить их отдельно   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_zeros.user_id.value_counts().iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, у нас нули в длительности звонка, мы можем найти у каких пользователей больше таких звонков и изучить их отдельно  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас много данных и мы не можем соеденить датафреймы, то мы можем посмотреть сколько одинаковых строк по какой-то переменной.  \n",
    "Лучше чтобы эта переменная была уникальная, также это можно сделать по нескольким переменным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_zeros = series_missed['duration']\n",
    "mb_used_zeros = series_missed['mb_used']\n",
    "common_users_with_zeros = set(duration_zeros['user_id']).intersection(set(df_internet['user_id']))\n",
    "len(common_users_with_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Думаем какие столбцы должны быть уникальными и где дублей не должно быть.  \n",
    "> И их уже изучаем на дубли.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно посмотреть на строки датафрейма в колонках с дублями  \n",
    "> Это делаем, если есть время, так как этот шаг редко даст результат, так как на глаз сложно определить закономерности.  \n",
    "> Суть этого шага посмотреть на строки датафрейма в разных колонках с дублями и выдвинуть гипотезы с закономеностями в этих дублях\n",
    "> по очереди берем колонки и смотрим на датафреймы (записано рядом, чтобы показать, что не одну колонку только беерем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_duplicated = series_duplicated['col1']\n",
    "col2_duplicated = series_duplicated['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_duplicated.head()\n",
    "col2_duplicated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно подумать не только о одиночных столбцах, которые долны иметь уникальные значения.  \n",
    "Но обязательно подумать какие комбинации столбцов должны быть уникальными.  \n",
    "Если есть такие комбинации, то фильтруем датафрейм по этим столбцам и используем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[['col1', 'col2']]\n",
    "pagri_data_tools.check_duplicated(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас есть столбцы в которых значения должны быть уникальными, то помещаем их в отдельный датафрейим и изучаем дальше.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> когда изучаем по категориям, то смотрим на diff_sum_pct, тут логика такая -  \n",
    "нам нужно сравнить количество строк с пропусками в каждой категории, учитывая размер этой категории.  \n",
    "То есть если у нас категории например дорогие квартиры и дешевые (категориальная переменная нарпимер категория стоимости)  \n",
    "и в них соотношение пропусков 1000 к 500, а общее соотношение групп 700 на 800, то явно отличается количество.  \n",
    "Поэтому мы смотрим на отличия, и если они существенны, то делаем вывод, что категория влияет на пропуски.  \n",
    "Иначе пишем, что влияние не обнаружено.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.check_duplicated_combinations_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на дубли в комбинации колонок с названием игры, жанром и платформой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.check_duplicated_combinations_gen(df[['name', 'platform', 'genre']], n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dabe8 caption {\n",
       "  font-size: 18px;\n",
       "  text-align: left;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dabe8\">\n",
       "  <caption>Duplicates</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dabe8_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_dabe8_level0_col1\" class=\"col_heading level0 col1\" >platform</th>\n",
       "      <th id=\"T_dabe8_level0_col2\" class=\"col_heading level0 col2\" >genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dabe8_level0_row0\" class=\"row_heading level0 row0\" >name</th>\n",
       "      <td id=\"T_dabe8_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_dabe8_row0_col1\" class=\"data row0 col1\" ></td>\n",
       "      <td id=\"T_dabe8_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dabe8_level0_row1\" class=\"row_heading level0 row1\" >platform</th>\n",
       "      <td id=\"T_dabe8_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "      <td id=\"T_dabe8_row1_col1\" class=\"data row1 col1\" ></td>\n",
       "      <td id=\"T_dabe8_row1_col2\" class=\"data row1 col2\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dabe8_level0_row2\" class=\"row_heading level0 row2\" >genre</th>\n",
       "      <td id=\"T_dabe8_row2_col0\" class=\"data row2 col0\" >5014</td>\n",
       "      <td id=\"T_dabe8_row2_col1\" class=\"data row2 col1\" >16150</td>\n",
       "      <td id=\"T_dabe8_row2_col2\" class=\"data row2 col2\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7405bc5474d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- В паре платформа и название игры всего 3 дубликата\n",
    "- В парах жанр/название игры и жанр/платформа много дубликатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на строки с дублями в названии игры и платформе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>genre</th>\n",
       "      <th>na_sales</th>\n",
       "      <th>eu_sales</th>\n",
       "      <th>jp_sales</th>\n",
       "      <th>other_sales</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>PC</td>\n",
       "      <td>2,005.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>PC</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>X360</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>83.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>X360</td>\n",
       "      <td>2,005.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>83.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name platform  year_of_release   genre  \\\n",
       "604                  Madden NFL 13      PS3         2,012.00  Sports   \n",
       "16230                Madden NFL 13      PS3         2,012.00  Sports   \n",
       "5972   Need for Speed: Most Wanted       PC         2,005.00  Racing   \n",
       "11715  Need for Speed: Most Wanted       PC         2,012.00  Racing   \n",
       "1190   Need for Speed: Most Wanted     X360         2,012.00  Racing   \n",
       "1591   Need for Speed: Most Wanted     X360         2,005.00  Racing   \n",
       "\n",
       "       na_sales  eu_sales  jp_sales  other_sales  critic_score  user_score  \\\n",
       "604        2.11      0.22      0.00         0.23         83.00        5.50   \n",
       "16230      0.00      0.01      0.00         0.00         83.00        5.50   \n",
       "5972       0.02      0.23      0.00         0.04         82.00        8.50   \n",
       "11715      0.00      0.06      0.00         0.02         82.00        8.50   \n",
       "1190       0.62      0.78      0.01         0.15         83.00        8.50   \n",
       "1591       1.00      0.13      0.02         0.10         83.00        8.50   \n",
       "\n",
       "      rating  \n",
       "604        E  \n",
       "16230      E  \n",
       "5972       T  \n",
       "11715      T  \n",
       "1190       T  \n",
       "1591       T  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df[['name', 'platform']].duplicated(keep=False)].sort_values(by=['name', 'platform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ddfd4\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ddfd4_row0_col0\" class=\"data row0 col0\" >name | platform | genre</td>\n",
       "      <td id=\"T_ddfd4_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7405bc2ad7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на дубликаты одновременно в названии игры, жанре и платформе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated is 3 (0.0%) rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>madden nfl 13</th>\n",
       "      <th>ps3</th>\n",
       "      <th>sports</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">need for speed: most wanted</th>\n",
       "      <th>pc</th>\n",
       "      <th>racing</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x360</th>\n",
       "      <th>racing</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             count\n",
       "name                        platform genre        \n",
       "madden nfl 13               ps3      sports      2\n",
       "need for speed: most wanted pc       racing      2\n",
       "                            x360     racing      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pagri_data_tools.check_duplicated(df[['name', 'platform', 'genre']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на строки датафрейма с этими дубликатами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>genre</th>\n",
       "      <th>na_sales</th>\n",
       "      <th>eu_sales</th>\n",
       "      <th>jp_sales</th>\n",
       "      <th>other_sales</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>PC</td>\n",
       "      <td>2,005.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>PC</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>X360</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>83.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>X360</td>\n",
       "      <td>2,005.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>83.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name platform  year_of_release   genre  \\\n",
       "604                  Madden NFL 13      PS3         2,012.00  Sports   \n",
       "16230                Madden NFL 13      PS3         2,012.00  Sports   \n",
       "5972   Need for Speed: Most Wanted       PC         2,005.00  Racing   \n",
       "11715  Need for Speed: Most Wanted       PC         2,012.00  Racing   \n",
       "1190   Need for Speed: Most Wanted     X360         2,012.00  Racing   \n",
       "1591   Need for Speed: Most Wanted     X360         2,005.00  Racing   \n",
       "\n",
       "       na_sales  eu_sales  jp_sales  other_sales  critic_score  user_score  \\\n",
       "604        2.11      0.22      0.00         0.23         83.00        5.50   \n",
       "16230      0.00      0.01      0.00         0.00         83.00        5.50   \n",
       "5972       0.02      0.23      0.00         0.04         82.00        8.50   \n",
       "11715      0.00      0.06      0.00         0.02         82.00        8.50   \n",
       "1190       0.62      0.78      0.01         0.15         83.00        8.50   \n",
       "1591       1.00      0.13      0.02         0.10         83.00        8.50   \n",
       "\n",
       "      rating  \n",
       "604        E  \n",
       "16230      E  \n",
       "5972       T  \n",
       "11715      T  \n",
       "1190       T  \n",
       "1591       T  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df[['name', 'platform', 'genre']].duplicated(keep=False)].sort_values(by=['name', 'platform', 'genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- У игры Madden NFL 13 все параметры совпадают в дублях, кроме количества проданных копий.  \n",
    "Возможно часть проданных копий учлась отдельно. \n",
    "- В игре Need for Speed: Most Wanted у дублей разные года выпуска, поэтому это не дубли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> смотрим по категориям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО - убедиться, что нет в ноутбуке `_gen_` (делаем ctrl+F и вбиваем `_gen_`)  \n",
    "ставим `_gen_` в том месте где хотим чтобы появились ячейки после работы в prep_dash  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код появится после работы в dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "добавить в приложение dash возможность писать код на питоне для работы с текущим датафреймом.  \n",
    "Это нужно чтобы изучить аномалии. То есть мы запускаем dash app.  \n",
    "Далее у нас для каждой колонки будут выводиться разбивки по категориям  \n",
    "Но дополнительно нужно будет проверять разные гипотезы, чтобы потом на основе этого обрабатывать данные.\n",
    "Для этого нужно иметь возможность выполнять код и видеть результат.  \n",
    "и чтобы можно было нужный код (который хотим поместить в отчет) сохранить также как next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_duplicated, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно на дубли проверить и отдельные строки и целиком таблицу и подумать какие группы столбцов могут дать дубли и на это тоже проверить.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если в дублях у нас есть ай ди клиента, то тут понятно, если нет ай ди, то пишем рекомендацию, чтобы данные приходили с ай ди,  \n",
    "> чтобы можно было понять это один человек или нет\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас id пользователя встречается не одни раз в таблице и есть другие поля которые должны быть всегда одни и те же,  \n",
    "> напримем пол и прочее, то нужно проверить у всех ли пользователей все значения одинаковые в этом столбце.  \n",
    "> Это может быть не только ай ди, любое уникальное поле, которое повторяется и для каждого этого поля есть другое  \n",
    "> поле, которое не должно меняться, нужно проверять а действительно ли это поле не меняется.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение пропусков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть временная переменная, то нуно посмотреть количество дублей, выбросов, пропусков в столбце во времени.  \n",
    "Мы так сможем определить есть ли зависимсть от времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "категориальные переменные с пропусков заменяем на что-то типа другое  \n",
    "Даже если пропусков много.  \n",
    "Это важно, так как когда смотрим на колонки с пропуском, то можем забыть, что определенные колонки категориальные,  \n",
    "и на них не распрастраняется правило, что больше 20 процентов пропусков не трогаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим пропуски в каждом столбце."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про ИИ.  \n",
    "> Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть пропуски.  \n",
    "> И просим предложить причины этих пропусков. Если видим важное, то используем для рекомендаций, выводов и замены пропусков в предобработке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверяем на пропуски\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Когда смотрим на пропуски, то нужно ответить на вопрос так и должно быть, это нормально, что пропуски в этих колонках.  \n",
    "> Когда смотрим на пропуски по категориям, то думаем есть ли закономерность, не случайно ли распределение по категориям\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Когда мы встречаем пропуски, прежде всего, нужно ответить на вопрос, существует ли закономерность в появлении пропусков.  \n",
    "> Иными словами, не случайно ли их возникновение в наборе данных.  \n",
    "> Случайно, значит нет закономерности с соседними столбцами, то есть пропуски есть для разных значений.  \n",
    "> А могут быть неслучайные, то есть существует явная закономерностЬ, что пропуски есть только у сторок с общими занчениями в другом столбце.  \n",
    "> Чтобы это проверить, нужно взять столбец с пропусками, отфильтровать только пропуски (взять их) и  \n",
    "> посмотреть как эти пропуски распределены по другой переменной.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Первое что нужно сделать, когда мы видим пропуск или выброс, это проверить является ли оно случайным.\n",
    "  > То есть посмотреть не относятся ли все выбросы к одной категории. Если это так, то это уже не случайно и мы нашли аномалию, которую можно изучать.  \n",
    "  > Если у нас случайны разброс пропусков в категориях, то значит тут есть случайность.  \n",
    "  > Например, у нас возраст 0, и мы видим, что больше всего это у женщин. Следовательно получаем гипотезу, что женщины не хотят сообщать свой возраст.\n",
    "- В пропусках мы можем определить какие категории, платформы и прочее не собираются данные. Смотрим пропуски, далее смотрим у каких категорий их больше,\n",
    "  > и получаем вывод, что нужно обратить внимание на эти категории или системы, почему там пропуски\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `find_columns_with_missing_values`  \n",
    "> `check_na_in_both_columns`  \n",
    "> `analyze_by_category_gen`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "категориальные переменные с пропускамми более 20 процентов не игнорируем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пропуски в каждом столбце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eac9c_ caption {\n",
       "  font-size: 18px;\n",
       "  text-align: left;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eac9c_\">\n",
       "  <caption>Missings</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_eac9c_level0_row0\" class=\"row_heading level0 row0\" >days_employed</th>\n",
       "      <td id=\"T_eac9c_row0_col0\" class=\"data row0 col0\" >2174 (10.10%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_eac9c_level0_row1\" class=\"row_heading level0 row1\" >total_income</th>\n",
       "      <td id=\"T_eac9c_row1_col0\" class=\"data row1 col0\" >2174 (10.10%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15835198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_missed = pagri_data_tools.find_columns_with_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfs.items():\n",
    "    print(key)\n",
    "    series_duplicated = pagri_data_tools.find_columns_with_missing_values(df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в колонке пропусков мало (меньше 10-20 штук), то можно их просто изучить в таблице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если хотим сразу несколько посмотреть и их мало, то можно использовать побитовый или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'].isna() | df['genre'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно посмотреть на строки датафрейма в колонках с пропусками  \n",
    "> Это делаем, если есть время, так как этот шаг редко даст результат, так как на глаз сложно определить закономерности.  \n",
    "> Суть этого шага посмотреть на строки датафрейма в разных колонках с пропусками и выдвинуть гипотезы с закономеностями в этих пропусках\n",
    "> по очереди берем колонки и смотрим на датафреймы (записано рядом, чтобы показать, что не одну колонку только беерем)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_missed = series_missed['col1']\n",
    "col2_missed = series_missed['col2']\n",
    "col1_missed.head()\n",
    "col2_missed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Думаем какие столбцы связаны, и их лучше изучить вместе на пропуски.  \n",
    "> Смотрим на количество и процент пропусков в разных колонках и если они равны, то можно выдвинуть гипотезу, что пропуски совпадают\n",
    "> То есть у нас может появиться гипотеза, что пропуски в нескольких столбцах связаны между собой.  \n",
    "> Вот мы береме эти столбцы и смотрим сколько прпоусков в обеих колонках вместе, если это совпадает с пропусками в каждой колонке,  \n",
    "> то гипотеза подтвердилась.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Пример  \n",
    "Можно заметить, что количество пропусков в колонке с количеством парков рядом и количеством прудов рядом совпадает.  \n",
    "Выдвигаем гипотезу, что пропуски в одних и тех же строках в обоих столбцах.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в колонке пропусков мало (меньше 10-20 штук), то можно их просто изучить в таблице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если хотим сразу несколько посмотреть и их мало, то можно использовать побитовый или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'].isna() | df['genre'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим пропуски одновременно в несколкьих колонках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.check_na_combinations_gen(df[['critic_score', 'user_score', 'rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на строки датафрейма, где пропуски одновременно в нескольких столбцах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na_in_both_columns = pagri_data_tools.check_na_in_both_columns(df, ['parks_around3000', 'ponds_around3000'])\n",
    "df_na_in_both_columns.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- Большинство пропусков в столбцах оценка пользователей и оценка критиков находятся в одних и тех же строках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на строки не только всего датафрейма, но и только на выбранные строки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_missed['living_area'][['total_area', 'living_area', 'kitchen_area']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза подтвердилась**:\n",
    "- Пропуски в одних и тех же строках в колонках с количеством парков рядом, количеством прудов рядом совпадает,  \n",
    "растоянием до центра, растоянием до аэропорта примерно равны  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как распределены пропуски по категориям в строках, где прпоуски одновременно в этих столбцах.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.analys_filtered_df_by_category(df, df_na_in_both_columns, 'df with na')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если хотим показать только часть из gen, то подставляем нужные категории в эту функцию  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.analyze_share_by_category(df, df_na_in_both_columns, 'df with na', 'is_apartment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Изучаем пропуски по категориям\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО - убедиться, что нет в ноутбуке `_gen_` (делаем ctrl+F и вбиваем `_gen_`)  \n",
    "ставим `_gen_` в том месте где хотим чтобы появились ячейки после работы в prep_dash  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_missed, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> когда изучаем по категориям, то смотрим на diff_sum_pct, тут логика такая -  \n",
    "нам нужно сравнить количество строк с пропусками в каждой категории, учитывая размер этой категории.  \n",
    "То есть если у нас категории например дорогие квартиры и дешевые (категориальная переменная нарпимер категория стоимости)  \n",
    "и в них соотношение пропусков 1000 к 500, а общее соотношение групп 700 на 800, то явно отличается количество.  \n",
    "Поэтому мы смотрим на отличия, и если они существенны, то делаем вывод, что категория влияет на пропуски.  \n",
    "Иначе пишем, что влияние не обнаружено.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Смотрим на все поля  \n",
    "> in_category_pct говорит о том сколько в этом значении категории изучаемых значений  \n",
    "> in_column_pct говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    "> total_count_pct помогает анализировать in_column_pct, так как мы видим сколько занимает это значение в общем\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение выбросов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если мы при изучении колонки, обнаружили выбросы (это может быть просто выбивающееся значение), то тут нужно посмотерть на строки датафрейма с этими значениями.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Выбросы могут быть не очевидны, например, у нас лог заказов и есть пользователи, которые совершили слишком много заказов.  \n",
    "Крупные заказы мы заметим, но важно тут сгруппировать по id (это может быть пользователь, заках и прочее) и посмотреть аггрегированные занчеия,  \n",
    "построить boxplot и если есть выделяющиеся id, то их нужно изучить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть временная переменная, то нуно посмотреть количество дублей, выбросов, пропусков в столбце во времени.  \n",
    "Мы так сможем определить есть ли зависимсть от времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим выбросы в каждом столбце."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Выбросы могут быть не заметны в общей картине, но в конкретной категории это будет выброс.  \n",
    "Поэтому по возможности нужно изучить хотя бы макс и мин значения в каждой категории и год мин и макс.  \n",
    "Например, у нас продажи игр и есть категория платформа.  \n",
    "Мы видим макс и мин год и вроде все нормально, но если посмотреть на конкретную платформу, то есть игры с датой 1985 год, хотя эта платформа  \n",
    "появилась позднее.   \n",
    "Вот такие выбросы могут быть не видны в общей картине. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если хотим изучить выбросы по категориям которых ещё нет и они будут дальше или если у нас несколько таблиц и мы хотим изучить  \n",
    "пропуски в одной таблице в разрезе категориальной переменной из другой таблицы.  \n",
    "То создаем временную таблицу для этого, объединаям все что нам нужно в одну таблицу,  \n",
    "создаем нужные категории и изучаем пропуски, выбросы дубликаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "когда изучаем выбросы, нулевые и отрицательные значения, то нужно сразу проверять гипотезы.  \n",
    "То есть если у нас нарпимер 0 команат, то мы выдвигаем гипотезу, что это студии и однокомнатыне и если у нас есть площадь или  \n",
    "другой паарметр по которому мы можем проверить гипотезу, то проверяем.  \n",
    "Также с другими параметрами.  \n",
    "Именно тут в изучении данных мы должны выдвигать гипотезы и проверять их.  \n",
    "И результаты писать в отчет и во верменный файл, чтобы потом в обработке данных использовать эти выводы гиптоез для замены пропусков.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем изучать по категориям сильно низкие и сильно высокие знения.  \n",
    "Например, если у нас цены на квартиры, то нужно посмотреть по категории населенный пункт.  \n",
    "Так как мы сможем понять в этом населенном пункте могут быть такие занчения или нет.  \n",
    "Аналогично и не с населенными пунктами.  \n",
    "Наша задача - определить какая категориальная переменная характеризует переменную с выбросами.  \n",
    "И посмотреть в ее разрезе, что поможет нам понять, что это за выбросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про ИИ.  \n",
    "> Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть выбросы.  \n",
    "> Обязательно приводим значения выбросов, самые характерные, чтобы дать ИИ болше информации.\n",
    "> И просим предложить причины этих выбросов. Если видим важное, то используем для рекомендаций, выводов и замены выбросов в предобработке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Когда смотрим на выбросы, то нужно ответить на вопрос так и должно быть, это нормально, что выбросы в этих колонках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выбросы это не только просто сильно большое или сильно маленькое значение.\n",
    "- Выбросы нужно также смотреть по мультипараметрам, с помощью моделей и искать аномалии.\n",
    "- Выброс это то, что отделяется от других, что выбивается из общей картины. Следовательно это что-то особенное.\n",
    "- Тажке выбросы говорят не только о плюсах, но и о минусах. Выбросы могут сказать, что у нас что-то сломалось.\n",
    "  > Что-то не записывается, или работает с багами. Все это можно увдитеь по выбрасам и аномалиям.\n",
    "- Обязательно посмотреть выбросы в разрезе категорий, так как мы сможем сделать выводы об их источнике.\n",
    "- Если мы работаем со строгой отчетностью, то тут любой выброс это уже инсайт и нужно идти разбираться откуда это взялось.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если мы во время изучения данных выявили потенциальные выбросы, то нужно их отдельно изучить.  \n",
    "> Для этого создаем датафрейм с нужными значениями и помещаем его в `Series`,  \n",
    "> индекс это название колонки, в которой мы изучаем выброс.  \n",
    "> Далее отдаем этот `Series` в функцию `analyze_by_category_gen`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сначала изучим потенциальные выбросы, которые мы выявили при изучении колонок.  \n",
    "> У нас в количестве детей есть значение 20.  \n",
    "> Изучим его подробнее.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно при изучении колонок записывать выбросы отдельно и потом коппировать сюда.  \n",
    "> А тут нужно изучить эти значения отдельно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> когда изучаем по категориям, то смотрим на diff_sum_pct, тут логика такая -  \n",
    "нам нужно сравнить количество строк с пропусками в каждой категории, учитывая размер этой категории.  \n",
    "То есть если у нас категории например дорогие квартиры и дешевые (категориальная переменная нарпимер категория стоимости)  \n",
    "и в них соотношение пропусков 1000 к 500, а общее соотношение групп 700 на 800, то явно отличается количество.  \n",
    "Поэтому мы смотрим на отличия, и если они существенны, то делаем вывод, что категория влияет на пропуски.  \n",
    "Иначе пишем, что влияние не обнаружено.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО - убедиться, что нет в ноутбуке `_gen_` (делаем ctrl+F и вбиваем `_gen_`)  \n",
    "ставим `_gen_` в том месте где хотим чтобы появились ячейки после работы в prep_dash  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если выбросов мало (меньше 10), то лучше просто показать датафрейм с этими выбросами и написать наблюдения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = pd.Series([df[df.children == 20]], index=['children'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим нет ли у нас выбросов по сумме заказов по пользователям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгруппируем по пользователям и посмотрим топ пользователй по сумме заказа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5539673724080479777</th>\n",
       "      <td>11,810.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11149926373378902217</th>\n",
       "      <td>10,519.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999372575896145244</th>\n",
       "      <td>1,979.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731421022966725351</th>\n",
       "      <td>1,450.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644482766749211722</th>\n",
       "      <td>1,444.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       revenue\n",
       "uid                           \n",
       "5539673724080479777  11,810.18\n",
       "11149926373378902217 10,519.46\n",
       "17999372575896145244  1,979.33\n",
       "6731421022966725351   1,450.68\n",
       "3644482766749211722   1,444.29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_orders.groupby('uid')[['revenue']].sum().sort_values('revenue', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- 2 пользователя имеют намного болше суммы заказов, чем остальные. Скорее всего это оптовики или перекупы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно проверить все id (не только пользователей, но и другие, для которых нет категории, то есть где количество уникальных значений большое), чтобы убедиться, что нет сильных выбросов)  \n",
    "Нужно взять id, сгруппировать по ним и аггрегировать все числовые переменные и убедиться, что нет явно выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "это очень важно, если у нас есть переменная, которая принмает много разных значений и это идентификатор, то мы далее будем аггрегировать данные,  \n",
    "и не заметим, что какой-то id может выделяться от остальных по какой-то числовой переменной.  \n",
    "По сути это выброс, который мы пропустим. И он будет нам искажать картинку.  \n",
    "Поэтому нужно изучить все id по всем числовым переменным, чтобы убедиться, что явных выбросов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "таким образом нам нужно изучить выбросы по неаггрегированным данным, чтобы обнаружить слишком большие значения.  \n",
    "И также нужно изучить выбросы по аггрегированным данным, чтобы обнаружить слишком большие суммарные занчения по категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_outliers, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Смотрим на выбросы используя Z-score  \n",
    "> `detect_outliers_Zscore`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = pagri_data_tools.detect_outliers_Zscore()\n",
    "# сначала смотрим на значения с большим количеством выбросов\n",
    "series_outliers['col'].col.value_counts().to_frame('outliers')\n",
    "# затем уже изучаем определенные датафреймы в series_outliers\n",
    "series_outliers['col'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_outliers, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `detect_outliers_quantile`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выбросы используя квантили.    \n",
    "Выбросами будем считать значения, которые выходят за пределы 5 и 95 квантилей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение того, какой процент выбросов за пределами 5-го и 95-го квантилей можно считать \"небольшим\", может зависеть от контекста и специфики ваших данных. Однако, в общем случае можно использовать следующие ориентиры:\n",
    "\n",
    "- 0% - 5%: Это обычно считается очень низким уровнем выбросов. Если процент выбросов находится в этом диапазоне, это может указывать на то, что данные достаточно чистые и не содержат значительных аномалий.\n",
    "- 5% - 10%: Этот диапазон все еще может считаться приемлемым, особенно в некоторых областях, где небольшое количество выбросов является нормальным явлением.\n",
    "- 10% - 20%: Это может быть признаком того, что в данных есть некоторое количество аномалий, и вам стоит обратить на них внимание. В зависимости от контекста, это может быть допустимо, но требует дальнейшего анализа.\n",
    "- Более 20%: Это обычно считается высоким уровнем выбросов. Если процент выбросов превышает 20%, это может указывать на наличие значительных аномалий или проблем с данными, и вам следует провести более детальный анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно посмотреть насколько одинаковые проценты выбросов в разных столбцах.  \n",
    "Если процент примерно одинаковый, то это говорит об однородности данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = pagri_data_tools.detect_outliers_quantile(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- Процент выбросов во всех колонках, кроме года выпуска, находится в диапазоне 0-5%. Это может указывать на то, что данные достаточно чистые и не содержат значительных аномалий.\n",
    "- Процент выбросов во всех колонках примерно одинаковый, что может свидетельствовать об однородности данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выбросы используя квантили.    \n",
    "Выбросами будем считать значения, которые выходят за пределы 5 и 95 квантилей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = pagri_data_tools.detect_outliers_quantile(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- Процент выбросов во всех колонках, кроме года выпуска, находится в диапазоне 0-5%. Это может указывать на то, что данные достаточно чистые и не содержат значительных аномалий.\n",
    "- Процент выбросов во всех колонках примерно одинаковый, что может свидетельствовать об однородности данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим от 1 до 99 квантиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = pagri_data_tools.detect_outliers_quantile(df, lower_quantile=0.01, upper_quantile=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределены выбросы во времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"d8c00a6a-ffd6-4260-ad40-9e8a54e3f6fb\" class=\"plotly-graph-div\" style=\"height:450px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d8c00a6a-ffd6-4260-ad40-9e8a54e3f6fb\")) {                    Plotly.newPlot(                        \"d8c00a6a-ffd6-4260-ad40-9e8a54e3f6fb\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"],[\"= 1\"]],\"hovertemplate\":\"x = %{x}\\u003cbr\\u003ey = %{y:.4s}\\u003cbr\\u003e\\u0420\\u0430\\u0437\\u043c\\u0435\\u0440 \\u0433\\u0440\\u0443\\u043f\\u043f\\u044b %{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"rgba(128, 60, 170, 0.9)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"2019-08-01T00:00:00\",\"2019-08-02T00:00:00\",\"2019-08-03T00:00:00\",\"2019-08-04T00:00:00\",\"2019-08-05T00:00:00\",\"2019-08-06T00:00:00\",\"2019-08-07T00:00:00\",\"2019-08-08T00:00:00\",\"2019-08-09T00:00:00\",\"2019-08-10T00:00:00\",\"2019-08-11T00:00:00\",\"2019-08-12T00:00:00\",\"2019-08-13T00:00:00\",\"2019-08-14T00:00:00\",\"2019-08-15T00:00:00\",\"2019-08-16T00:00:00\",\"2019-08-17T00:00:00\",\"2019-08-18T00:00:00\",\"2019-08-19T00:00:00\",\"2019-08-20T00:00:00\",\"2019-08-21T00:00:00\",\"2019-08-22T00:00:00\",\"2019-08-23T00:00:00\",\"2019-08-24T00:00:00\",\"2019-08-25T00:00:00\",\"2019-08-26T00:00:00\",\"2019-08-27T00:00:00\",\"2019-08-28T00:00:00\",\"2019-08-29T00:00:00\",\"2019-08-30T00:00:00\",\"2019-08-31T00:00:00\"],\"xaxis\":\"x\",\"y\":[58460,69466,0,31460,28615,68469,163923,116900,98904,175060,250,204800,225990,31952,202930,129840,290,536,1403875,37735,91499,54284,68310,53904,41840,112225,230385,550,306995,114960,320],\"yaxis\":\"y\",\"type\":\"bar\",\"hoverlabel\":{\"bgcolor\":\"white\"},\"textfont\":{\"family\":\"Segoe UI\",\"size\":14}}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"font\":{\"size\":14,\"color\":\"rgba(0, 0, 0, 0.7)\"},\"text\":\"\\u0414\\u0430\\u0442\\u0430\"},\"tickfont\":{\"size\":14,\"color\":\"rgba(0, 0, 0, 0.7)\"},\"linecolor\":\"rgba(0, 0, 0, 0.4)\",\"tickcolor\":\"rgba(0, 0, 0, 0.4)\",\"visible\":true,\"showgrid\":false,\"gridwidth\":1,\"gridcolor\":\"rgba(0, 0, 0, 0.1)\",\"dtick\":\"D1\",\"tickformat\":\"%d %b\",\"tickangle\":-45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"font\":{\"size\":14,\"color\":\"rgba(0, 0, 0, 0.7)\"},\"text\":\"\\u0421\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c \\u0437\\u0430\\u043a\\u0430\\u0437\\u0430\"},\"tickfont\":{\"size\":14,\"color\":\"rgba(0, 0, 0, 0.7)\"},\"linecolor\":\"rgba(0, 0, 0, 0.4)\",\"tickcolor\":\"rgba(0, 0, 0, 0.4)\",\"visible\":true,\"showgrid\":true,\"gridwidth\":1,\"gridcolor\":\"rgba(0, 0, 0, 0.07)\"},\"legend\":{\"tracegroupgap\":0,\"title\":{\"font\":{\"color\":\"rgba(0, 0, 0, 0.7)\",\"size\":14}},\"font\":{\"color\":\"rgba(0, 0, 0, 0.7)\"},\"orientation\":\"h\",\"yanchor\":\"top\",\"y\":1.05,\"xanchor\":\"center\",\"x\":0.5},\"margin\":{\"t\":70,\"l\":50,\"r\":50,\"b\":50},\"barmode\":\"group\",\"title\":{\"font\":{\"size\":16,\"color\":\"rgba(0, 0, 0, 0.7)\"},\"text\":\"\\u0421\\u0443\\u043c\\u043c\\u0430\\u0440\\u043d\\u0430\\u044f \\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c \\u0437\\u0430\\u043a\\u0430\\u0437\\u0430 \\u043f\\u043e \\u0434\\u043d\\u044f\\u043c\"},\"font\":{\"size\":14,\"family\":\"Segoe UI\",\"color\":\"rgba(0, 0, 0, 0.7)\"},\"hoverlabel\":{\"bgcolor\":\"white\"},\"width\":1000,\"height\":450},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d8c00a6a-ffd6-4260-ad40-9e8a54e3f6fb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    df = outliers_by_month\n",
    "    , x = 'date'\n",
    "    , y = 'revenue'  \n",
    "    , barmode = 'group'\n",
    "    , orientation = 'v'\n",
    "    , func = 'sum'\n",
    "    , xaxis_show = True\n",
    "    , yaxis_show = True\n",
    "    , showgrid_x = False\n",
    "    , showgrid_y = True      \n",
    "    , sort = True    \n",
    "    , sort_axis = False    \n",
    "    , sort_legend = True      \n",
    "    , width = 1000\n",
    "    , height = 450                                                                                                                         \n",
    ")\n",
    "fig = pagri_data_tools.bar(config)\n",
    "fig = pagri_data_tools.plotly_default_settings(fig)\n",
    "fig.update_layout(\n",
    "    title_text = 'Суммарная стоимость заказа по дням'\n",
    "    , yaxis_title_text = 'Стоимость заказа'\n",
    "    , xaxis_title_text = 'Дата'\n",
    "    , xaxis=dict(\n",
    "        dtick='D1',  # Интервал в 1 день\n",
    "        tickformat='%d %b',  # Формат отображения даты\n",
    "        tickangle=-45,  # Угол наклона меток\n",
    "        showgrid = False\n",
    "    )    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- Боьше всего суммарных выбросов в стоимости заказа было в декабре 2017 года"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_outliers, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим на строки датафрейма с выбросами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_outliers = series_outliers['col1']\n",
    "col2_outliers = series_outliers['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_outliers.head()\n",
    "col2_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Изучить выбросы по категориями  \n",
    "> `analyze_by_category_gen`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Смотрим на все поля  \n",
    "> `in_category_pct` говорит о том сколько в этом значении категории изучаемых значений  \n",
    "> `in_column_pct` говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    "> `total_count_pct` помогает анализировать `in_column_pct`, так как мы видим сколько занимает это значение в общем\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_outliers, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если переменная распределенна нормально, то выбросы можно определить как точки за пределами плюс минус 3 стандартных отклонения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать функцию для определения выбросов через 3 стандартных отклонения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть адреса, и мы знаем, что данные из одного города или из определенных, то нужно убедиться, что нет дургих городов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.address.str.lower().str.contains(\"москва\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение выбросов через дендрограмму"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно либо строить дендограмму по всем данным, либо взять выбросы (до 0.01 квантиля и полсе 0.99 квантиля)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы определить выбросы через дендограмму, необходимо проанализировать высоту, на которой происходит слияние кластеров. Выбросы обычно будут находиться на значительном расстоянии от остальных кластеров, что проявляется в виде длинных ветвей на дендр ограмме. Вот несколько шагов, которые помогут вам в этом процессе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "# Пример данных\n",
    "data = {\n",
    "    'Feature1': [1.0, 2.0, 1.5, 8.0, 8.5, 9.0],\n",
    "    'Feature2': [1.0, 1.5, 1.2, 8.0, 8.5, 9.0],\n",
    "    'Category': ['A', 'A', 'A', 'B', 'B', 'B']  # Категориальный признак\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Выбор числовых признаков\n",
    "numerical_data = df[['Feature1', 'Feature2']]\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Вычисление иерархической структуры для дендограммы\n",
    "linked = linkage(numerical_data_scaled, method='ward')\n",
    "\n",
    "# Построение дендограммы с использованием Plotly\n",
    "fig = ff.create_dendrogram(linked, orientation='bottom')\n",
    "fig.update_layout(title='Dendrogram for Numerical Features',\n",
    "                  xaxis_title='Distance',\n",
    "                  yaxis_title='Observations',\n",
    "                  width=800,\n",
    "                  height=600, \n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Обратите внимание на высоту, на которой происходит слияние кластеров. Если два кластера сливаются на большой высоте, это может указывать на наличие выбросов.\n",
    "- Выбросы будут представлены как отдельные ветви, которые соединяются с основным деревом на значительном расстоянии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение отрицательных значений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть временная переменная, то нуно посмотреть количество дублей, выбросов, пропусков в столбце во времени.  \n",
    "Мы так сможем определить есть ли зависимсть от времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про ИИ.  \n",
    "> Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть отрицательные значения там где их быть не должно.  \n",
    "> Обязательно приводим значения, самые характерные, чтобы дать ИИ болше информации.\n",
    "> И просим предложить причины этих отрицательных значений. Если видим важное, то используем для рекомендаций, выводов и замены отрицательных значений в предобработке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Очень важно, если у нас есть столбец, в котором не должно быть отрицательных значений, то нам нужно отдельно изучить положительные и отрицательные значения.  \n",
    "> И те и те посмотреть по категориям.  \n",
    "> И на основе этого изучения мы моежм заметить причины отрицательных значений.  \n",
    "> Например, в колонке стажа у нас очень много отрицательных значений и есть положительные значения.  \n",
    "> Мы отдельно посмотрели отрицательные значения и они в основном принадлежат работающим людям.  \n",
    "> А положительные пренадлежат пенсионерам.  \n",
    "> Важно и полоительные и отрицательные значения посмотреть их макс и мин.  \n",
    "> Вот мы для стажа посмотрели макси и мин и видим, что отрицательные значения похожи на реальные значения в годах.  \n",
    "> А вот положительные слишком большие, и далее мы поняли, что это данные в часах.  \n",
    "> В итоге у нас уже много предположений, которые помогут выяснить откуда появляются странные данные в этом столбце.  \n",
    "> К тому же мы можем попробовать заменить отрицательные значения, если у нас есть уверенность на основе анализа.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим отрицательные значения в каждом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_negative = pagri_data_tools.find_columns_with_negative_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Определяем в каких колонках не должно быть орицательных значений.  \n",
    "> Колонки в которых допустимы отрицательные значения удаляем из `series_negative`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Изучим отрицательные значения в разрезе категорий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Смотрим на все поля  \n",
    "> in_category_pct говорит о том сколько в этом значении категории изучаемых значений  \n",
    "> in_column_pct говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    "> total_count_pct помогает анализировать in_column_pct, так как мы видим сколько занимает это значение в общем\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> когда изучаем по категориям, то смотрим на diff_sum_pct, тут логика такая -  \n",
    "нам нужно сравнить количество строк с пропусками в каждой категории, учитывая размер этой категории.  \n",
    "То есть если у нас категории например дорогие квартиры и дешевые (категориальная переменная нарпимер категория стоимости)  \n",
    "и в них соотношение пропусков 1000 к 500, а общее соотношение групп 700 на 800, то явно отличается количество.  \n",
    "Поэтому мы смотрим на отличия, и если они существенны, то делаем вывод, что категория влияет на пропуски.  \n",
    "Иначе пишем, что влияние не обнаружено.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО - убедиться, что нет в ноутбуке `_gen_` (делаем ctrl+F и вбиваем `_gen_`)  \n",
    "ставим `_gen_` в том месте где хотим чтобы появились ячейки после работы в prep_dash  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_negative, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение нулевых значений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть временная переменная, то нуно посмотреть количество дублей, выбросов, пропусков в столбце во времени.  \n",
    "Мы так сможем определить есть ли зависимсть от времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помним, что важно выдвигать гипотезы и потом их проверять.   \n",
    "Например так  \n",
    "Выдвинем гипотезу, что 0 комнат у студий и однокомнатных.  \n",
    "Проверим гипотезу по полощади.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про ИИ.  \n",
    "> Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть нули там, гед их быть не должно.  \n",
    "> И просим предложить причины этих нулей. Если видим важное, то используем для рекомендаций, выводов и замены нулей в предобработке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим нулевые значения в каждом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_zeros = pagri_data_tools.find_columns_with_zeros_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na_in_both_columns = pagri_data_tools.check_zeros_in_both_columns(df, ['parks_around3000', 'ponds_around3000'])\n",
    "df_na_in_both_columns.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на нули в стоимости заказа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_dt</th>\n",
       "      <th>revenue</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2017-06-22 18:19:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17030528792926543083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>2017-07-07 15:54:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10281425020415612933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>2017-08-02 14:54:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>184148767273119549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5095</th>\n",
       "      <td>2017-08-09 14:48:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5603453646174104178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>2017-08-23 13:43:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5603453646174104178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                order_dt  revenue                   uid\n",
       "1802 2017-06-22 18:19:00     0.00  17030528792926543083\n",
       "2787 2017-07-07 15:54:00     0.00  10281425020415612933\n",
       "4783 2017-08-02 14:54:00     0.00    184148767273119549\n",
       "5095 2017-08-09 14:48:00     0.00   5603453646174104178\n",
       "5863 2017-08-23 13:43:00     0.00   5603453646174104178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_negative.revenue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим есть ли зависимость от пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2037345392173160982</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603453646174104178</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8277558335454815700</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927261749585088199</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570343171257035973</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883839899480223178</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184148767273119549</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10281425020415612933</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15254206642996645755</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973814017160376581</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      revenue\n",
       "uid                          \n",
       "2037345392173160982        12\n",
       "5603453646174104178         6\n",
       "8277558335454815700         6\n",
       "4927261749585088199         4\n",
       "5570343171257035973         4\n",
       "2883839899480223178         2\n",
       "184148767273119549          1\n",
       "10281425020415612933        1\n",
       "15254206642996645755        1\n",
       "14973814017160376581        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_negative.revenue.groupby('uid')[['revenue']].count().sort_values('revenue', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "\n",
    "- У пользователя с id 2037345392173160982 больше всего нулей в стоимости заказа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Определяем в каких колонках не должно быть нулевых значений.  \n",
    "> Колонки в которых допустимы нулевые значения удаляем из `series_negative`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dob_years           children  days_employed  dob_years educ...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_zeros = series_zeros.drop('children')\n",
    "series_zeros = series_zeros.loc[['rooms', 'airports_nearest']]\n",
    "series_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Изучим нулевые значения в разрезе категорий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> когда изучаем по категориям, то смотрим на diff_sum_pct, тут логика такая -  \n",
    "нам нужно сравнить количество строк с пропусками в каждой категории, учитывая размер этой категории.  \n",
    "То есть если у нас категории например дорогие квартиры и дешевые (категориальная переменная нарпимер категория стоимости)  \n",
    "и в них соотношение пропусков 1000 к 500, а общее соотношение групп 700 на 800, то явно отличается количество.  \n",
    "Поэтому мы смотрим на отличия, и если они существенны, то делаем вывод, что категория влияет на пропуски.  \n",
    "Иначе пишем, что влияние не обнаружено.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Смотрим на все поля  \n",
    "> in_category_pct говорит о том сколько в этом значении категории изучаемых значений  \n",
    "> in_column_pct говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    "> total_count_pct помогает анализировать in_column_pct, так как мы видим сколько занимает это значение в общем\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО - убедиться, что нет в ноутбуке `_gen_` (делаем ctrl+F и вбиваем `_gen_`)  \n",
    "ставим `_gen_` в том месте где хотим чтобы появились ячейки после работы в prep_dash  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строчку с созданием gen оставляем без is_dash, это для отчета,  \n",
    "И ниже пишем строчку с is_dash для создания dash app и потом ее удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, series_zeros, is_dash=True)\n",
    "pagri_dash.prep_dash(gen, \"/colab/pagri-projects/quarto/projects/housing-ads-investigation/housing_ads_investigation.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> После изучения данных у нас могут возникнуть вопросы по определенным значениям, это возможно не выбросы,  \n",
    "> мы просто хотим подробнее их изучить.  \n",
    "> Для этого создаем датафрейм с нужными значениями и помещаем его в `Series`,  \n",
    "> индекс это название колонки, в которой мы изучаем выброс.  \n",
    "> Далее отдаем этот `Series` в функцию `analyze_by_category_gen`.  \n",
    "> Нужно сделать специальную функцию для этого, чтобы не использовать `analyze_by_category_gen`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_series = pd.Series([df[df.col_for_check == value_for_check]], index=['col_for_check'])\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, check_series)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Также мы можем изучить любые столбцы (или часть столбцов) по категориям.  \n",
    "> То есть мы изучаем как распределены элементы по категориям\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_series = pd.Series([df[df.col_for_check == value_for_check]], index=['col_for_check'])\n",
    "gen = pagri_data_tools.analyze_by_category_gen(df, check_series)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сделать функцию определения выбросов на основе машинного обучения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Дополнительные моменты, которые стоит проверить и изучить\n",
    "\n",
    "- Проверить на сложные выбросы, типа у нас есть статус и возраст и мы видим что студент имеет возраст 60 лет, это реально, но уже подозрительно.\n",
    "  > Вот таких моментов может быть много, но нужно додуматься, чтобы найти такие комбинации, но это важно делать.\n",
    "- важно проверить на корректность данные, то есть смотрим по отдельности каждый столбец и изучаем мин, макс, и другие параметры, и\n",
    "  > думаем, это физически реально. И особенно, когда у нас несколько связаных параметров, нет ли между ними противоречия.  \n",
    "  > Например, у нас есть дата показа рекламы и есть дата создания рекламы, естественно создание должно быть раньше, это нужно проверить.\n",
    "- Проверяем данные ошибки\n",
    "  > Ошибки которые не являются дублями, пропусками или выбросами.  \n",
    "  > Это сложно сделать, хотя бы заметить явные ошибки\n",
    "- Проверить на ошибки согласованности\n",
    "  > Например, у нас пользователь с одним ай ди имеет разные имена.\n",
    "  > `display(df.groupby('name')['age'].nunique())`\n",
    "- вообще нужно придумать разные проверки для колонок, особенно связанных. И провести эту проверку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Из наблюдений собираем важные выводы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы собрать все наблюдения используем это  \n",
    "нужно поставить `_pagristart_` где начало и `_pagriend_` где конец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем удалить метки `_pagristart_` и `_pagriend_` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.collect_observations(notebook_path, '/home/pagri/git_repos/pagri-projects/quarto/projects/prospective_tariff_for_telecom/temp_for_report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут помещаем все наблюдения про диапазоны столбцов, основные диапазон и медианы с модами.  \n",
    "Чтобы в конце скопировать отсюда и составить уже общий вывод.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-collect",
   "metadata": {},
   "source": [
    "> Принимаем решение, как именно мы будем проводить обработку, почему именно так, \\*зафиксировать рекомендации.  \n",
    "> То есть отвечаем на вопрос, что будем делать с выбросами, что будем делать с null.  \n",
    "> Будет идеально если тут зафиксировать рекомендации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточный вывод**\n",
    "\n",
    ">\n",
    "\n",
    "- **children** Присутствует 47 отрицательных значений с \"-1\", а также аномалия в виде 20 детей ...\n",
    "- **days_employed** Большая часть данных стобца со знаком \"-\". Однако, эти данные представляют из себя 84% всей выборки. ... будут заменены на .. исходя из определенного критерия, который будет описан далее.\n",
    "  > - Причины пропущенных значений в столбцах **days_employed** и **income**:\n",
    "  >   - Во-первых, это может быть из-за неправильной выгрузки данных. Оставим это предположение до того момента, пока не убедимся в неверности других предположений.**Наиболее вероятно**\n",
    "  >   - Во-вторых, одной из гипотез было предположение об отсутствии трудового опыта у данной части выборки. Однако, если распределение по возрасту в данной группе равномерное по всем возрастам выборки. Также большая доля этой части выборки трудоустроена. **Гипотеза не подтверждена**\n",
    "  >   - В-третьих, возможно, что эта часть выборки не имеет официального трудоустройства. Данная гипотеза вызывает сомнение в связи с тем, что при наличии достаточно большого стажа работы у представителей выборки у ее представителей нет официального трудового стажа. К тому же 18.9% данной выборки являются госслужащими. **Гипотез не подтверждена**\n",
    "- **age** .. 0 возраст у 101 человека.\n",
    "- **education & education_id** Необходимо будет привести данную категорийнуй переменную к общему виду. Избавиться от разного регистра. Но можно не тратить на это время и использовать следующий столбец **education_id**. Это позволит использовать меньше памяти и не повлияет на качество анализа.\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Удалять значения нужно по одной колонке.  \n",
    "Чтобы контролировать скоько занчений мы должны удалить и сколько удалили.  \n",
    "Иначе, если мы будем удалять сразу в нескольких полях, то мы не сможем точно убедиться, что не удалили лишние значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "помним, что когда мы удаляем записи  \n",
    "`df = df[df.column > 0]`\n",
    "то удаляются `na`  \n",
    "поэтому нужно делать так  \n",
    "`df = df[~(df.column <= 0)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу записываем в файл что заменили и что удалили для промежуточного вывода.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для некоторых пропущенных значений можно предположить логичную замену. Например, если человек не указал число балконов — скорее всего, их нет.   \n",
    "Такие пропуски правильно заменить на 0. Для других типов данных нет подходящего значения на замену.   \n",
    "В этом случае правильно оставить эти значения пустыми. Отсутствие значения — тоже важный сигнал, который не нужно прятать;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно, когда удаляем строки, то делаем сброс индекса\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про ИИ  \n",
    "> Когда мы проводим предобработку данных, то первый вопрос мы себе задать следующий\n",
    "> Какава вероятнсоть, что это является истиной? Если вероятнсоть ниже 60 прцоентов, то это делать не стоти и может лучше оставить как есть или не трогать этот столбец.  \n",
    "> Например, у нас дубли или отрицательные значеия и мы выдвинули гипотезу, что это просто неправильный знак и хотим взять модель числа.  \n",
    "> Но если мы подумаем, а высокая ли вероятность, что число просто с неверным знаком, то вероятнсот этого низкая.  \n",
    "> Поэтому это делать не нужно.  \n",
    "> Другое дело у нас датафрейме 1 прцоент полных дублей и при этом у нас есть достаточно точные колонки типа зарплаты с точностью до рублей или стаж в днях.  \n",
    "> Вот тут мы можем с высокой вероятностью утверждать, что это дубли, так как мало вероятно что будет две записи настолько точно совпадать.  \n",
    "> Поэтому сначала думаем насколько вероятна та гипотеза, которую мы выдвинули и хотим по ней изменить наши данные.  \n",
    "> Тут лучше придерживаться правила не навреди.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Когда удаляем значения из категориальных столбцов pandas, и в этом столбце нет больше таких занчений, которые удалил.  \n",
    "> То нужно удалить это значение из категории\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.gender == 'XNA'].index, inplace=True)\n",
    "df['gender'] = df['gender'].cat.remove_unused_categories()\n",
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительная фильтрация данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас датасет за год, например, и первый или последний месяц неполные, то их лучше выбрасить, если мы будем  \n",
    "> расчитывать месячные метрики.  \n",
    "> Но сначала конечно нужно проанализировать столбцы без обрезания, чтобы убедиться, что там нет ничего необычного.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖЖО  \n",
    "Посмотреть насколько репрезентативные данные за все периоды.  \n",
    "Если у нас данные по годам, например, то посмотреть возможно до определенного года данных мало.  \n",
    "Или картина меняется в какой-то момент (причем это может быть не связано с данными, а просто с изменением разных факторов).\n",
    "Желательно либо разделить датафрейма на несколько, либо отбросить нерелевантные периоды.  \n",
    "Так как важно, чтобы во время анализа данные были репрезентативными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные до 90-х годов несущественны для анализа, поскольку занимают ничтожную часть от последующих данных, в дальнейшем мы не будем использовать их для исследования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только нужные столбцы для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Крайне маленький процент игр выпускался в период с 1980 до ~1994. Потому в рамках анализа мы не будем брать этот период для сравнения. Пик выпуска игр приходится на 2007-2011 год."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сохраним исходный датафрейм в переменную df_origin, чтобы была возможность вернуться к нему\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Удаляем ненужные столбцы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['col1', 'col2'], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Думаем, какие колонки нам нужны, выбираем только их для дальнейшей работы.\n",
    "  > Остальные убираем в другой датасет.\n",
    "- Важно после изученя данных сначала убрать не нужные столбцы, а потом уже заниматься преобразованием (удалением пропусков и выбросов).\n",
    "  > Думаем прежде чем удалять строки, так как возможно лучше удалить столбец и строки удалять будет не нужно.\n",
    "- Пишем почему выбираем определенные столбцы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка выбросов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем про нулевые значения и отрицательный.  \n",
    "> В столбцах, где их быть не должно, они являются выбросами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> С обработкай нулевых и отрицательных значений нужно быть внимательным.  \n",
    "> Нужно сначала хорошо подумать, откуда могло это появиться,  \n",
    "> тут поможет анализ этих значений в предыдущей главе.  \n",
    "> Думаем откуад появилось отрицательное или нулевое занчение,  \n",
    "> и если у нас есть гипотезы, которые похожи на правду (мы думаем что вероятность их истины больше 60%),  \n",
    "> то мы обрабатываем их исходя из гипотезы.  \n",
    "> Например, -1 часто бывает как отсутсвие чего-то, то есть мы в зависимости от контекста можем заменить его на 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно каждый раз, когда мы удаляем что-то из датафрейма, то убедиться, что мы удалили столько строк, сколько и хотели.  \n",
    "> Для этого выводим размер датафрейма до удаления.  \n",
    "> Смотрим сколько строк мы хотим удалить.  \n",
    "> Далее не сохраняя в датафрейм удаляем строки и смотрим верный ли итоговый размер.  \n",
    "> Если все верно, то удаляем уже с сохранением.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем, что выбросы мы также можем заменять на медианные значения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим где у нас отрицательные значения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_negative_value_in_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21478"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[df.children >= 0]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим где у нас нулевые значения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_zeros_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обрабатываем нулевые и отрицательные значения, затем снова проверяем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [negative]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pagri_data_tools.check_negative_value_in_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [zeros]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pagri_data_tools.check_zeros_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Также нужно обработать выбросы, которые мы обнаружили при изучении данных.  \n",
    "> Это могут быть любые колонки со значениями, которые не моут быть в реальности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Нужно сначала обработать выбросы, а потом уже обрабатываться пропуски.  \n",
    "> Так как мы заоплняем пропуски, учитывая значения в колонке, которые возможно мы потом удалим.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Помним про нулевые и отрицательные значения\n",
    "- Нулевые значения, отрицательные значения являются выбросами, если они не могут быть у этой колонки.\n",
    "- Очень важно понимать, когда выброс можно отбросить и он реально выброс и когда нельзя.\n",
    "  > Опираемся на физику параметра, думаем это значение физически возможно.\n",
    "- Также выброс может казаться выбрасом, но для бизнеса это не выброс.\n",
    "  > Например у нас суммы покупок и одна покупка сильно выделяется, а там просто человек купил супе дорогой каньяк, например.\n",
    "- Когда хотим обрезать выбросы, то думаем, какой порог может быть физически реальным и по нему режем, а не просто так берем какой-то перцентиль.\n",
    "  > Всегда нужно думать с точки зрения физического возможного значения параметра и по нему резать (подумать а какое значение может быть максимально реальным и по нему обрезать)\n",
    "- Если мы имеем дело со строгой отчестностью, то выбросы убирать нельзя, нужно разобраться откуда они.\n",
    "- Если мы не можем с увереностью сказать, что это выброс, то нам не стоит его выкидывать, но работать как то нужно с ними,\n",
    "  > тогда, логарифмируем (лучше использовать натуральный логарифм) эту колонку и работаем с такими значениями (тогда выбросы сожмуться).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> После удаления выбрасов, можно снова выполнить пункт про изучение выбрасов, так как выбросы могут появиться новые,  \n",
    "> если у нас например выбросы были слишком нереальные значения, когда мы от них избавимся, будет лучше видно другое\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пропусков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "категориальные переменные с пропусков заменяем на что-то типа другое  \n",
    "Даже если пропусков много.  \n",
    "Это важно, так как когда смотрим на колонки с пропуском, то можем забыть, что определенные колонки категориальные,  \n",
    "и на них не распрастраняется правило, что больше 20 процентов пропусков не трогаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно помнить, что пропус может быть вызван тем, что во измежании дублирования строк, при созаднии сводной таблицы,  \n",
    "> занчения не повторяются, а если потом эту таблицу куда то отправить, то там эти пропуски могут стать null  \n",
    "> Поэтому сначала смотрим последовательно на значения и думаем, не может ли это быть таким случаем.  \n",
    "> Это могут быть даты, которые идут подряд и меду ними пропуски.  \n",
    "> Или список названий четко по порядоку и между ними пропуски, это может быть вызвано как раз последствием создания сводной таблицы.  \n",
    "> В пандас это видно, когда мы группируем строки, у нас в индексе дубли не пишуться, но пандас занчет, что там есть занчения,  \n",
    "> но после импорта куда-то там могут не продублироваться значения и возникнут пропуски.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Прежде чем обрабатывать пропуски, нужно подумать а можем ли мы их заменить исходя из имеющихся столбцов.  \n",
    "> Например, у нас есть столбец с пропусками возраст, и есть стаж,  \n",
    "> мы можем возраст заменить так стаж + 18 + 5  \n",
    "> Аналогично другие ситуации нужно сообразить как можно заменить пропуски.  \n",
    "> И только если нет идей, тогда уже заменяем на медиану, например, по группам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас в данных есть временные ряды, то можно использовать заполнение соседними значениями «из прошлого». Когда у вас есть привязка ко времени и один из параметров присутствует в данных с меньшей частотой, чем другие, тогда применяется fillna() с параметром 'method'='ffill'. Здесь мы справедливо предполагаем, что отсутствующие значения стоит заполнять значениями «из прошлого»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_missed_value_in_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset='name')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим прпоуски в категориальных переменных.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рейтинге заменим пропуски на значение 'не указано'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].cat.add_categories(['не указано'])\n",
    "df['rating'] = df['rating'].fillna('не указано')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rating.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если решии заменять прпоуски значениями, учитывая категории, то нужно убедиться, что размер этих категорий достаточный.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим размеры групп, если заменять внутри этих групп\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = ['education', 'family_status', 'gender', 'income_type']\n",
    "value_column = 'total_income'\n",
    "pagri_data_tools.check_group_count(df, category_columns, value_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Заполним пропуски в группах от 10 элементов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[value_column] = pagri_data_tools.fill_na_with_function_by_categories(df, category_columns, value_column, func='median', minimal_group_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверим сколько у нас осталось пропусков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_missed_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если пропуски остались, то убираем какую-нибудь категорию и повторяем.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-general",
   "metadata": {},
   "source": [
    "> что-то изменили - > посмотрели не изменилось ли количество дублей  \n",
    "> `check_duplicated`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Увидели пропуск — подумайте, нормально ли это. Сколько вообще пропусков может быть в этом столбце?  \n",
    "> К примеру, в списке с электронными адресами пользователей, согласных на рассылку, будет много пропусков. Далеко не все предоставляют email.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно использвоать такой подход\n",
    "\n",
    "- если количество пропусков меньше 5 процентов, то удаляем (лучше меньше 1 процента)\n",
    "- если количество пропусков от 5 до 20 процентов, то подбираем чем заменить, удалять не стоит\n",
    "- если больше 20 процентов, то не трогаем, так как исказим\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Но оставляя пропуски, нам нужно помнить, что мы не можем по этим полям считать корреляцию с другими,  \n",
    "> так как пропуски испортят расчет коэффициента корреляции. Аналогично другие метрики могут считаться некорректно.  \n",
    "> Поэтому, если мы будем считать показатели по столбцу с пропусками, то их нужно либо убирать, либо этот столбец не использовать для расчетов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для категориальных переменных оставлять пропуски нельзя, так как мы скорее всего будем группировать по ним и смотреть разные разрезы.  \n",
    "> Поэтому в худшем случае, если не можем ничем заменить, и нет уверености, что пропуск можно заполнить пустой строкой (если значения физически нет),  \n",
    "> то создаем категорию например `other` из пропусков.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас пропуски в категориальной переменной и есть разные периоды или просто данные разбиты на части (то есть эта категориальная переменная повторяется),  \n",
    "> то мы можем взять ещё какую-нибудь переменную, у которой нет пропусков, где пропуски у первой переменной и далее посмотреть другие периоды  \n",
    "> Таким образом у нас будет предыдущий период, где будет занчение второй переменной и первой и если в нескольких периодах они одинаковые, то мы можем  \n",
    "> заполнить и пропуски этим значением.  \n",
    "> Ещё раз схема такая - берем 2 поля одно с пропусками, другое без, получаем новую таблицу, в этой таблице оставляем только униклаьные значения в поле без пропусков,  \n",
    "> по этому полю будем джойнить. Далее в основнйо таблице дропаем описание и создаем новое описание из таблицы справочника.  \n",
    "> `fill_missing_values_using_helper_column`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.fill_missing_values_using_helper_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Заполняем пропуски учитвая категории  \n",
    "> `fill_na_with_function_by_categories`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно следить, чтобы категории, по которым будем заполнять пропуски были обработаны.  \n",
    "> Если у нас в категориальной переменной есть значение с большой буквы и с маленькой, то это одна категория,  \n",
    "> но замена будет идити по двум, чтобы такого не было, нужно сначала обработать категориальную переменную.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Также важно, чтобы в группах по которым мы будем считать значение для заополения было достаточно значений  \n",
    "> для выбранной функции.  \n",
    "> Например, если мы решили брать среднее, а в группе у нас 5 значений, то среди них может быть выброс и наше среднее будет некорректно.  \n",
    "> Лучше в такой ситуации брать группу побольше для этих микрогрупп.  \n",
    "> В идеале группы должны быть от 30 элементов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно посмотреть какой процент группах без значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby(['education', 'family_status', 'gender', 'income_type'])['total_income'].sum()\n",
    "(temp == 0).sum() * 100 / temp.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.fill_na_with_function_by_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сделать функцию заполнения пропусков с помощью машинного обучения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> После удаления пропусков и выбросов желательно проверить какой прцоент строк мы удалили.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дубликатов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Все значения в колонках во всех таблицах нужно привести к нижнему регистру и по возможности к одному языку,  \n",
    "> для перевода к одному языку можно использовать словарь, с помощью которого изменить неправильный язык  \n",
    "> Это нужно, чтобы когда будем соединять таблицы, у нас условие соеденения правильно сравнивало равные значения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно посмотреть снвоа на дубликаты после обработки пропусков.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `check_duplicated`  \n",
    "> `find_columns_with_duplicates`  \n",
    "> `check_duplicated_combinations_gen`  \n",
    "> `get_duplicates_value_proportion_by_category`  \n",
    "> В первую функцию можно передавать весь датафрейм и можно выбирать нужные столбцы для проверки на дубли и передавать их.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.check_duplicated_value_in_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.find_columns_with_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Заполним пропуски в группах от 10 элементов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[value_column] = pagri_data_tools.fill_na_with_function_by_categories(df, category_columns, value_column, func='median', minimal_group_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_income</th>\n",
       "      <td>63 (0.3%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 missed\n",
       "total_income  63 (0.3%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pagri_data_tools.check_missed_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть строки, которые нужно объеденить, то делаем так"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объеденим задублированные строки для игры Madden NFL 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>genre</th>\n",
       "      <th>na_sales</th>\n",
       "      <th>eu_sales</th>\n",
       "      <th>jp_sales</th>\n",
       "      <th>other_sales</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>PC</td>\n",
       "      <td>2,005.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>PC</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>82.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>X360</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>83.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Need for Speed: Most Wanted</td>\n",
       "      <td>X360</td>\n",
       "      <td>2,005.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>83.00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name platform  year_of_release   genre  \\\n",
       "604                  Madden NFL 13      PS3         2,012.00  Sports   \n",
       "16230                Madden NFL 13      PS3         2,012.00  Sports   \n",
       "5972   Need for Speed: Most Wanted       PC         2,005.00  Racing   \n",
       "11715  Need for Speed: Most Wanted       PC         2,012.00  Racing   \n",
       "1190   Need for Speed: Most Wanted     X360         2,012.00  Racing   \n",
       "1591   Need for Speed: Most Wanted     X360         2,005.00  Racing   \n",
       "\n",
       "       na_sales  eu_sales  jp_sales  other_sales  critic_score  user_score  \\\n",
       "604        2.11      0.22      0.00         0.23         83.00        5.50   \n",
       "16230      0.00      0.01      0.00         0.00         83.00        5.50   \n",
       "5972       0.02      0.23      0.00         0.04         82.00        8.50   \n",
       "11715      0.00      0.06      0.00         0.02         82.00        8.50   \n",
       "1190       0.62      0.78      0.01         0.15         83.00        8.50   \n",
       "1591       1.00      0.13      0.02         0.10         83.00        8.50   \n",
       "\n",
       "      rating  \n",
       "604        E  \n",
       "16230      E  \n",
       "5972       T  \n",
       "11715      T  \n",
       "1190       T  \n",
       "1591       T  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df[['name', 'platform', 'genre']].duplicated(keep=False)].sort_values(by=['name', 'platform', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_combine = [604, 16230]\n",
    "\n",
    "# Группируем строки по индексам и объединяем значения\n",
    "combined_row = df.loc[indices_to_combine].groupby(['name', 'platform', 'genre'], as_index=False, observed=True).agg({\n",
    "    'na_sales': 'sum',\n",
    "    'eu_sales': 'sum',\n",
    "    'other_sales': 'sum',\n",
    "    'jp_sales': 'sum',\n",
    "    'critic_score': 'first',\n",
    "    'user_score': 'first',\n",
    "    'rating': 'first',\n",
    "    'year_of_release': 'first'\n",
    "})\n",
    "\n",
    "# Обновляем DataFrame, удаляя объединенные строки и добавляя новую\n",
    "df = pd.concat([df.drop(indices_to_combine), combined_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16442"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>genre</th>\n",
       "      <th>na_sales</th>\n",
       "      <th>eu_sales</th>\n",
       "      <th>jp_sales</th>\n",
       "      <th>other_sales</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>user_score</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16441</th>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2,012.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>83.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name platform  year_of_release   genre  na_sales  eu_sales  \\\n",
       "16441  Madden NFL 13      PS3         2,012.00  Sports      2.11      0.23   \n",
       "\n",
       "       jp_sales  other_sales  critic_score  user_score rating  \n",
       "16441      0.00         0.23         83.00        5.50      E  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строки правильно объеденились."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если есть дубли, и мы считаем, что это не дубли, а просто разделились данные,  \n",
    "> то объединеняем записи, которые имеют одинаковые значения ключевых признаков.  \n",
    "> `merge_duplicates`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.merge_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если мы не уверены, что дубль является дублем и не хотим удалять, то можно использовать  \n",
    "> маркировку дублей, можно добавить новую колонку, которая будет содержать информацию о том,  \n",
    "> является ли строка дубликатом или нет.  \n",
    "> `df['is_duplicate'] = df.duplicated()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_duplicate'] = df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Подумать, а можем ли мы обогатить данные, что разделит дубли.  \n",
    "> То есть возможно в наших данных нет какого-то столбца, и тогда дубли уже не будут дублями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если уверены, что это дубли, то удаляем их  \n",
    "> `df.drop_duplicates()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приведение данных к удобной форме\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть переменная в которой значения - да, нет.  \n",
    "То можно заменить значения на более удобные.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, у нас столбец, который указывает является ли точка сетевой.   \n",
    "Можно заменить значения и далее на графиках можно будет писать - тип точки  \n",
    "Заменим \"да\" и \"нет\" на \"сетевая\" и \"несетевая\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим значения в столбцах на более удобные\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.debt = df.debt.apply(lambda x: 'есть' if x == '1' else 'нет').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_apartment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_apartment = df.is_apartment.astype(str).map({'True': 'да', 'False': 'нет'}).astype('category')\n",
    "df.is_apartment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "смотрим все переменные во всех датафрейма и приводим одинаковые метрики к одной размерности.  \n",
    "И размерность делаем удобной для дальнейшего анализа.  \n",
    "На пример, если у нас мегабайты и их больше 1000, то нужно сделать гигабайты (и важно в названии поля добавить _gb)  \n",
    "Аналогично для всех метрик, суть в том, что если значение в поле больше 1000 и мы можем записать его в другом измерении, то делаем это.    \n",
    "То же самое с секундами, минутами, часами и так далее.  \n",
    "Думаем какая точность нам нужна и меняем размерность.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас в столбце, например, стаж данные в днях, то это нужно преобразовать в года.  \n",
    "> Также если у нас в других столбцах данные в формате, который нужно изменить для лучшего анализа, то делаем это.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Округлим значения в поле дохода до целого.  \n",
    "> Целая часть выглядит реальной. А с дробной частью нужно разбираться почему стоько знаков.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если мы хотим перевесит тип float в int, то нужно проверить нет ли у нас дробных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "этот способ na посчитает ка дробные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что в столбце нет дробных чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.critic_score % 1 != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>family_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>высшее</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>253876</td>\n",
       "      <td>покупка жилья</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  age education    family_status gender income_type debt  \\\n",
       "0         1   42    высшее  женат / замужем      F   сотрудник    0   \n",
       "\n",
       "   total_income        purpose  \n",
       "0        253876  покупка жилья  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.total_income = df.total_income.astype('int32')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть похожие числовые переменные в разных размерностях, то приводим их к одной размерности, чтобы сравнивать.  \n",
    "Например оценка пользователей в 10 бальной системе и оценка критиков в 100 бальной системе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим сколько у нас людей с полом XNA осталось\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.gender == 'XNA').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим кто это\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>family_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10701</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>неоконченное высшее</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>XNA</td>\n",
       "      <td>компаньон</td>\n",
       "      <td>0</td>\n",
       "      <td>203905</td>\n",
       "      <td>покупка недвижимости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  age            education     family_status gender  \\\n",
       "10701         0   24  неоконченное высшее  гражданский брак    XNA   \n",
       "\n",
       "      income_type debt  total_income               purpose  \n",
       "10701   компаньон    0        203905  покупка недвижимости  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df.gender == 'XNA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Всего 1 человек. И мы не можем идентифицировать его пол.  \n",
    "> Удалим, чтобы не мешало анализировать графики.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.drop(df[df.gender == 'XNA'].index, inplace=True)\n",
    "df['gender'] = df['gender'].cat.remove_unused_categories()\n",
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "год нужно перевести в категориальный тип  \n",
    "Но важно сначала перевести в строку, а потом в категориальный тип, иначе plotly будет воспринимать как continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем год выпуска в категориальный тип, чтобы анализировать в разрезе года."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что в столбце нет дробных чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.year_of_release % 1 != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сделать упорядоченную категориальную переменную, нужно делать так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_years = pd.CategoricalDtype(categories=[str(int(year)) for year in sorted(df['year_of_release'].unique())], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_score</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>region</th>\n",
       "      <th>sales</th>\n",
       "      <th>critic_score_cat</th>\n",
       "      <th>user_score_cat</th>\n",
       "      <th>sales_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>E</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2006</td>\n",
       "      <td>Северная Америка</td>\n",
       "      <td>41.36</td>\n",
       "      <td>средняя</td>\n",
       "      <td>средняя</td>\n",
       "      <td>много</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_score  critic_score   genre        name platform rating  user_score  \\\n",
       "0      78.00         76.00  Sports  Wii Sports      Wii      E       80.00   \n",
       "\n",
       "  year_of_release            region  sales critic_score_cat user_score_cat  \\\n",
       "0            2006  Северная Америка  41.36          средняя        средняя   \n",
       "\n",
       "  sales_cat  \n",
       "0     много  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.year_of_release = df.year_of_release.astype(int).astype(str).astype(ordered_years)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть названия и в них есть подобные названия, то лучше их привести к одному названию, например, у нас есть сетевые рестораны, которые называются по разному  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_mapping = {\n",
    "    'kfc': 'kfc'\n",
    "    , 'кфс': 'kfc'\n",
    "    , 'кфц': 'kfc'\n",
    "    , 'макдоналдс': 'mcdonalds'\n",
    "    , 'старбакс': 'starbucks'\n",
    "    , 'starbucks': 'starbucks'\n",
    "    , 'шоколадница': 'шоколадница'\n",
    "    , 'бургер кинг': 'burger king'\n",
    "    , 'burger king': 'burger king'\n",
    "    , 'burgerking': 'burger king'\n",
    "    , 'domino-s': 'dominos pizza'\n",
    "    , 'dominos pizza': 'dominos pizza'\n",
    "    , 'домино\\'с': 'dominos pizza'\n",
    "    , 'domino s': 'dominos pizza'\n",
    "    , 'доминос': 'dominos pizza'\n",
    "    , 'крошка картошка': 'крошка картошка'\n",
    "    , 'крошка-картошка': 'крошка картошка'\n",
    "    , 'теремок': 'теремок'\n",
    "    , 'милти': 'милти'\n",
    "    , 'суши wok': 'суши wok'\n",
    "    , 'папа джонс': 'папа джонс'\n",
    "    , 'papa johns': 'папа джонс'\n",
    "    , 'додо пицца': 'додо пицца'\n",
    "    , 'додо-пицца': 'додо пицца'\n",
    "    , 'якитория': 'якитория'\n",
    "    , 'тануки': 'тануки'\n",
    "    , 'subway': 'subway'\n",
    "    , 'сабвай': 'subway'\n",
    "}\n",
    "def standardize_restaurant_name(name):\n",
    "    for key in restaurant_mapping:\n",
    "        if key in name.lower():  # Приводим к нижнему регистру для сравнения\n",
    "            return restaurant_mapping[key]\n",
    "    return name  # Если не найдено, возвращаем оригинальное название\n",
    "df['standartized_name'] = df.name.apply(standardize_restaurant_name).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы собрать все наблюдения используем это  \n",
    "нужно поставить `_pagristart_` где начало и `_pagriend_` где конец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем удалить метки `_pagristart_` и `_pagriend_` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.collect_observations(notebook_path, '/home/pagri/git_repos/pagri-projects/quarto/projects/prospective_tariff_for_telecom/temp_for_report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> пишем как обработали данные, например\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Удалили колонки с id образования и семейного статуса, так как нам для графиков лучше подойдут названия, а не id.\n",
    "- Колонка со стажем имеет совершенно некорректные данные. Чтобы не внести искажение в анализ, удалим эту колонку.\n",
    "- Удалили отрицательные значения в колонке с количеством детей, которые составляли 0,2% от общего количества записей в данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обогащение данных и создание новых переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обогащение данных из внешних источников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нам нужно добавить к нашим данным данные из таблиц из внешних источников, то делаем это здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсинг внешних источников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "описываем процесс парсинга  \n",
    "описываем источники и переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание новых числовых переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала пишем все имеющиеся колонки ИИ и просим написать какие новые числовые переменные можно создать.  \n",
    "Если таблиц много, то идем по одной таблице, закончили с одной идем к следующей.  \n",
    "Далее в конце можно спросить какие новые числовые можно создать, учитывая все таблицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу пишем в файл какие новые переменные создали для промежуточного вывода.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новые числовые переменные часто это коэффициенты.  \n",
    "Нужно подумать из каких имеющихся числовых переменных можно создать коэффициенты.  \n",
    "То есть это отношение одной переменной числовой к другой. Вот нужно подумать какие такие отношения нам могут помочь в анализе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также новая числовая переменная может быть средним из других колонок и другие статистические функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также новые переменные могут быть, например, расчеты, основанные на других переменных, такие как разница, процентное изменение и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Числовые переменные создаем не только для дальнейшего их анализа.  \n",
    "Создание числовой переменной может помочь создать новую категориальную переменную.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например есть у нас расстояние до центра в метрах.  \n",
    "Мы создаем новую числовую переменную расстояние в км.  \n",
    "Далее строим график зависимости расстояния и цены.  \n",
    "И определеяем где цена резко меняется и получаем границу для создания новой категориальной переменной, в которой будет центр и остальное.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим переменную соотношение жилой и общей площади"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['living_total_ratio'] = round(df['living_area'] / df['total_area'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"display: flex; justify-content: flex-start; align-items: flex-end;\">\n",
       "            <style type=\"text/css\">\n",
       "#T_a9dbc caption {\n",
       "  font-size: 16px;\n",
       "  text-align: left;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_a9dbc_row0_col0, #T_a9dbc_row0_col1, #T_a9dbc_row0_col2, #T_a9dbc_row0_col3, #T_a9dbc_row0_col4, #T_a9dbc_row0_col5, #T_a9dbc_row0_col6, #T_a9dbc_row0_col7, #T_a9dbc_row0_col8, #T_a9dbc_row0_col9, #T_a9dbc_row1_col0, #T_a9dbc_row1_col1, #T_a9dbc_row1_col2, #T_a9dbc_row1_col3, #T_a9dbc_row1_col4, #T_a9dbc_row1_col5, #T_a9dbc_row1_col6, #T_a9dbc_row1_col7, #T_a9dbc_row1_col8, #T_a9dbc_row1_col9, #T_a9dbc_row2_col0, #T_a9dbc_row2_col1, #T_a9dbc_row2_col2, #T_a9dbc_row2_col3, #T_a9dbc_row2_col4, #T_a9dbc_row2_col5, #T_a9dbc_row2_col6, #T_a9dbc_row2_col7, #T_a9dbc_row2_col8, #T_a9dbc_row2_col9, #T_a9dbc_row3_col0, #T_a9dbc_row3_col1, #T_a9dbc_row3_col2, #T_a9dbc_row3_col3, #T_a9dbc_row3_col4, #T_a9dbc_row3_col5, #T_a9dbc_row3_col6, #T_a9dbc_row3_col7, #T_a9dbc_row3_col8, #T_a9dbc_row3_col9, #T_a9dbc_row4_col0, #T_a9dbc_row4_col1, #T_a9dbc_row4_col2, #T_a9dbc_row4_col3, #T_a9dbc_row4_col4, #T_a9dbc_row4_col5, #T_a9dbc_row4_col6, #T_a9dbc_row4_col7, #T_a9dbc_row4_col8, #T_a9dbc_row4_col9, #T_a9dbc_row5_col0, #T_a9dbc_row5_col1, #T_a9dbc_row5_col2, #T_a9dbc_row5_col3, #T_a9dbc_row5_col4, #T_a9dbc_row5_col5, #T_a9dbc_row5_col6, #T_a9dbc_row5_col7, #T_a9dbc_row5_col8, #T_a9dbc_row5_col9, #T_a9dbc_row6_col0, #T_a9dbc_row6_col1, #T_a9dbc_row6_col2, #T_a9dbc_row6_col3, #T_a9dbc_row6_col4, #T_a9dbc_row6_col5, #T_a9dbc_row6_col6, #T_a9dbc_row6_col7, #T_a9dbc_row6_col8, #T_a9dbc_row6_col9 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9dbc\">\n",
       "  <caption>living_total_ratio</caption>\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row0_col0\" class=\"data row0 col0\" >Values</td>\n",
       "      <td id=\"T_a9dbc_row0_col1\" class=\"data row0 col1\" >21 796 (92%)</td>\n",
       "      <td id=\"T_a9dbc_row0_col2\" class=\"data row0 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row0_col3\" class=\"data row0 col3\" >Max</td>\n",
       "      <td id=\"T_a9dbc_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "      <td id=\"T_a9dbc_row0_col5\" class=\"data row0 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row0_col6\" class=\"data row0 col6\" >Avg</td>\n",
       "      <td id=\"T_a9dbc_row0_col7\" class=\"data row0 col7\" >0.56</td>\n",
       "      <td id=\"T_a9dbc_row0_col8\" class=\"data row0 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row0_col9\" class=\"data row0 col9\" >0.56 (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row1_col0\" class=\"data row1 col0\" >Missing</td>\n",
       "      <td id=\"T_a9dbc_row1_col1\" class=\"data row1 col1\" >1 903 (8%)</td>\n",
       "      <td id=\"T_a9dbc_row1_col2\" class=\"data row1 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row1_col3\" class=\"data row1 col3\" >95%</td>\n",
       "      <td id=\"T_a9dbc_row1_col4\" class=\"data row1 col4\" >0.73</td>\n",
       "      <td id=\"T_a9dbc_row1_col5\" class=\"data row1 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row1_col6\" class=\"data row1 col6\" >Mode</td>\n",
       "      <td id=\"T_a9dbc_row1_col7\" class=\"data row1 col7\" >0.56</td>\n",
       "      <td id=\"T_a9dbc_row1_col8\" class=\"data row1 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row1_col9\" class=\"data row1 col9\" >0.55 (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row2_col0\" class=\"data row2 col0\" >Distinct</td>\n",
       "      <td id=\"T_a9dbc_row2_col1\" class=\"data row2 col1\" >91 (<1%)</td>\n",
       "      <td id=\"T_a9dbc_row2_col2\" class=\"data row2 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row2_col3\" class=\"data row2 col3\" >75%</td>\n",
       "      <td id=\"T_a9dbc_row2_col4\" class=\"data row2 col4\" >0.64</td>\n",
       "      <td id=\"T_a9dbc_row2_col5\" class=\"data row2 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row2_col6\" class=\"data row2 col6\" >Range</td>\n",
       "      <td id=\"T_a9dbc_row2_col7\" class=\"data row2 col7\" >0.98</td>\n",
       "      <td id=\"T_a9dbc_row2_col8\" class=\"data row2 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row2_col9\" class=\"data row2 col9\" >0.6 (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row3_col0\" class=\"data row3 col0\" >Duplicates</td>\n",
       "      <td id=\"T_a9dbc_row3_col1\" class=\"data row3 col1\" >23 607 (99.6%)</td>\n",
       "      <td id=\"T_a9dbc_row3_col2\" class=\"data row3 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row3_col3\" class=\"data row3 col3\" >Median</td>\n",
       "      <td id=\"T_a9dbc_row3_col4\" class=\"data row3 col4\" >0.57</td>\n",
       "      <td id=\"T_a9dbc_row3_col5\" class=\"data row3 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row3_col6\" class=\"data row3 col6\" >iQR</td>\n",
       "      <td id=\"T_a9dbc_row3_col7\" class=\"data row3 col7\" >0.14</td>\n",
       "      <td id=\"T_a9dbc_row3_col8\" class=\"data row3 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row3_col9\" class=\"data row3 col9\" >0.62 (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row4_col0\" class=\"data row4 col0\" >Zeros</td>\n",
       "      <td id=\"T_a9dbc_row4_col1\" class=\"data row4 col1\" >---</td>\n",
       "      <td id=\"T_a9dbc_row4_col2\" class=\"data row4 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row4_col3\" class=\"data row4 col3\" >25%</td>\n",
       "      <td id=\"T_a9dbc_row4_col4\" class=\"data row4 col4\" >0.5</td>\n",
       "      <td id=\"T_a9dbc_row4_col5\" class=\"data row4 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row4_col6\" class=\"data row4 col6\" >std</td>\n",
       "      <td id=\"T_a9dbc_row4_col7\" class=\"data row4 col7\" >0.11</td>\n",
       "      <td id=\"T_a9dbc_row4_col8\" class=\"data row4 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row4_col9\" class=\"data row4 col9\" >0.58 (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row5_col0\" class=\"data row5 col0\" >Negative</td>\n",
       "      <td id=\"T_a9dbc_row5_col1\" class=\"data row5 col1\" >---</td>\n",
       "      <td id=\"T_a9dbc_row5_col2\" class=\"data row5 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row5_col3\" class=\"data row5 col3\" >5%</td>\n",
       "      <td id=\"T_a9dbc_row5_col4\" class=\"data row5 col4\" >0.39</td>\n",
       "      <td id=\"T_a9dbc_row5_col5\" class=\"data row5 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row5_col6\" class=\"data row5 col6\" >kurt</td>\n",
       "      <td id=\"T_a9dbc_row5_col7\" class=\"data row5 col7\" >0.23</td>\n",
       "      <td id=\"T_a9dbc_row5_col8\" class=\"data row5 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row5_col9\" class=\"data row5 col9\" >0.57 (4%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9dbc_row6_col0\" class=\"data row6 col0\" >RAM (Mb)</td>\n",
       "      <td id=\"T_a9dbc_row6_col1\" class=\"data row6 col1\" ><1 Mb</td>\n",
       "      <td id=\"T_a9dbc_row6_col2\" class=\"data row6 col2\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row6_col3\" class=\"data row6 col3\" >Min</td>\n",
       "      <td id=\"T_a9dbc_row6_col4\" class=\"data row6 col4\" >0.02</td>\n",
       "      <td id=\"T_a9dbc_row6_col5\" class=\"data row6 col5\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row6_col6\" class=\"data row6 col6\" >skew</td>\n",
       "      <td id=\"T_a9dbc_row6_col7\" class=\"data row6 col7\" >-0.14</td>\n",
       "      <td id=\"T_a9dbc_row6_col8\" class=\"data row6 col8\" >                              </td>\n",
       "      <td id=\"T_a9dbc_row6_col9\" class=\"data row6 col9\" >0.59 (4%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            <div>\n",
       "                <img src=\"data:image/png;base64,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\" alt=\"График\"/>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = pagri_data_tools.info_gen(df_internet, column='mb_used_cat', mode='column')\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категоризация данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала пишем все имеющиеся колонки ИИ и просим написать какие новые категориальный переменные можно создать.  \n",
    "Если таблиц много, то идем по одной таблице, закончили с одной идем к следующей.  \n",
    "Далее в конце можно спросить какие новые категориальные переменные можно создать, учитывая все таблицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальная переменная, это то за счет чего мы можем разделить наши данные и установить, что есть влияние этого фактора на целевую переменную.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "категориальные переменные могут быть не только в отдельном столбце.  \n",
    "Категориальная переменная может быть разбита на разные столбцы.  \n",
    "Например, оценка пользователей и оценка критиков могут быть в отдельных столбцах.  \n",
    "Нужно при предобработке это не забыть привести  к категориальному типу, чтобы далее анализировать.  \n",
    "Смотрим на имеющиеся столбцы в датафрейме и думаем, есть ли у нас категориальная переменная, которая разбита на несколько столбцов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категория может быть созадана\n",
    "- из нескольких столбцов, когда у нас числовая переменная разбита на несколкьо столбцов\n",
    "- при объединении нескольких таблиц, когда у нас есть несколько таблиц с одинаковыми столбцами\n",
    "- из числовых перменных можно сделать диапазоны возраста, продаж, цен, размера, объема и т.д.\n",
    "- из названий чего-либо можно сдлать категории по длинне названия, цвету вывески, количеству гласных. согласных, количеству позитивных, негативных слов и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Можно создать категориальную переменную относится к топ 5-10 по какой-то числовой переменной или нет.  \n",
    "То есть у нас будет столбец где будет типа топ и не топ (подумать как лучше называть), столбец називаем топ n по такой-то числовой переменной.  \n",
    "Например, топ 5 жанров по количеству продаж.  \n",
    "Тогда у нас у каждой записи будет признак относиться к топу или нет, это нам даст возмонсоть на графиках смотреть вклад топ 5-10 в общую картину.  \n",
    "Таким образом мы получим новый разрез топ 5-10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "категории можно делать из поведения пользователей и подобное  \n",
    "У нас есть активность пользователей и есть раздел куда он заходил, это категории.  \n",
    "Можно сделать просто категории из имеющихся, это правильно.  \n",
    "Но важно сделать категории типа - открывал пользователь страницу помощи или нет,  \n",
    "открывал пользователь раздел профиль 5 и более раз, менее 5 и не открывал.  \n",
    "Тут можно придумать много таких категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Категория может появится после анализа выбросов, нулевых значений и прочих аномалий.  \n",
    "Например, у нас датасет с данными о покупка и мы определили, что часть пользователей совершает слишком большие покупки, мы можем разбить на группы исходя их этого. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "следим, чтобы не осталось пропусков в категориальной переменной  \n",
    "все пропуски нужно заменить на что-то типа - не указано"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.isna()sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если есть пропуски, то добавляем "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".fillna(\"не указано\").astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас много пропусков (болше 20 процентов)  \n",
    "То можно создать категориальуню переменную (с пропусками / без пропусков) для каждой колонки с пропусками.  \n",
    "И далее на графиках долей и числовых можно будет анализировать.  \n",
    "Плюс можно будет создать срезы.  \n",
    "Бонусом мы получаем возможность изучать данные в разрезе пропусков в числовой переменной, так как na мы заполним на что-то типа - не указано"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы при загрузке данных не смогли изменить типы данных из-за пропусков, то теперь меняем типы данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас могут быть категориальные переменные не только для изучения данных на графиках под другим углом,  \n",
    "но категориальные переменные можно использовать для изучения среза данных.  \n",
    "Таким образом думаем какие срезы в датафрейме дадут нам важную информацию. И создаем категориальную переменную для них.  \n",
    "Например, у нас в данных есть растояние до центра, мы можем создать новую категориальную переменную и поместить туда катгории растояния до центра.  \n",
    "И затем изучить отдельные срезы в данных, например квартиры только в центре.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Думаем какие категориальные переменные сделать для срезов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Могут быть операции разность, сумма отношение с другими переменными, которые дадут новую переменную.  \n",
    "Смотрим на имеющиеся переменные и думаем какие из этих операций можно применить.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно, когда создали новые переменные, особенно числовые, то нужно их изучить через my_info (взять df только с нужными столбцами)  \n",
    "Посмотреть на гистограммы и стат параметры.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас есть категориальная переменная, в которйо больше 3 значений, то нужно подумать а не можем ли мы из нее сделать  \n",
    "> новую категориальную переменную с 2-3 значениями, но тут важно, чтобы это несло смысл. Тут нам может помочь ИИ. И сообразительнсоть. Часто сразу не заментны возможные категории, котоыре несут смысл.  \n",
    "> Тут исходим из смысла, наша задача созадть перменную, которая добавит нашему исследованию новый смысл, даст как бы новый разрез, и это улучшит  \n",
    "> качество наших выводов.  \n",
    "> Например, у нас столбец семейный стату, и там 6-7 статусов, мы можем собрать их в 2 семейный статус и не семейный статус.  \n",
    "> Тут отлично помогает ИИ. Пишешь ему название переменной, униальные значения в ней,  \n",
    "> и просишь придумать возможную новую категориальнуюд переменную из 2-3 значений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Вообще при категоризации ИИ очень хорошо помогает, он может дать идеи возможных категорий на оснвое имеющихся значений.  \n",
    "> Поэтому можно все столбцы прогонять через ИИ и смотреть что он предлагает, если есть то , что даст новый разрез нашим данным, то созадем категорийю.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно, когда мы создаем категории, то всегда смотреть value_counts.  \n",
    "> И делаем так, чтобы в каждой группе было достаточно элементов, хотя бы больше 30, а лучше больше 100.  \n",
    "> Иначе выводы будут некоректные.  \n",
    "> В идеале, чтобы количество элементов в каждой группе было от 1000. Лучше изменить диапазон и забрать часть данных от другой категории.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно, когда создаем категориальную переменную, то даем ей тип `category`  \n",
    "> Чтобы она появилась на графиках (так как идет фильтрация на числовые и категориальные)  \n",
    "> и чтобы места меньше занимала\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Придумываем какие колонки можно дополнительно сделать из имеющихся.  \n",
    "> Например у нас есть колонка длительность звонков, и 0 это пропущенный звонок,  \n",
    "> мы можем сделать колонку is_missed, в которой будет true или false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Стараемся сделать категориальную колонку с да нет для всех возможных колонок.  \n",
    "> Например, у нас колонка количество детей и есть 0, 1, 2, 3, 4, 5 мы созадем колнку  \n",
    "> есть дети или нет. 2 значения  \n",
    "> Это очень полезно, так как мы можем посмотреть это на графиках и проверить гипотезы  \n",
    "> стат тестами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Смотрим на колонки и думаем можно ли из нее сделать колонку с 2 значениями,  \n",
    "> например есть и нет что-то\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Очень важно, когда мы создаем новые колонки, в которых используем несколько дургих, то нужно проверить распределение этой новой переменной, особенно выбросы.  \n",
    "> Например, у нас начальная и конечная дата сессии и мы считаем длительность сессии. Вот тут нужно посмотреть какая минимальная длительность  \n",
    "> и какая максимальная. Ну и естественно проверить есть ли длительность 0 и меньше нуля.  \n",
    "> Таким образом мы можем найти инсайты уже после создания новых колонок, хотя в изначальных данных этих инсайдов не было видно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обычная категоризация данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Категоризация помогает избежать проблемы с разреженными данными, когда у нас есть слишком много групп с небольшим количеством элементов.  \n",
    "> Это может привести к некорректным выводам и ошибкам в анализе.\n",
    "> Категоризация нужна, чтобы образовать группы, в которых достаточно значений для использования статистических методов.  \n",
    "> И вообще, если в группе 1-10 элементов, например у нас возраст пользователей и 5 человек с возрастом 22, 3 человека с возрастом 23 и так далее.  \n",
    "> Мы не можем разбивать по таким группам, так как их размер небльшой и выводы будут некорректные, поэтому нам нужно собрать их в группы,  \n",
    "> чтобы у нас были группы с достаточным размером.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если у нас категориальная переменная имеет много значений, то мы не можем номрально с ней работать.\n",
    "  > Так как мы не можем построить графики по ним, так как их много и они не числовые. Не можем сравнить их все.  \n",
    "  > Поэтому нам нужно сократить категории.\n",
    "- Нужно посмотреть на данные и подумать можем ли мы разделить их по сегментам рынка или по другим категориям, которые нам помогут.\n",
    "- Мы можем категоризировать на основе и числовых и категориальных столбцов. То есть мы можем из категориальной переменной сделать\n",
    "  > другую категориальную, уменьшив или увеличив разбиение.\n",
    "- добавление категорий обогощает данные, при чем категории могут формироваться не из одной колонки, а из серии, то есть чтобы попасть\n",
    "  > в определенную категорию значения столбцов должно быть такое то, а не только один столбец определяет категорию.\n",
    "- категории могут быть да нет, то есть состоять из двух значений, например, у нас есть данные о рекламе и столбец где она показвалась,\n",
    "  > и у нас много много разных устройств. Мы можем разбить на да нет, то есть показвалась реклама по телеку или нет\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Мы можем разбить данные на категории двумя способами\n",
    "\n",
    "- разбивать на равные части\n",
    "  > подходит, когда\n",
    "  >\n",
    "  > - диапазон значений является равномерным и имеет линейную структуру\n",
    "  > - мы понимаем на какие интервалы хотим разбить данные\n",
    "  > - мы хотим разделить диапазон значений на равные части для удобства анализа.\n",
    "- разбить на основе квантилей\n",
    "  > подходит, если\n",
    "  >\n",
    "  > - диапазон значений имеет неравномерную структуру\n",
    "  > - мы не можем понять какие интервалы выбрать\n",
    "  > - хотим выделить группы с конкретными характеристиками (например, группы с низким доходом, средним доходом и высоким доходом)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Выбираем нужные способ и используем  \n",
    "> `create_category_column`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы посмотреть распределение по квантилям используем `pagri_data_tools.quantiles_columns()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем новые каеториальные переменные делать `.astype('category')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "создали новую переменную, сразу же изучили ее использу `info_gen`  \n",
    "задаем вопросы и пишем важные наблюдения  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.info_gen(df_internet, column='mb_used_cat', mode='column')\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['floor_cat'] = df.apply(lambda x: 'первый' if x['floor'] == 1 else 'последний' if x['floor'] == x['floors_total'] else 'другой', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visits['is_new_user'] = df_visits['is_new_user'].map({True: 'да', False: 'нет'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на квантили в столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.quantiles_columns(df.sales, list(np.arange(0, 1, 0.05)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно так разделить на группы, если других идей нет  \n",
    "- Дешевые: Заказы ниже Q1.  \n",
    "- Средние: Заказы между Q1 и Q3.  \n",
    "- Дорогие: Заказы выше Q3.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения границ используем квантили Q1, Q2 и Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.create_category_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сделаем следующие группы\n",
    "\n",
    "- до 30 лет\n",
    "- от 30 до 40 лет\n",
    "- от 40 до 50 лет\n",
    "- от 50 до 60 лет\n",
    "- старше 60 лет\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['до 30', '30-40', '40-50', '50-60', 'старше 60']\n",
    "bins = [-np.inf, 30, 40, 50, 60, np.inf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно пропуски заменить, то добавляем параметр `fillnavalue='не укаазано'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-40        5704\n",
       "40-50        5241\n",
       "50-60        4520\n",
       "до 30        3804\n",
       "старше 60    2132\n",
       "Name: age_cat, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['age_cat'] = pagri_data_tools.create_category_column(df.age, labels=labels, bins=bins)\n",
    "df['age_cat'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас в таблице числовая переменная разбита на несколько столбцов, то лучше ее объеденить в одни столлбец."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объеденим продажи в одну числовую переменную и создадим категориальную переменную region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_score</th>\n",
       "      <th>genre</th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_score</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>region</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>E</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2006</td>\n",
       "      <td>Северная Америка</td>\n",
       "      <td>41.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>не указано</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985</td>\n",
       "      <td>Северная Америка</td>\n",
       "      <td>29.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.00</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>E</td>\n",
       "      <td>83.00</td>\n",
       "      <td>2008</td>\n",
       "      <td>Северная Америка</td>\n",
       "      <td>15.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>E</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2009</td>\n",
       "      <td>Северная Америка</td>\n",
       "      <td>15.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>не указано</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>Северная Америка</td>\n",
       "      <td>11.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sports</td>\n",
       "      <td>LMA Manager 2007</td>\n",
       "      <td>X360</td>\n",
       "      <td>не указано</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>Другие</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65764</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Haitaka no Psychedelica</td>\n",
       "      <td>PSV</td>\n",
       "      <td>не указано</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>Другие</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65765</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Spirits &amp; Spells</td>\n",
       "      <td>GBA</td>\n",
       "      <td>не указано</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003</td>\n",
       "      <td>Другие</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65766</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>Winning Post 8 2016</td>\n",
       "      <td>PSV</td>\n",
       "      <td>не указано</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>Другие</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65767</th>\n",
       "      <td>83.00</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Madden NFL 13</td>\n",
       "      <td>PS3</td>\n",
       "      <td>E</td>\n",
       "      <td>55.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>Другие</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       critic_score         genre                      name platform  \\\n",
       "0             76.00        Sports                Wii Sports      Wii   \n",
       "1               NaN      Platform         Super Mario Bros.      NES   \n",
       "2             82.00        Racing            Mario Kart Wii      Wii   \n",
       "3             80.00        Sports         Wii Sports Resort      Wii   \n",
       "4               NaN  Role-Playing  Pokemon Red/Pokemon Blue       GB   \n",
       "...             ...           ...                       ...      ...   \n",
       "65763           NaN        Sports          LMA Manager 2007     X360   \n",
       "65764           NaN     Adventure   Haitaka no Psychedelica      PSV   \n",
       "65765           NaN      Platform          Spirits & Spells      GBA   \n",
       "65766           NaN    Simulation       Winning Post 8 2016      PSV   \n",
       "65767         83.00        Sports             Madden NFL 13      PS3   \n",
       "\n",
       "           rating  user_score  year_of_release            region  sales  \n",
       "0               E       80.00             2006  Северная Америка  41.36  \n",
       "1      не указано         NaN             1985  Северная Америка  29.08  \n",
       "2               E       83.00             2008  Северная Америка  15.68  \n",
       "3               E       80.00             2009  Северная Америка  15.61  \n",
       "4      не указано         NaN             1996  Северная Америка  11.27  \n",
       "...           ...         ...              ...               ...    ...  \n",
       "65763  не указано         NaN             2006            Другие   0.00  \n",
       "65764  не указано         NaN             2016            Другие   0.00  \n",
       "65765  не указано         NaN             2003            Другие   0.00  \n",
       "65766  не указано         NaN             2016            Другие   0.00  \n",
       "65767           E       55.00             2012            Другие   0.23  \n",
       "\n",
       "[65768 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Применяем melt для преобразования данных\n",
    "value_vars = ['na_sales', 'eu_sales', 'jp_sales', 'other_sales']\n",
    "melted_df = pd.melt(df, id_vars=df.columns.difference(value_vars), \n",
    "                    value_vars=value_vars,\n",
    "                    var_name='region', value_name='sales')\n",
    "# Словарь для замены значений\n",
    "region_mapping = {\n",
    "    'na_sales': 'Северная Америка',\n",
    "    'eu_sales': 'Европа',\n",
    "    'jp_sales': 'Япония',\n",
    "    'other_sales': 'Другие'\n",
    "}\n",
    "\n",
    "# Замена значений в столбце region\n",
    "melted_df['region'] = melted_df['region'].replace(region_mapping).astype('category')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть названия, то из них можно создать новые категории, извлекая определенные слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим название улицы из адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['street'] = df.address.str.split(',').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно убедиться, что на первом месте всегда город, иначе нужно думать как извлечь улицу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно исходить из задачи. Если извлечь сложно, но нам нужно будет построить только топ улиц, то можно пренебречь этим.  \n",
    "И извлечь просто сплитом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_address = df[~df.address.str.lower().str.contains(\"москва\")].address\n",
    "cities = filtered_address[filtered_address.str.contains('поселение')].unique().tolist()\n",
    "cities += filtered_address[filtered_address.str.contains('город')].unique().tolist()\n",
    "cities = [city.split(',')[0].lower() for city in cities]\n",
    "cities = set(cities+['москва', 'город москва', 'город москва, поселение'])\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_street(address):\n",
    "    # Проверяем наличие города в адресе\n",
    "    for city in cities:\n",
    "        if city in address.lower():\n",
    "            # Если город найден, разбиваем строку по запятой и берем второй элемент\n",
    "            parts = address.split(',')\n",
    "            if len(parts) > 1:\n",
    "                return parts[1].strip()  # Возвращаем название улицы\n",
    "    # Если город не найден, берем первый элемент\n",
    "    return address.split(',')[0].strip()\n",
    "\n",
    "# Применяем функцию к столбцу адресов\n",
    "df['street'] = df['address'].apply(extract_street)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в адресе после города может стоять поселение или город, то у нас часть улиц будет содержать название города или поселения.  \n",
    "Но нам для анализа потребуются только улицы, на которых много заведений. Поэтому эти строки нам не помешают, так как в городах спутниках и в поселениях будет меньше заведений, чем в москве.  \n",
    "Важно было выделить улицы, в которых на первом месте не стоит город и сразу идет улица. Такие мы извлекли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в адресе после города может стоять поселение или город, то у нас часть улиц будет содержать название города или поселения.  \n",
    "Но нам для анализа потребуются только улицы, на которых много заведений. Поэтому эти строки нам не помешают, так как в городах спутниках и в поселениях будет меньше заведений, чем в москве.  \n",
    "Важно было выделить улицы, в которых на первом месте не стоит город и сразу идет улица. Такие мы извлекли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим категориальную переменную, которая будет показывать круглосуточный ли объект. Для этого используем название объекта.  \n",
    "Если в его названии есть слова \"круглосуточный\", \"24 часа\", \"ежедневно\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление дополнительных столбцов к основной таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Добавим столбец с названием улиц\n",
    "places['street']=places['address'].str.split(',').str[1]\n",
    "\n",
    "# Добавим столбец с режимом работы\n",
    "places['is_24_7']=places['hours'].str.contains('ежедневно','круглосуточно')\n",
    "\n",
    "places['is_24_7'].mean()\n",
    "\n",
    "places['hours'].str.contains('ежедневно, круглосуточно').mean()\n",
    "\n",
    "# Для удобства заменим числовые значения в столбце chain на понятную запись\n",
    "places['chain']=places['chain'].replace({1:'Сетевое', 0:'Несетевое'})\n",
    "\n",
    "# Для удобства построения графиков дадим сокращенное название округов\n",
    "places['district_short']=places['district'].replace({'Северный административный округ':'САО', \\\n",
    "                                               \"Северо-Восточный административный округ\":\"СВАО\",\\\n",
    "                                              \"Северо-Западный административный округ\":\"СЗАО\",\\\n",
    "                                              \"Западный административный округ\":\"ЗАО\",\\\n",
    "                                              \"Центральный административный округ\":\"ЦАО\",\\\n",
    "                                              \"Восточный административный округ\":\"ВАО\",\\\n",
    "                                              \"Юго-Восточный административный округ\":\"ЮВАО\",\\\n",
    "                                              \"Южный административный округ\":\"ЮАО\",\\\n",
    "                                              \"Юго-Западный административный округ\":\"ЮЗАО\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем новые переменные из времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "если у нас год уже есть в таблице и он числовой,  \n",
    "то переводим его в категориальный тип   \n",
    "Но важно сначала перевести в строку, а потом в категориальный тип, иначе plotly будет воспринимать как continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.info_gen(df_internet, column='mb_used_cat', mode='column')\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_dict = {\n",
    "    'Monday': 'Понедельник',\n",
    "    'Tuesday': 'Вторник',\n",
    "    'Wednesday': 'Среда',\n",
    "    'Thursday': 'Четверг',\n",
    "    'Friday': 'Пятница',\n",
    "    'Saturday': 'Суббота',\n",
    "    'Sunday': 'Воскресенье'\n",
    "}\n",
    "month_dict = {\n",
    "    1: 'Январь',\n",
    "    2: 'Февраль',\n",
    "    3: 'Март',\n",
    "    4: 'Апрель',\n",
    "    5: 'Май',\n",
    "    6: 'Июнь',\n",
    "    7: 'Июль',\n",
    "    8: 'Август',\n",
    "    9: 'Сентябрь',\n",
    "    10: 'Октябрь',\n",
    "    11: 'Ноябрь',\n",
    "    12: 'Декабрь'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publication_weekday'] = df['first_day_exposition'].dt.day_name().map(weekday_dict).astype('category')\n",
    "df['publication_month'] = df['first_day_exposition'].dt.month.map(month_dict).astype('category')\n",
    "df['publication_year'] = df['first_day_exposition'].dt.year.astype(str).astype('category')\n",
    "# Задаем порядок для weekdays\n",
    "weekday_order = ['Понедельник', 'Вторник', 'Среда', 'Четверг', 'Пятница', 'Суббота', 'Воскресенье']\n",
    "df['publication_weekday'] = df['publication_weekday'].cat.reorder_categories(weekday_order, ordered=True)\n",
    "\n",
    "# Задаем порядок для months\n",
    "month_order = ['Январь', 'Февраль', 'Март', 'Апрель', 'Май', 'Июнь', 'Июль', 'Август', 'Сентябрь', 'Октябрь', 'Ноябрь', 'Декабрь']\n",
    "df['publication_month'] = df['publication_month'].cat.reorder_categories(month_order, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.isna()sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.info_gen(df_internet, column='mb_used_cat', mode='column')\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для даты заказа создадим новую категориальную переменную в формате месяц год."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Словарь для замены месяцев\n",
    "months_translation = {\n",
    "    'Jan': 'Янв',\n",
    "    'Feb': 'Фев',\n",
    "    'Mar': 'Мар',\n",
    "    'Apr': 'Апр',\n",
    "    'May': 'Май',\n",
    "    'Jun': 'Июн',\n",
    "    'Jul': 'Июл',\n",
    "    'Aug': 'Авг',\n",
    "    'Sep': 'Сен',\n",
    "    'Oct': 'Окт',\n",
    "    'Nov': 'Ноя',\n",
    "    'Dec': 'Дек'\n",
    "}\n",
    "# Получаем отдельно месяц и год\n",
    "months = df['first_day_exposition'].dt.strftime('%b').astype('category').cat.reorder_categories(list(months_translation.keys()), ordered=True)\n",
    "years = df['first_day_exposition'].dt.strftime('%y')\n",
    "months_years = pd.concat([months, years], axis=1)\n",
    "months_years.columns = ['month', 'year']\n",
    "# Создаем список уникальных (год, месяц) и сортируем\n",
    "unique_months = months_years.drop_duplicates().sort_values(by=['year', 'month'])\n",
    "\n",
    "# Создаем список для порядка\n",
    "month_year_order = []\n",
    "\n",
    "# Формируем month_year_order на основе уникальных (год, месяц)\n",
    "for _, row in unique_months.iterrows():\n",
    "    year = row['year']\n",
    "    month = row['month']\n",
    "    month_year_order.append(f\"{months_translation[month]}'{str(year)[-2:]}\")\n",
    "\n",
    "# Заменяем месяцы и соединяем с годом\n",
    "df['publication_month_year'] = months.astype(str).map(months_translation) + \"'\" + years\n",
    "df['publication_month_year'] = df['publication_month_year'].astype('category')\n",
    "df['publication_month_year'] = df['publication_month_year'].cat.reorder_categories(month_year_order, ordered=True)\n",
    "df['publication_month_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.isna()sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.info_gen(df_internet, column='mb_used_cat', mode='column')\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для верменных переменных нужно делать не только отедльно месяц, год.  \n",
    "Но и делать категориальную переменную обрезая время.  \n",
    "То есть мы созадем переменную   \n",
    "Янв'23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но нужно подумать, нужна ли нам будет именно временная переменная, или достаточно категории,  \n",
    "если будет нужна временная, то создаем обрезанную переменную datetime используя .dt.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно перевести в категорильный упорядоченный тип"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_lifetime_order = list(map(str, range(100)))[:df_cohort['cohort_lifetime'].nunique()]\n",
    "df_cohort['cohort_lifetime'] = df_cohort['cohort_lifetime'].astype(str).astype('category').cat.reorder_categories(cohort_lifetime_order, ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Категоризация с использованием лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас есть столбец и мы хотим его лематизировать, то используем функцию  \n",
    "> `lemmatize_column`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы создать лемы для словаря категоризации, можно посмотреть имеющиеся предложения и использовать\n",
    ">\n",
    "> ```\n",
    "> m = Mystem()\n",
    "> m.lemmatize('образованием')\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "m.lemmatize('образованием')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.lemmatize_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_dict = {\n",
    "    'недвижимость': ['жилье', 'недвижимость']\n",
    "    , 'образование': ['образование']\n",
    "    , 'автомобиль': ['автомобиль', 'машина']\n",
    "    , 'свадьба': ['свадьба'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "недвижимость    10779\n",
       "автомобиль       4288\n",
       "образование      3997\n",
       "свадьба          2337\n",
       "Name: purpose_new, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['purpose_new'] = pagri_data_tools.categorize_column_by_lemmatize(df.purpose, categorization_dict, use_cache=True)\n",
    "df['purpose_new'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если нужно, уддалим старую колонку\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>family_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dob_cat</th>\n",
       "      <th>total_income_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>высшее</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>253876</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>40-50</td>\n",
       "      <td>200-500 тыс</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  dob_years education    family_status gender income_type debt  \\\n",
       "0         1         42    высшее  женат / замужем      F   сотрудник    0   \n",
       "\n",
       "   total_income       purpose dob_cat total_income_cat  \n",
       "0        253876  Недвижимость   40-50      200-500 тыс  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop('purpose', axis=1).rename(columns={'purpose_new': 'purpose'})\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> С помощью лематизации мы можем сократить количество категорий.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Например мы можем выделить группы:\n",
    "\n",
    "- операции с автомобилем (ключевое слово - автомобиль)\n",
    "- операции с недвижимостью (ключевые слова: жилье, недвижимость)\n",
    "- проведение свадьбы (ключевое слово: свадьба)\n",
    "- получение образования (ключевое слово: образование)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Используем функцию  \n",
    "> `categorize_column_by_lemmatize`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.categorize_column_by_lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из времени также можно сделать категориальный переменные, например, создать переменную для времени заправки, если больше 1 минуты, то долгая заправка, иначе короткая и так далее.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО подумать какие переменные мы можем создать не только категориальные, но и числовые и временные.  \n",
    "Например, обрезание времени, чтобы получить дату по часам и прочее,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если мы хотим преобразовать категории в числа, то мы можем использовать\n",
    "\n",
    "- lable encoding\n",
    "  > Заменяем быквы числами. Хорошо работает, когда у нас порядковые категориальные переменные.  \n",
    "  > Не забываем про порядок, если у нас алфавитный порядок наших категорий соотвествует числовому, то ок,  \n",
    "  > если нет, то нам нужно самим определить порядок чисел, чтобы они соответствовали категориям в нужном порядке.\n",
    "- one hot encoding\n",
    "  > Если у нас категориальная переменная не упорядочиваемая, то лучше использовать one hot encoding, чтобы разница между числами не вносила шум,  \n",
    "  > так как черный и белый и красный цвет закодированные 1, 2, 3 вносят смысл количества, но они не имеют этого свойства.\n",
    "- target encoding\n",
    "  > замена категориальной переменной на каую-то статистику по одной из категорий внутри этой переменной.  \n",
    "  > Например у нас категориальная переменная это наличие задержки. Значение задержан / незадержан. Мы кодируем их как 0 и 1. Далее мы берем и считаем по каждой группе (для задержан и для незадержан)  \n",
    "  > статистику, например, среднее и получаем столбец, где вместо каждой буквы будет ее среднее.  \n",
    "  > Тут важно делать регуляризацию. Так как маленькие группы могут иметь сильно зашумленные статистики, так как если у нас  \n",
    "  > группа из 5 значений, то среди них может быть легко экстремальное одно и оно сбивает статистику, поэтому добавляем штраф всем статистикам.  \n",
    "  > Регуляризация это что-то похожее на сглаживание.  \n",
    "  > Как это делается\n",
    "  >\n",
    "  > - берем считаем среднее по таргету (целевой переменной, то есть той, по которой мы счтаем статистику) всей таблице (то есть не делим на категории)\n",
    "  > - Далее используем следующую формулу для сглаженного значения среднего по конкретной группе:  \n",
    "  >   (среднее по группе _ количество элементов в группе + среднее по таргету без учета категорий _ размер регуляризирующей группы) / (количество элементов в категории + размер регуляризирующей группы)  \n",
    "  >   Количество элементов в регуляризационнной группе выбирает эмперически. То есть это количество элементов, которым мы сглаживаем.  \n",
    "  >   Смысл в том, что мы берем сколько-то элементов с занчением для всех категорий и сглаживаем им наши отдельные категории.\n",
    "  > - Размер регуляризирующей группы обычно выбирают с помощью grid search, то есть берут цикл для размера этой группы и считают результат модели для каждого размера,  \n",
    "  >   и потом выбирают тот размер, для которого результат лучше.\n",
    "  >\n",
    "  > `target_encoding_linear`  \n",
    "  > `target_encoding_bayes`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.target_encoding_linear()\n",
    "pagri_data_tools.target_encoding_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Использование кластеризации для категоризации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно понизить размерность до 3  \n",
    "> и построить 3 д график  \n",
    "> По этому графику посмотреть есть ли у нас возможные кластеры  \n",
    "> Если есть, то выделить их  \n",
    "> Причем для понижения размерности можно брать все столбцы, а можно только часть.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание дополнительных датафреймов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если для анализа срезов нужны сложные датафреймы (нужно  обогатить, соеденить и прчее), то  \n",
    "думаем какие разрезы данных нам будут нужны и создаем для них датафреймы, если нужно.  \n",
    "Если нам для срезов нужно просто отфильтровать данные, то этот раздел не нужен, мы при визуализации отфильтруем сразу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас есть категориальная переменная в которой для каждой категории есть несколкьо записей, то можно аггрегировать данные по этой переменной и создать переменную количество объектов и дополнительно из имеющихся числоваых переменных также создать переменные.  \n",
    "Например, среднее, медианное, суммарное значение и т.д. Далее можно будет построить диаграмму рассеяния."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сетевых заведений аггрегируем данные и создадим таблицу для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>is_chain</th>\n",
       "      <th>type</th>\n",
       "      <th>address</th>\n",
       "      <th>seats</th>\n",
       "      <th>street</th>\n",
       "      <th>seats_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151635</td>\n",
       "      <td>сметана</td>\n",
       "      <td>нет</td>\n",
       "      <td>кафе</td>\n",
       "      <td>город Москва, улица Егора Абакумова, дом 9</td>\n",
       "      <td>48</td>\n",
       "      <td>улица Егора Абакумова</td>\n",
       "      <td>средне</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     name is_chain  type                                     address  \\\n",
       "0  151635  сметана      нет  кафе  город Москва, улица Егора Абакумова, дом 9   \n",
       "\n",
       "   seats                 street seats_cat  \n",
       "0     48  улица Егора Абакумова    средне  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_cnt</th>\n",
       "      <th>seats_median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beverly hills diner</th>\n",
       "      <td>1</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bierloga</th>\n",
       "      <td>1</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black &amp; white</th>\n",
       "      <td>1</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bocconcino</th>\n",
       "      <td>3</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boobo</th>\n",
       "      <td>1</td>\n",
       "      <td>46.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     obj_cnt  seats_median\n",
       "name                                      \n",
       "beverly hills diner        1         88.00\n",
       "bierloga                   1         75.00\n",
       "black & white              1         40.00\n",
       "bocconcino                 3         68.00\n",
       "boobo                      1         46.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_chain_obj = df[df.is_chain == 'да'].groupby('name').agg(\n",
    "    obj_cnt = ('id', 'nunique')\n",
    "    , seats_median = ('seats', 'median')\n",
    ")\n",
    "df_chain_obj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим 2 категорилаьные переменные для количества объектов в сети и для медианного количества посадочных мест в объекте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что если в сети 5 и менее объектов, то это сеть с малым количеством объектов, а если в сети 6 и более объектов, то это сеть с большим количеством объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Мало заведений', 'Много заведений']\n",
    "bins = [-np.inf, 5, np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj_cnt_cat\n",
       "Мало заведений     457\n",
       "Много заведений     93\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_chain_obj['obj_cnt_cat'] = pagri_data_tools.create_category_column(df_chain_obj.obj_cnt, labels=labels, bins=bins)\n",
    "df_chain_obj['obj_cnt_cat'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, если в заведении 30 и менее посадочных мест, то это небольшое заведение. Если более 30, то это крупное заведение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Мало мест', 'Много мест']\n",
    "bins = [-np.inf, 30, np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seats_median_cat\n",
       "Много мест    343\n",
       "Мало мест     207\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_chain_obj['seats_median_cat'] = pagri_data_tools.create_category_column(df_chain_obj.seats_median, labels=labels, bins=bins)\n",
    "df_chain_obj['seats_median_cat'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь объеденим эти 2 категориии в одну."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_cnt</th>\n",
       "      <th>seats_median</th>\n",
       "      <th>obj_cnt_cat</th>\n",
       "      <th>seats_median_cat</th>\n",
       "      <th>Категория заведения</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beverly hills diner</th>\n",
       "      <td>1</td>\n",
       "      <td>88.00</td>\n",
       "      <td>Мало заведений</td>\n",
       "      <td>Много мест</td>\n",
       "      <td>Мало заведений - Много мест</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bierloga</th>\n",
       "      <td>1</td>\n",
       "      <td>75.00</td>\n",
       "      <td>Мало заведений</td>\n",
       "      <td>Много мест</td>\n",
       "      <td>Мало заведений - Много мест</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black &amp; white</th>\n",
       "      <td>1</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Мало заведений</td>\n",
       "      <td>Много мест</td>\n",
       "      <td>Мало заведений - Много мест</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bocconcino</th>\n",
       "      <td>3</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Мало заведений</td>\n",
       "      <td>Много мест</td>\n",
       "      <td>Мало заведений - Много мест</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boobo</th>\n",
       "      <td>1</td>\n",
       "      <td>46.00</td>\n",
       "      <td>Мало заведений</td>\n",
       "      <td>Много мест</td>\n",
       "      <td>Мало заведений - Много мест</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     obj_cnt  seats_median     obj_cnt_cat seats_median_cat  \\\n",
       "name                                                                          \n",
       "beverly hills diner        1         88.00  Мало заведений       Много мест   \n",
       "bierloga                   1         75.00  Мало заведений       Много мест   \n",
       "black & white              1         40.00  Мало заведений       Много мест   \n",
       "bocconcino                 3         68.00  Мало заведений       Много мест   \n",
       "boobo                      1         46.00  Мало заведений       Много мест   \n",
       "\n",
       "                             Категория заведения  \n",
       "name                                              \n",
       "beverly hills diner  Мало заведений - Много мест  \n",
       "bierloga             Мало заведений - Много мест  \n",
       "black & white        Мало заведений - Много мест  \n",
       "bocconcino           Мало заведений - Много мест  \n",
       "boobo                Мало заведений - Много мест  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_chain_obj['Категория заведения'] = (df_chain_obj['obj_cnt_cat'].astype(str) + ' - ' + df_chain_obj['seats_median_cat'].astype(str)).astype('category')\n",
    "df_chain_obj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала все одниаковый по смыслу поля в разных таблицах приводим к одному названию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно  \n",
    "Все новые таблицы начинаем с `df_`  чтобы потом не нужно было искать навзание   \n",
    "вводишь `df_` и далее будет список переменных таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Перевести id всех сущностей в числа и чтобы уникальность сохранилась.  \n",
    "Это нужно для анализа на графиках, чтобы можно было для них аггрегировать по count и nunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если будет много новых таблиц, то созадем подразделы   \n",
    "- без аггрегации \n",
    "- с аггрегацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем про ИИ  \n",
    "Пишем ему задание типа такого -  \n",
    "пишем какие таблицы у нас есть, название таблицы, поля таблицы с описанием полей.  \n",
    "и спрашиваем какие новые таблицы можно создать, чтобы проанализировать данные.  \n",
    "Какие аггрегации сделать и так далее.  \n",
    "Вот пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "у меня есть таблица \n",
    "users с полями \n",
    "- user_id - уникальный идентификатор пользователя\n",
    "- first_name - имя пользователя\n",
    "далее пишем все имеющиеся поля\n",
    "есть таблица calls с полями \n",
    "- id - уникальный номер звонка\n",
    "- call_date - дата звонка\n",
    "и так далее описываем все таблицы и поля  \n",
    "Пишем цель анализа, можно скопировать из описания и цели\n",
    "И далее пишем что нужно \n",
    "- это pandas dataframes какие таблицы я могу из них сделать для будущего анализа, чтобы подробно все проанализировать, что с чем объеденить, какую аггрегацию выбрать, расскажи подробно и как можно больше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот структурированный подход к выбору таблиц для объединения при анализе данных:\n",
    "\n",
    "1. Начните с бизнес-задачи:\n",
    "- Четко определите, какой анализ вам нужно провести\n",
    "- Какие метрики вы хотите получить\n",
    "- Какие гипотезы проверить\n",
    "2. Создайте карту данных:\n",
    "- Выпишите все доступные датафреймы\n",
    "- Для каждого датафрейма укажите ключевые поля\n",
    "- Отметьте связи между таблицами (общие ключи)\n",
    "3. Выберите основную таблицу:\n",
    "- Определите центральную сущность анализа (например, пользователь или транзакция)\n",
    "- Выберите таблицу с этой сущностью как базовую\n",
    "4. Определите необходимые признаки:\n",
    "- Составьте список всех нужных переменных для анализа\n",
    "- Отметьте, в каких таблицах они находятся\n",
    "- Исключите таблицы с избыточной информацией\n",
    "5. Спланируйте последовательность объединения:\n",
    "- Начните с основной таблицы\n",
    "- Добавляйте только те таблицы, которые содержат нужные признаки\n",
    "- Учитывайте гранулярность данных (уровень агрегации)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создание таблиц без аггрегации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО \n",
    "когда мы соединяем несколько таблиц в одну, то нужно добавить метку откуда мы берем данные, если это не один источник просто в разных таблицах.  \n",
    "По сути разные таблицы это категориальная переменная, и общая метрика которую мы соберем из разных фреймов, должна быть изучена в разрезе этой категории тоже.  \n",
    "И также важно посмотреть структуру метрики по этой новой категории.  \n",
    "Нужно внимательно посмотреть на таблицы и подумать есть ли у нас такая ситуация.  \n",
    "При чем это может быть не очевидно.  \n",
    "Например, у нас информация о звонках, сообщениях и так далее.  \n",
    "Даже тут можно создать категориальную переменную (сообщение, звонок и так далее).  \n",
    "Все что можно сделать категориальной переменной, нужно обязательно сделать.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего у нас будет таблица фактов и таблица измерений.  \n",
    "И наша задача добавить категории к таблице фактов для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Думаем какие метрики нам нужно обхеденить в один датафрейм, чтобы потом проанализировать.  \n",
    "Обычно мы берем датафрейм где есть числовая переменная, которую мы хотим проанализировать и к этому  \n",
    "датафрейму добавляем категориальные переменные из других датафреймов.   \n",
    "Также можно добавлять числовые перменные для анализа корреляции.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все новые созданные таблицы записываем в temp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала думаем какие таблицы соеденить для анализа без аггрегации.  \n",
    "Чтобы проанализировать не аггрегированные данные.  \n",
    "Тут нужно изучить размеры таблицы и какие зависимости нам было бы полезно изучить.  \n",
    "Далее посчитать сколько будет строк в случии объединения без аггрегации и если памяти хватает, то делаем.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, у нас есть таблицы тарифом, сообщений, пользователей, звонков.  \n",
    "Объеденить в один фрейм мы их не можем, но мы можем создать отдельные фреймы для сообщений, звонков и трафика без аггрегации.  \n",
    "И потом уже отдельно их изучить в dash app. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим дополнительные таблицы для анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим отдельные таблицы для анализа выручки для звонков, сообщений и интернета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df_calls =  202607\n",
      "len of df_messages =  123036\n",
      "len of df_internet =  149396\n"
     ]
    }
   ],
   "source": [
    "print('len of df_calls = ', len(df_calls))\n",
    "print('len of df_messages = ', len(df_messages))\n",
    "print('len of df_internet = ', len(df_internet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_users = df_calls.merge(df_users, on='user_id', how='left')\n",
    "messages_users = df_messages.merge(df_users, on='user_id', how='left')\n",
    "internet_users = df_internet.merge(df_users, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of calls_users =  202607\n",
      "len of messages_users =  123036\n",
      "len of internet_users =  149396\n"
     ]
    }
   ],
   "source": [
    "print('len of calls_users = ', len(calls_users))\n",
    "print('len of messages_users = ', len(messages_users))\n",
    "print('len of internet_users = ', len(internet_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим информацию о тарифах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_full = calls_users.merge(df_tariffs, left_on='tariff', right_on='tariff_name', how='left')\n",
    "messages_full = messages_users.merge(df_tariffs, left_on='tariff', right_on='tariff_name', how='left')\n",
    "internet_full = internet_users.merge(df_tariffs, left_on='tariff', right_on='tariff_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of calls_full =  202607\n",
      "len of messages_full =  123036\n",
      "len of internet_full =  149396\n"
     ]
    }
   ],
   "source": [
    "print('len of calls_full = ', len(calls_full))\n",
    "print('len of messages_full = ', len(messages_full))\n",
    "print('len of internet_full = ', len(internet_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество строк не изменилось, все хорошо. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так нужно подумать и создать все нужные таблицы без аггрегации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создание таблиц с аггрегацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО когда мы соединяем несколько таблиц в одну, то нужно добавить метку откуда мы берем данные, если это не один источник просто в разных таблицах.  \n",
    "По сути разные таблицы это категориальная переменная, и общая метрика которую мы соберем из разных фреймов, должна быть изучена в разрезе этой категории тоже.  \n",
    "И также важно посмотреть структуру метрики по этой новой категории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "вниметльно выбираем функции для аггрегации.  \n",
    "Думаем какая аггрегирующая метрика нам нужна. Возможно нужно несколько, то используем несколько `.agg(mb_used=('mb_used', 'sum'), mb_used_avg=('mb_used', 'mean'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Думаем нужно ли считать   \n",
    "`mean, median, count, nunique, sum`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно хорошо подумать какие аггрегационные метрики нам будут нужны для анализа на графиках.  \n",
    "Так как без аггрегации мы в dash app сами выбираем аггрегацию, а тут аггрегация уже сделана, поэтому нам нужно выбрать аггрегацию заранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Хорошо думаем по каким каетгориям нужно саггрегировать данные, чтобы сравнить категории.  \n",
    "Например, у нас заказы и расходы на макретинг. Мы хотим не просто сравнить источники по выручке или расходам, а хотим посмотреть выручку минус расходы.  \n",
    "Для этого нужно каждого пользователя привязать к источнку (например по первому входу с какого источника он пришел)  \n",
    "И далее добавить в таблицу, где нет источнкика колонку для каждого пользователя с истончиком и аггрегировать данные и обхеденить по источнику\n",
    "Вот в таких ситуациях нужно аггрегировать по источнику, объеденять таблицы и рассчитывать метрки (выручка, прибыль и прочие)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "чтобы дальше при анашизе не было путаницы, аггрегированные метрики называем с префикосом аггрегации, например, avg_age, sum_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И не забываем, что если мы рассчитали несколько аггрегирующих метрик в agg,  \n",
    "то нужно все их изучить в info_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если мы можем сделать аггрегацию по нескольким столбцам (то есть группируем по нескольим столбцам),  \n",
    "То не забываем сделать аггрегацию для каждого столбца отдельно.  \n",
    "Так как в dash app у нас будет автомтаически групироваться по категории и браться, например, среднее занчение.  \n",
    "И если исходный датафрейм у нас был сгруппирован, например, по месяцу и пользователям, то в итоге у нас будет среднее значение за месяц по пользователям.  \n",
    "Поэтому нам нужно сделать отдельно аггрегацию по месяцу.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно подумать как лучше создавать аггрегированные таблицы.  \n",
    "Сначала нужно определтиь какие уровни аггрегации нам нужны для анализа.  \n",
    "Наприммер, средняя выручка за день по месяцам, нам нужно чтобы изначально в dash app шла таблица с аггрегацией по дням.  \n",
    "И так все таблицы. Поэтому очень важно правильно выбирать уровень аггрегации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее переходим к созаднию аггрегированных таблиц.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Структура объединения с аггрегацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Определение целей анализа\n",
    "- Формулировка вопросов: Начните с четкого понимания, какие вопросы вы хотите ответить с помощью агрегации. Например, хотите ли вы узнать средний доход по регионам или общее количество продаж по месяцам?\n",
    "- Идентификация ключевых метрик: Определите, какие метрики будут важны для вашего анализа (например, сумма, среднее, количество, максимум, минимум и т.д.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Анализ исходных данных\n",
    "- Изучение структуры данных: Посмотрите на каждый из датафреймов, которые вы хотите объединить. Определите, какие переменные есть в каждом из них и какие из них могут быть использованы для агрегации.\n",
    "- Определение типов данных: Убедитесь, что типы данных в ваших переменных соответствуют тому, что вы хотите агрегировать (например, числовые данные для суммирования)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Определение уровня агрегации\n",
    "- Группировка по уровням: Решите, на каком уровне вы хотите агрегировать данные. Например, вы можете агрегировать данные по месяцам, кварталам или годам, в зависимости от ваших целей.\n",
    "- Многоуровневая агрегация: Если необходимо, подумайте о многоуровневой агрегации, когда данные агрегируются сначала по одному критерию, а затем по другому (например, сначала по регионам, затем по категориям товаров).  \n",
    "Примеры:\n",
    "- По времени (день/месяц/год)\n",
    "- По объекту (пользователь/продукт/регион)\n",
    "- По комбинации измерений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Классификация полей\n",
    "- Метрики (что агрегируем)\n",
    "- Атрибуты (характеристики объектов)\n",
    "- Группировочные поля (по ним агрегируем)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Выбор агрегационных функций для каждого типа данных:\n",
    "- Числовые: sum, mean, max, min, count\n",
    "- Категориальные: mode, count, nunique\n",
    "- Временные: first, last, max, min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помним, что аггрегировать можно не только по строкам,  \n",
    "можно использовать pivot_table для аггрегации по столбцам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно не сделать таблицы аггрегации, которые у нас уже потенциально есть в неаггрегированном виде.  \n",
    "То есть мы создаем аггрегации только для тех ситуаций, когда у нас нет этого без аггрегации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут важно определить по каким полям мы будем аггрегировать данные.  \n",
    "И выбрать таблицы, которые нам нужно объеденить, чтобы изучить зависимости их полей.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблиц может быть много, так как если у нас данных много, то нам нужно будет аггрегировать их перед соединением.  \n",
    "Нужно подумать какие аггрегации нам нужны для анализа и для каждой сделать отдельный датафрейм и добавить нужные категориальные  \n",
    "перменные из других датафреймов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть если у нас данных сильно много, то мы думаем как аггрегировать числовую перменную и уже к аггрегированной таблице джойним другие с категориями.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда у нас в двух таблицах разные названия столбцвов, то нужно стандартизировать названия, чтобы они совпадали.  \n",
    "Если мы используем не inner соединение. Так как при внешенм соединение в итоговой таблице будут пропуски, где нет совпадений.  \n",
    "И если мы не приведем названия столбцов к одному виду, то у нас получиться, что в одном и другом столбце, по которому мы соединяли,  \n",
    "будут пропуски. И если нам далее нужно будет соединять с другой таблицей по этому полю, то мы не сможем это сделать.  \n",
    "И для расчетов также это портит все.  \n",
    "Поэтому нужно всегда приводить названия столбцов к одному виду."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не хотим менять название столбца в исходной таблице, то мы можем прям в merge переименовать таблицу  \n",
    "`df_revenue_by_month = df_revenue_by_month.merge(df_tariffs.rename(columns={'tariff_name': 'tariff'}), on='tariff')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если мы можем создать таблицу без аггрегации, то не нужно создавать аггрегированные, так как мы можем в процессе изучения   \n",
    "в dash app строить разные аггрегации и изучать в разрезах.  \n",
    "Аггрегация нужна, когда мы не можем объеденить таблицы из-за размера например, и тогда нам нужно уже думать до построения графиков  \n",
    "какие аггрегации сделать для объединнения таблиц.  \n",
    "И придется делать много разных таблиц, которые нам нужно изучить. Это минус аггрегации. Так как мы не можем автоматизироваать процесс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нам нужно для каждого пользователя найти источник, с которого он первый раз зашел, то делаем так"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проверка соответствия:  \n",
    "> Если у нас в разных таблицах есть значения, которые дожны быть одинакоые,  \n",
    "> то нужно проверить, что значения в одном столбце соответствуют значениям в другом столбце.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column_name1'].equals(df['column_name2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обоготить данные можно следующими способами\n",
    "\n",
    "- взять поле нашей таблицы и найти дополнительные данные в интернете или ещё где-то и потом связать с нашей колонкой по этому полю\n",
    "  > Самое просто это дата, если у нас есть дата, то мы можем много разной доп информации внести в наши данные связывая по дате.  \n",
    "  > Также, например, у нас есть какие-то коды чего-то, мы ищем информацию по этим кодам и находим табличку с доп инфой по этим кодам и можем обоготить ими  \n",
    "  > нашу таблицу. Например, у нас города или страны, мы можем по ним также внести доп инфу из какого-то источника, которая нам поможет.  \n",
    "  > Вообще любое поле нашей таблицы это потенцильная нить для обогощения. Главное понять с чем полезным мы можем соеденить  \n",
    "  > через конкретное поле, чтобы получить больше полезной информации для анализа, по сути для детализации наших зависимостей или для поиска  \n",
    "  > новых зависимостей и инсайтов в них.  \n",
    "  > Процесс следующий - мы берем каждую колонку нашего дата сета и думаем, с чем через нее мы можем связать и если придумываем, то идешь ищем эту информацию и  \n",
    "  > в итоге соединяем.\n",
    "- Можно пойти от обратного. Сначал подумтаь какие данные нам могут помочь и поискать их в интернете например, а потом уже думать как их соеденить с нашими\n",
    "  > данными. Оба способа лучше делать одновременно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Каждый раз, когда мы работаем с дата сетом, мы должны понять что является сущностью этого дата сета.  \n",
    "> Например событие, человек и прочее.  \n",
    "> Далее нам нужно поянть а можем ли мы его идентифицировать по текущим данным (не всегда есть уникальный ай ди).  \n",
    "> Если не можем, то нужно думта как обогатить данные, чтобы четко идентифицировать сущности\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Что нужно обязательно првоерить после соединения\n",
    "\n",
    "- если мы соединяем по полю, которое уникально в обеих таблицах\n",
    "  > - количество строк в левом датафрейме равно количеству строк в итоговом\n",
    "  > - параметры каждого дата сета не изменились (если мы соединили правильно, то итоговые суммы по столбцам не должны измениться)\n",
    "  >   - используем `df.sum(numeric_only=True)` для каждой таблицы до соединения и для общей таблицы и сравниваем значения\n",
    "  >   - можно использвоать `df.describe` также до и после объединения и сравнивать параметры\n",
    "- если у нас в одной из колонок для соединения не уникальные значения (то есть для одной строки в левой таблице будет несколько в итоговй)\n",
    "  > - Сначала группируем таблицы, чтобы поле для соединения в обеих таблицах было уникальное\n",
    "  >   и применяем предыдущий шаг с количеством строк в левой и итоговой и суммой значений в левой и итоговой одинаковой\n",
    "  > - Если нам нужно соеденить без группировки (но это редко может быть, поэтому нужно подумать точно ли не моежм сгруппировать)  \n",
    "  >   тогда нет выбора и остаются только следующие варианты  \n",
    "  >    - если в левой таблице уникальные записи в колонке, по которйо соединяем  \n",
    "  >    - тогда считаем сколько было записей в левой таблице в колонке для соединения и сравниваем с количеством **уникальных** записей в итоговой  \n",
    "  >    они должны совпадать, но тут важно в итоговой брать уникальные записи - есил и в левой и правой нет уникальных - тут считаем сколько **уникальных** в левой до и сколько **уникальных** в итоговой, должно совпадать\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас что-то не сходится после соединения таблиц, то нужно внимально изучить это.  \n",
    "> Тут может быть инсайт (кто-то не правильно вносит информацию, какие-то значения неверные или кто-то что-то хотел спрятать, не указать и прчоее).  \n",
    "> Когда видим нестыковки после соединения таблиц, то должна загораться красная лампочка. Это потенциальный инсайт, баг, который мы можем найти и сообщить, чтобы его починили.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> помним, что метод соединения inner стоит по умолчанию в merge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> В колонках, по которым будем соеднить, проверяем, нет ли пропусков, пропуски нужно заменить нулями.  \n",
    "> Иначе будет либо ошибка, либо пропуски сджойнятся с пропусками\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проблема справочников  \n",
    "> При объединение таблиц важно помнить про то, что в разных таблицах не только названия столбцов может быть разное,  \n",
    "> но и одно значение может быть записано по разному в разных таблицах, например, названия профессий, названия городов,  \n",
    "> имя в одной таблице на русском, а в другой на английском, номер телефона с черточкой или плюсом и без черточки или плюса.  \n",
    "> Поэтому не забываем привести все значения таблиц к нижнему регистру, чтобы не было проблем разными регистрами для одного слова\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проблема временных зон  \n",
    "> В одной таблице может быть выгрузка по местному времени, а в другом по московскому\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Проблема курсов валют  \n",
    "> Разыне системы могут брать курс за разные промежутки вермени, например, одна система берет курс в гугле (раз в час обновляется),  \n",
    "> а другая система берет курс в ЦБ (обновляется раз в сутки)  \n",
    "> И поэтому итоговые резултаты могут не состыковаться, поэтому, когда видим курсы валют, то нужно убедиться. что они взяты из одного испточника  \n",
    "> и за один промежуток времени\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Когда мы работаем с данными, нам важно четко идентифицировать клиентов, событие или другую сущность, с которой мы работаем.  \n",
    "> Иначе у нас будет шум, так как мы одного и того же клиента учтем более одного раза.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Как можно обоготить данные, чтобы лучше идентифицировать сущности\n",
    "\n",
    "- Добавить для клиента email, телефон, устройство, 4 цифры карты и другое, что может помочь его идентифицировать\n",
    "  > Это важно так как у клиента могут быть разные телефоны, устройства, карты, но все это вместе поможет его идентифицировать точнее\n",
    "- Добавить для события локацию, погоду, связанные событие, праздники, что поможет нам идентифицировать событие\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все новые созданные переменные помещаем в temp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет метрик\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "обязательно создать метрику количество всех сущностей, которые есть в датафреймах.   \n",
    "Так как в анализе категорий мы сравниваем количество в категориях.  \n",
    "А нам также очень важно посмотреть количество не категоризированных сущностей.  \n",
    "Нужно подумать как лучше это сделать. В dash app есть функция cnt, главное не забыть ее использовать.  \n",
    "Но это суммарное, нужно ещё среднее или медианное значение.\n",
    "Если количество применимо к ним. Например количество пользователей, количество заказов, количество товаров и т.д.\n",
    "И также важно смотреть суммарное и среднее / медианное значение.\n",
    "И важно назвать не как было например user_id, а назвать понятнее users_cnt или типа того, чтобы не запутаться на графиках.  \n",
    "Очень важно давать четкое и понятное детализированное название переменным.   \n",
    "Это очень сильно помогает далее при анализе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО когда мы соединяем несколько таблиц в одну, то нужно добавить метку откуда мы берем данные, если это не один источник просто в разных таблицах.  \n",
    "По сути разные таблицы это категориальная переменная, и общая метрика которую мы соберем из разных фреймов, должна быть изучена в разрезе этой категории тоже.  \n",
    "И также важно посмотреть структуру метрики по этой новой категории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Строим временные графики не только по месяцам, важно построить и по дням.  \n",
    "Для всех метрик желательно, чтобы посмотреть как метрика меняется со временем.  \n",
    "Так как если мы построим только аггрегировав по месяцам, то можем потерять важные колебания и инсайты.  \n",
    "Также на графике временных изменений метрик, рисуем линию срднего (моды, медианы, что подходит больше всего) и подписываем значение.  \n",
    "Так будет видно колебание вокруг средннего значения.  \n",
    "Если у нас данных сильно много и по дням сильно много данных на графике, то просто берем за последний год, полгода или три месяца."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "изучаем отдельно каждую новую метрики через info_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.info_gen(df_users, column='age_cat', mode='column')\n",
    "gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "После каждого объединения таблиц (merge or join) нужно проверить, есть ли NaN значения в результирующем датафрейме, чтобы убедиться, что данные корректно объединены.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Когда создали новую переменную, то записываем ее в temp.ipynb название переменной и описание  \n",
    "Чтобы далее когда нужно будет добавлять в title_for_axis не нужно бьло искать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала все одниаковый по смыслу поля в разных таблицах приводим к одному названию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если метрик много, то можно создать подразделы для них.  \n",
    "Ниже примерные названия подразделов.  \n",
    "Названия метрик могут повторяться в разных разделах ниже.  \n",
    "Это нормально, так как многие разделы имеют общее.  \n",
    "Нужно выбрать разделы, которые лушче подходят для конкретнго проекта.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если метрик не много, то просто созадем их в одном разделе  \n",
    "Каждую новую метрику можно просто выделить начало создания жирным шрифтом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "для неаггригированных данных создаем новую категориальную переменную новый или нет пользователй (считаем для каждого пользователя его первый месяц и сравниваем с текущим месяцем)  \n",
    "и также при аггрегации создаем вместе с mau считаем new_user_cnt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сколько времени в среднем проходит с момента первого посещения сайта до совершения покупки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте данные, чтобы рассчитать метрики отдельно за сентябрь, октябрь и ноябрь:\n",
    "1. Количество сессий (визитов).\n",
    "2. MAU.\n",
    "3. DAU.\n",
    "4. Revenue.\n",
    "5. ARPU.\n",
    "6. ARPPU.\n",
    "7. Session / user.\n",
    "8. Количество целевых действий (целевое действие — событие, за которое получен\n",
    "доход).\n",
    "\n",
    "Дополнительно рассчитайте показатель LTV на пользователя за период три месяца: с\n",
    "сентября по ноябрь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно можно расчитать долю новых покупателей, долю новых пользователей за период"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cogs (cost of good sold) - стоимость оказания услуги или товара (себестоймость 1 продажи или услуги)  \n",
    "1cogs - особенные затраты на 1 сделку (например, покупки по промокоду, тестовые периоды пользования услугой, мы при этом бесплатно оказываем всю услугу или часть)      \n",
    "cogs и 1cogs не имеют отношения к маркетингу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "при расчетах следующих метрик, нужно убедиться что поле в знаменателе не имеет нулей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "для когортного анализа колиества чего-то лучше делать отношение с начальным, как в retention.  \n",
    "Тогда удобно сравнивать динамику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие ещё метрики стоит считать  \n",
    "ВАЖНО: почти все эти метрики расчитываются на определнном периоде, поэтому нужно это всегда уточнять\n",
    "- $\\text{CAC} = \\frac{\\text{Marketing costs}}{\\text{Buyers}} $\n",
    "\n",
    "- $\\text{CPA} = \\frac{\\text{Marketing costs}}{\\text{Users acquisition}}$\n",
    "- $APC = \\frac{Orders}{Buyers}$\n",
    "- $\\text{C1} = \\frac{\\text{Buyers}}{\\text{Users acquisition}} $\n",
    "- $\\text{AOV} = \\frac{\\text{Revenue}}{\\text{Orders}} $\n",
    "- $\\text{ROMI} = \\frac{\\text{LTV}}{\\text{CARC}} * 100$\n",
    "- $\\text{ARPU} = \\frac{\\text{Revenue}}{\\text{users}} $\n",
    "- $\\text{ARPPU} = \\frac{\\text{Revenue}}{\\text{Buyers}} $\n",
    "- $\\text{ARPU} = \\text{ARPPU} * \\frac{\\text{Buyers}}{\\text{users}} = \\text{ARPPU} * \\text{C1}$\n",
    "- $\\text{ARPPU} = {\\text{APC}}*{\\text{AOV}} $\n",
    "- $\\text{gross profit} = \\text{Users} * ((\\text{AOV} - \\text{cogs}) * \\text{APC} - \\text{1cogs}) * С1 - \\text{CPA}$\n",
    "- $Margin(\\%) = \\frac{AOV - COGS}{AOV}$\n",
    "- $Margin(\\%) = \\frac{Revenue - Costs}{Revenue} = \\frac{Margin}{Revenue}$\n",
    "- $\\text{Costs} = {\\text{Marketing Costs}} + {\\text{COGS}}*{\\text{Orders}} + {\\text{1st COGS}}* {\\text{Buyers}} +  {\\text{fix COGS}}$\n",
    "- $\\text{Monthly Sticky Factor} = \\frac{\\text{DAU}}{\\text{MAU}}$\n",
    "- $\\text{Weekly Sticky Factor} = \\frac{\\text{DAU}}{\\text{WAU}}$\n",
    "- $ASL = \\frac{\\text{total session time by period}}{\\text{number of sessions by period}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способы расчета LTV  \n",
    "ВАЖНО: \n",
    "LTV расчитываются на определнном периоде, поэтому нужно это всегда уточнять и ARPU тогда должна быть расчитана на этот же период и  \n",
    "lifetime долен иметь изменрение такого же периода (то есть если ARPU за месяц, то lifetime в месяцах)  \n",
    "Лучше всего считать LTV через когорты, тогда нам не нужен lifetime  \n",
    "Расчет через валовую прибыль\n",
    "- $\\text{LTV} = \\text{margin rate} * \\frac{\\text{Total revenue by period}}{\\text{total users by period}}$\n",
    "- $\\text{LTV} = \\text{margin rate} * \\text{ARPU} * \\text{Lifetime}$\n",
    "- $ \\text{LTV} = \\text{(ARPU - CAC + CRC)} * \\text{Lifetime} $\n",
    "\n",
    "Расчет через выручку:\n",
    "- $\\text{LTV} = \\frac{\\text{Total revenue by period}}{\\text{total users by period}}$\n",
    "- $\\text{LTV} = \\text{ARPU} * \\text{Lifetime}$\n",
    "- $\\text{LTV} = \\text{AOV} * \\text{APC}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы рассчитать lifetime, нужно узнать Churn Rate за определенный период, который будет размерностью lifetime, то есть период должен быть таким же как в расчете ARPU\n",
    "\n",
    "$\\text{Lifetime} = \\frac{1}{\\text{Churn Rate}} $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ltv лучше считать по когортам  \n",
    "И когда составили матрицу когорт, то уже успреднить каждый месяц жизни и потом суммировать все месяца (именно так, вертикально усредняем, горизонтально суммируем)  \n",
    "\n",
    "В иделае считать не просто среднее значение по когортам, а средневзвешенное.  \n",
    "То есть если мы хотим посчитать среднее значение по всем когортам какого-то показателя, то мы не просто суммируем все значения в когортах и делим на  \n",
    "число когорт, мы взвешиваем какждое значение когорты.  \n",
    "Есить 2 способа\n",
    "- умножать значение каждой когорты на ее размер и потом всю эту сумму разделить на общий размер всех когорт\n",
    "- сразу дать веса каждой когорты, то есть определить долю каждой когорты в общем.  \n",
    "Берем размер когорты и делим на размер всех когорт. И потом умнажаем значения в когортах на коэффиценты.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "для всех метрик, считаем среднее (или мода или медиана) за все время, изображаем на графике во времени и в идеале строим когортный анализ.  \n",
    "То есть у нас должно быть аггрегированное за все время значение, разбитое во времени и разбитое по когортам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продуктовые метрики, которые полезно считать  \n",
    "- MAU, DAU, WAU  \n",
    "за весь период, динамика во времени по периодам\n",
    "- сколько раз за день пользователи в среднем заходят на сайт. график, отражающий изменения метрики во времени.\n",
    "    Сколько сессий в день можно нести два смысла\n",
    "    - сколько всего сессий в среднем проходит в день  \n",
    "    покажет среднюю нагрузку в день на сервис\n",
    "    - сколько в среднем совершает сессий 1 пользователь в день  \n",
    "    покажет поведение посетителей на платформе (как часто  они в днеь появляются)   \n",
    "- сколько времени пользователи проводят на сайте. график во времени  \n",
    "- продолжительность типичной пользовательской сессии за весь период. Чтобы выбрать подходящую среднюю меру, постройте график распределения. График во времени  \n",
    "    - рисуем гистограму или violine\n",
    "    - вычисляем все средние меры и выбираем наиболее подходящую из них и приводим число  \n",
    "    Если среднее, мода и медина примерно равны, то можно брать среднее.  \n",
    "    Но если они разные, то нужно подумать какое лучше взять и обосновать выбор.  \n",
    "    Как всегда пишем причины, почему выбрали эту метрику.  \n",
    "    Тут важно какой вопрос, если вопрос сколько обычно длиться одна сессия, и у нас ненормальное распределение длительностей сессий,  \n",
    "    то среднее значение будет некоректно, так как обычно в данном случае это будет мода, так как среднее будет  \n",
    "    смещенно вправо, елси у нас экспоненциальное распределение времени.  \n",
    "    Вот этот момент очень важен.  \n",
    "    Так как среднее введет в заблуждение.  \n",
    "    Обычно сессия длить как раз модальное значение.  \n",
    "- Рассчитайте Retention Rate, применяя когортный анализ. Покажите изменения метрики во времени на графике. Найдите средний Retention Rate на второй месяц «жизни» когорт.  \n",
    "    - расчитываем retention rate, для этого\n",
    "    - необходимо сделать когортный анализ по времени (по месяцам или неделям или дням и тп)  \n",
    "    Чтобы сделать когортный анализ, мы по одной оси откладываем даты, а по второй оси откладываем номер месяца,  \n",
    "    таким образом мы получим для одной даты разные значения retention rate черзе 1, 2, 3, 4 и так далее месяцев  \n",
    "    Будет динамика по месяцам от стартового месяца.  \n",
    "    Также дополнительно можно сделать тепловую карту времени и какой-нибудь каетгории (например возраст, пол польователей),  \n",
    "    retention rate можно считать просто относительно предыдущего месяца (тут уже не будет динамики по месяцам)\n",
    "\n",
    "    Ответ среднее значение, тепловая карта выводы  \n",
    "    Для описания тенденции, берем среднее значение за первый период (после нулевого) и смотрим как дальше относительно этого значения  \n",
    "    идут изменения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики электронной коммерции\n",
    "- сколько времени в среднем проходит с момента первого посещения сайта до совершения покупки. график во времени   \n",
    "    Нужно ответить на 2 вопроса\n",
    "    - Через сколько времени после первого посещения пользователь совершил первую покупку?  \n",
    "    - В какую по счету сессию люди начинают покупать?\n",
    "    Ответом будет среднее значение метрики (обоих вариантов) и выводы  \n",
    "    Дополнительно можно попробовать построить бар чар и посмотреть эти значения в разрезе какой-то категории\n",
    "- AOV. Применяя когортный анализ или другой метод, рассчитайте среднее количество покупок на одного покупателя за определённый период, например за 6 месяцев. график во времени\n",
    "    то есть сколько в среднем один покупатель делает покупок за период  \n",
    "    Для выбора периода нужно понять какой период нам лучше подходит, например если у нас данные за год,  \n",
    "    то период 6 месяцев будет нормально. \n",
    "    - Суммируем все покупки за все периоды и делим на количество покупателей, которое было в нулевой период  \n",
    "    Берем суммирем все покупки за первые 6 месяцев всех пользователей и   \n",
    "    делим на общее число пользователей в начале периода (в первый месяца)   \n",
    "    Важно уточнение за какой период  \n",
    "    Для расчета показателей за период X месяцев можно использовать только данные  \n",
    "    - по когортам, которые взаимодействуют с компанией в течении X месяцев или более  \n",
    "    - за первые X месяцев жизни когорт  \n",
    "- Рассчитайте средний чек, применяя группировку по времени совершения покупки. Когортный анализ не подходит — он может исказить расчёты. Постройте график, отражающий изменения метрики во времени.\n",
    "- Выясните, как меняется LTV на покупателя по когортам. Помните, что LTV — накопительная метрика. Рассчитайте средний LTV по когортам за 6 месяцев; в расчёт включайте когорты, «прожившие» не менее 6 месяцев. Маржинальность сервиса — 100%. Отразите изменения метрики во времени на графике;\n",
    "В финансовом менеджменте ответ на вопрос когда, также важен как ответ на вопрос сколько.  \n",
    "Тут важно указывать за какой промежуток, так как LTV считается за период и еденица периода должна идти в ответе.    \n",
    "Например, 3 y.e. это неверно    \n",
    "правильно будет 3 y.e./год   \n",
    "Тут у нас еденица расчета ltv это год     \n",
    "Для выбора периода нужно понять какой период нам лучше подходит, например если у нас данные за год,  \n",
    "то период 6 месяцев будет нормально. \n",
    "И нельзя сравнивать ltv за разные периоды.  \n",
    "Если мы выбрали год, то мы берем отсечку год от первого сессии и считаем сколько всего люди все потратили за это время  \n",
    "и делим на количество людей в первый период.  \n",
    "Очень частая ошибка считать сначала среднее по разным периодам (например среднее людей, которые прожили месяц, потом 2 и так далее),  \n",
    "а потом усреднять эти значения.  \n",
    "Тут нужно суммировать все доходы от всех и разделить на количество пользователей на старте.  \n",
    "Когорты это хорошо, но их нужно считать отдельно и не выводить из них общее среднее для всех.    \n",
    "Чтобы проверить правильно ли мы рассчитали LTV можно сравнить его с   \n",
    "LTV = среднее число покупок за выбранный период на одного пользователя * средний чек   \n",
    "До этого мы как раз посчитали среднее число покупок за период на одного пользователя и средний чек.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маркетинговые метрики  \n",
    "- Посчитайте общую сумму расходов на маркетинг. Выясните, как траты распределены по источникам. Визуализируйте изменения метрик во времени;\n",
    "(значит нужно изучить как данные по расходам в всего изменяются во времени)  \n",
    "Ответ среднее занчение, график, выводы (можно сравнить с общей прибылью и можно cac сравнить с ltv)  \n",
    "график затрат на маркетинг не только по периодам, но ещё график затрат по источникам (бар плот и heatmap)  \n",
    "и сделать вывод какие источники самые затратные, какие менее затратные  \n",
    "- Рассчитайте средний CAC на одного покупателя для всего проекта и для каждого источника трафика. Отразите изменения метрик на графиках\n",
    "Важно, что метрика рассчитывается по покупателям, поэтому нам нужно использовать только тех, кто совершил хотя бы одну покупку  \n",
    "Сложность в том, что пользователи заходят с разных источников.  \n",
    "Возможные решения этой проблемы    \n",
    "    - вычислить в какую именно сессию была совершена покупка и привязать ее именно к этому источнику (с которого эта сессия произошла)\n",
    "    - привязать пользователя к тому источнику, с которого он чаще заходил  \n",
    "    - привязать пользователя к источнику, с которого он первый раз зашел на сервис     \n",
    "    этот метод предпочтительнее    \n",
    "Ответ - среднее значение метрики в целом и по разным источникам  \n",
    "таблица средних значений метрики по источника или/и график (бар плот)\n",
    "выводы\n",
    "-  Рассчитайте ROMI по когортам в разрезе источников. Сравните окупаемость за одинаковые периоды жизни когорт. Обратите внимание, что клиенты, пришедшие из разных источников, могут иметь разный LTV. Постройте графики, отражающие изменения метрик во времени.  \n",
    "Окупаемость считаем не от выручки, а от LTV (в целом и по источникам)  \n",
    "Не забывать про сопостовляемый период (как с LTV)\n",
    "Ответ - среднее значение метрики, таблица средних значений метрики по источникам и графики (бар плот и heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Все метрики нужно посмотреть в разрезе разных параметров (которые есть, например, по платформам, полу пользователй и другим категориям) и сделать выводы,  \n",
    "о том как параметр влияет на каждую метрику. Посмотреть как они меняются во времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если нам нужно выбрать главные метрики, которые нужно изучить, если у нас слишком много метрик или мало времени,  \n",
    "то собираем все метрики в датафрейм и строим матрицу корреляций.  \n",
    "И берем те метрики, которые имеют наибольшую корреляцию с целевой метрикой, чаще всего выручкой (60-70+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Выводы должны не просто описывать графики, а содержать рекомендации.  \n",
    "И общий вывод должен включить все метрики, которые мы получили (числами).  \n",
    "И сделать вывод основываясь на всех полученных метриках, а не просто сказать, что вот этот канал лушче других.  \n",
    "То есть в какой канал рекламы лучше направить больше выручки, какая категория больше приносит выручки (можно сделать предоложения почему). \n",
    "И итоговый вывод это всегда рекомендация что можно сделать, чтобы улучшить сервис, основываясь на полученных данных.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Сначал смотрим общую картину. Общую выручку, общие расходы, рентабельность и другие бизнес метрики, а потом уже спускаемся к детальным метрикам.  \n",
    "Хорошая проверка, это когда мы сначала просто смотрим выручку и расходы и получаем вывод о окупаемости сервиса.  \n",
    "А потом когда разобрали по метрикам, то результат должен сходиться, не должно быть так, что выручка - расходы говорит, что все плохо,  \n",
    "а выводы по метрикам, что все хорошо.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что можно дополнительно посчитать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- накопительная сумма продаж    \n",
    "- остаток на балансе (количество пришедших едениц минус количество ушедших)   \n",
    "- накопительный остаток   \n",
    "- создание категориальной переменной новый / постоянный клиент. Считаем для каждого клиента дату первой покупки,  если текущая дата  \n",
    "равна минимальной, то это новый. Также можно добавить, что если прошло больше N дней, то тоже новый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Производные метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут пишем разные производные метрики из имеющихся переменных.  \n",
    "Тут будут те метрики, которые нельзя отнести к остальным подразделам метрик. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ключевые показатели эффективности (KPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финансовые KPI\n",
    "\n",
    "- Выручка — общий доход от продаж товаров или услуг.\n",
    "- Прибыль — разница между доходами и расходами.\n",
    "- Рентабельность — отношение прибыли к выручке или к активам.\n",
    "- Коэффициент ликвидности — способность компании покрыть свои краткосрочные обязательства.\n",
    "- Себестоимость продаж — общие затраты на производство товаров или услуг.\n",
    "\n",
    "Операционные KPI\n",
    "\n",
    "- Производительность — количество продукции, произведенной за единицу времени.\n",
    "- Уровень запасов — количество товаров на складе в данный момент времени.\n",
    "- Время выполнения заказа — время, необходимое для обработки и доставки заказа.\n",
    "- Качество продукции — процент бракованных изделий или уровень удовлетворенности клиентов.\n",
    "\n",
    "Маркетинговые KPI\n",
    "\n",
    "- Стоимость привлечения клиента (CAC) — затраты на привлечение одного клиента.\n",
    "- Конверсия — процент пользователей, совершивших целевое действие (например, покупку).\n",
    "- Возврат на инвестиции в маркетинг (ROMI) — прибыль, полученная от маркетинговых кампаний.\n",
    "- Трафик на сайт — количество посетителей на сайте.\n",
    "\n",
    "KPI для HR\n",
    "\n",
    "- Текучесть кадров — процент сотрудников, покинувших компанию за определенный период.\n",
    "- Уровень удовлетворенности сотрудников — измеряется через опросы и анкетирования.\n",
    "- Среднее время найма — время, необходимое для заполнения вакансии.\n",
    "- Процент выполнения целей сотрудников — доля сотрудников, достигших своих KPI.\n",
    "\n",
    "KPI для обслуживания клиентов\n",
    "\n",
    "- Уровень удовлетворенности клиентов (CSAT) — измеряется через опросы после обслуживания.\n",
    "- Чистый промоутерский балл (NPS) — измеряет лояльность клиентов.\n",
    "- Время ответа на запросы — среднее время, необходимое для ответа на запросы клиентов.\n",
    "- Процент решенных проблем с первого обращения — доля запросов, решенных при первом контакте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Финансовые метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выручка\n",
    "- Прибыль\n",
    "- Рентабельность\n",
    "- Операционные расходы\n",
    "- Кэш-флоу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Маркетинговые метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Стоимость привлечения клиента (CAC)\n",
    "- Пожизненная ценность клиента (LTV)\n",
    "- Конверсия\n",
    "- ROI (возврат на инвестиции)\n",
    "- Охват и вовлеченность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Операционные метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Эффективность процессов\n",
    "- Время выполнения заказа\n",
    "- Уровень запасов\n",
    "- Производительность труда\n",
    "- Уровень дефектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики пользовательского опыта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Удовлетворенность клиентов (CSAT)\n",
    "- Чистый промоутерский балл (NPS)\n",
    "- Время на сайте\n",
    "- Показатель отказов\n",
    "- Количество активных пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики продаж"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Объем продаж\n",
    "- Средний размер сделки\n",
    "- Темп роста продаж\n",
    "- Доля рынка\n",
    "- Уровень удержания клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики производительности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Время выполнения задач\n",
    "- Эффективность использования ресурсов\n",
    "- Уровень производительности сотрудников\n",
    "- Качество продукции\n",
    "- Время простоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики веб-аналитики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Посещения\n",
    "- Уникальные посетители\n",
    "- Время на странице\n",
    "- Конверсии по каналам\n",
    "- Источники трафика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики социальных медиа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Подписчики\n",
    "- Вовлеченность (лайки, комментарии, репосты)\n",
    "- Охват постов\n",
    "- Темп роста подписчиков\n",
    "- Анализ упоминаний бренда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики HR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Уровень текучести кадров\n",
    "- Удовлетворенность сотрудников\n",
    "- Время на заполнение вакансий\n",
    "- Эффективность обучения\n",
    "- Уровень вовлеченности сотрудников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Уровень удовлетворенности клиентов\n",
    "- Количество жалоб\n",
    "- Соответствие стандартам\n",
    "- Время на исправление дефектов\n",
    "- Показатели качества продукции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики продукта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финансовые метрики:\n",
    "\n",
    "- Выручка: общий доход от продаж.\n",
    "- LTV (Lifetime Value): пожизненная ценность клиента, показывающая, сколько дохода приносит клиент за все время взаимодействия с продуктом.\n",
    "- CAC (Customer Acquisition Cost): стоимость привлечения одного клиента.\n",
    "- ARPU (Average Revenue Per User): средний доход на пользователя.\n",
    "\n",
    "Метрики вовлеченности:\n",
    "    \n",
    "- DAU (Daily Active Users): количество уникальных пользователей, которые взаимодействуют с продуктом ежедневно.\n",
    "- WAU (Weekly Active Users): количество уникальных пользователей за неделю.\n",
    "- MAU (Monthly Active Users): количество уникальных пользователей за месяц.\n",
    "- Retention Rate: процент пользователей, которые продолжают использовать продукт после определенного периода.\n",
    "\n",
    "Метрики конверсии:\n",
    "\n",
    "- Conversion Rate: процент пользователей, которые выполняют целевое действие (например, покупка, регистрация).\n",
    "- Churn Rate: процент пользователей, которые перестают использовать продукт за определенный период.\n",
    "\n",
    "Метрики качества:\n",
    "\n",
    "- NPS (Net Promoter Score): показатель лояльности клиентов, основанный на их готовности рекомендовать продукт.\n",
    "- CSAT (Customer Satisfaction Score): уровень удовлетворенности клиентов продуктом.\n",
    "Метрики использования:\n",
    "\n",
    "- Average Session Duration: среднее время, проведенное пользователем в приложении или на сайте.\n",
    "- Bounce Rate: процент пользователей, которые покидают сайт после просмотра только одной страницы.\n",
    "\n",
    "Метрики роста:\n",
    "\n",
    "- GMV (Gross Merchandise Value): общий объем продаж товаров через платформу.\n",
    "- Monthly Recurring Revenue (MRR): ежемесячный повторяющийся доход, особенно важен для подписочных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Экономические метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> тут будут расчеты экономических метрик\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если расчет метрик является важным аспектом вашего исследования и требует подробного описания, то создание отдельной главы будет лучшим решением.  \n",
    "> Если в этом разделе будет немного расчетов, то можно сделать расчеты метрик разделом предобработки данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Расчитываем разные метрики на основе имеющихся данных и тех, которыми смогли обогатить данные\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важно следить за количеством недель в году, если мы создаем столбец месяца.  \n",
    "> Проверять чтобы у нас не появлялась неделя дополнительная, из за того, что мы захватили предыдущий год\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финансовые метрики:\n",
    "\n",
    "- Выручка: общий доход от продаж товаров или услуг.\n",
    "- Прибыль: разница между выручкой и затратами, показывающая финансовый результат деятельности.\n",
    "- Рентабельность: отношение прибыли к выручке, выраженное в процентах, что позволяет оценить эффективность использования ресурсов.\n",
    "\n",
    "Метрики затрат:\n",
    "\n",
    "- Себестоимость: общие затраты на производство и продажу товаров или услуг.\n",
    "- Операционные расходы: затраты, связанные с основной деятельностью компании, включая зарплаты, аренду и коммунальные услуги.\n",
    "\n",
    "Метрики ликвидности:\n",
    "\n",
    "- Текущая ликвидность: отношение текущих активов к текущим обязательствам, показывающее способность компании покрывать краткосрочные долги.\n",
    "- Коэффициент быстрой ликвидности: более строгий показатель ликвидности, исключающий запасы из текущих активов.\n",
    "\n",
    "Метрики эффективности:\n",
    "\n",
    "- ROE (Return on Equity): доходность собственного капитала, показывающая, насколько эффективно компания использует средства акционеров.\n",
    "- ROA (Return on Assets): доходность активов, отражающая, как эффективно используются все активы компании для генерации прибыли.\n",
    "\n",
    "Метрики роста:\n",
    "\n",
    "- Темпы роста выручки: процентное изменение выручки за определенный период, показывающее динамику бизнеса.\n",
    "- Темпы роста прибыли: процентное изменение прибыли, что позволяет оценить финансовую устойчивость и развитие компании.\n",
    "\n",
    "Метрики инвестиционной привлекательности:\n",
    "\n",
    "- P/E (Price to Earnings Ratio): соотношение цены акции к прибыли на акцию, используемое для оценки стоимости компании.\n",
    "- EV/EBITDA (Enterprise Value to Earnings Before Interest, Taxes, Depreciation, and Amortization): показатель, который помогает оценить стоимость компании относительно ее операционной прибыли."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы собрать все наблюдения используем это  \n",
    "нужно поставить `_pagristart_` где начало и `_pagriend_` где конец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем удалить метки `_pagristart_` и `_pagriend_` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.collect_observations(notebook_path, '/home/pagri/git_repos/pagri-projects/quarto/projects/prospective_tariff_for_telecom/temp_for_report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация взаимосвязей переменных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала пишем ИИ все наши таблицы и названия переменных, которые были и которые создали.  \n",
    "И спрашиваем какие зависимости нужно изучить. Пишем напиши подробный список.  \n",
    "Далее это вставляем в temp.ipynb и когда будем изучать то смотрим.  \n",
    "И в конце убедиться, что мы это все изучили. Если нет, то отедльно строим графики для этого.  \n",
    "Также в процессе сами думаем какие зависимости стоит изучить,  \n",
    "когда ИИ нам напишет список.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "не забываем, что легенду можно двигать куда нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_layout(legend_x = 0.6, legend_y = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Когда смотрим графики и не видим явных различий, то нельзя сразу пропускать график, нужно подумать важная ли это зависимость для нас.  \n",
    "Если нам это важно и значения не прям идеально ровно расположены, то сохраняем график и сразу пишем в temp.ipynb для гипотезы вывод.\n",
    "Гипотезы формулируем для случаев, когда на графике нет явных различие числовой переменной по категории.  \n",
    "Если различия явные, то нет смысла  проводить тест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Сезонность это не только, когда покупают шорты летом, также сезонностью может быть какие-то события, которые влияют на продажи.  \n",
    "Например, вышел фильм, где актер был в шляпе и прочее. Также сезоность может быть редкой, например, во время олимпиады увеличивается спрос на спорт товары.  \n",
    "Важно, когда мы видим на графике аномалию, то подумать сезоность ли это. С чем это связано.  \n",
    "Аналитик не просто константирует факт, он ищет причину и выдвигает гипотезы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Смотрим и общую картину и по каждой нужно категории отедльно и делаем это за один проход, чтобы снова не проходить все данные.  \n",
    "И в такой последовательности мы можем сравнить общую картину и по каждой категории отдельно и сделать более точные выводы.\n",
    "В итоге будет график общей ситуации и далее графики по каждой категории.  \n",
    "Причем нужно определить, что для нас важно, что нужно отобразить в любом случае, даже если нет явных зависимостей.  \n",
    "А остальное сохраняем только то, что представляет интерес.  \n",
    "Схема следующая\n",
    "- Нужно выбрать важные категории и числовые переменные, которые мы хотим изучить отдельно.  \n",
    "- Когда изучаем графики, то изучаем всю картину целиком и затем изучаем отдельно каждую категорию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Когда мы анализируем данные и у нас в категории болше 10 значений, то по возможности нужно брать топ 5-10 значений на графиках.  \n",
    "Нас в основном интересует топ 5-10 значений, а не все значения.  \n",
    "Бывают исключения, но чаще всего нам интересно оп 5-10 значений.  \n",
    "И тогда анализировать графики будет проще. И выводы можно будет сделать точнее.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас было несколько таблиц и мы создали общую из нескольких, то изучать нужно общую.  \n",
    "Или как минимуму общую тоже, так как будет ошибкой, изучить только исходые таблицы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Не далать выводы только по абсолютным значениям, если они зависят от других значений.  \n",
    "Например, у нас 2 отдела продавали машины, один отдел продал 100 машин, другой 1000 машин.  \n",
    "Казалось бы второй отдел справился лучше. Но если мы учтем, что у первого отдела было 500 машин, а у второго 100 000, то первый отдел продал больше машин в долевом выражении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнительный анализ распределений числовых переменных по категориям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем каждую числовую переменную и строим накладывающиеся гистограммы для всех категорий.  \n",
    "И так повторяем для всех числовых переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Строим накладывющиеся гистограммы или боксплты / violin для всех числовых переменных.  \n",
    "Нужно изучить все числовые переменные и сравнить их распределения и сделать выводы какие лучше и прочее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "смотрим на выбросы  \n",
    "Мы могли при изучении отдельных столбцов не заметить их, если заметили, то возвращаемся в изучение и предобработку и изучаем их дополнительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "категориальные переменные могут быть не только в отдельном столбце.  \n",
    "Категориальная переменная может быть разбита на разные столбцы.  \n",
    "Например, оценка пользователей и оценка критиков могут быть в отдельных столбцах.  \n",
    "Нужно при предобработке это не забыть привести  к категориальному типу, чтобы далее анализировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если создали категориальную переменную есть пропуск или нет, то тут по ней тоже смотрим накладывающиеся гистограммы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "наложенные гистограммы нужно сделать не только для категориальных переменных.  \n",
    "У нас могут быть 2 числовые переменные, которые мы решили не соединятьь через melt  \n",
    "Но они имеют похожую природу. Для таких случаев тоже нужно сделать гистограммы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Когда посторили боксплоты\n",
    "- сравниваем медианы, квартили, делаем выводы\n",
    "- сравниваем количество выбросво\n",
    "- сравниваем размахи внутри квартилей\n",
    "- сравниваем iqr\n",
    "- смотрим пересекаются ли irq у разных категорий, если не пересекаются, то это говорит о существенном отличии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сормируем словарь для подписей осей и названий графиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column ['Именительный падеж', 'для кого / чего']\n",
    "    avg_score = ['Средняя оценка', 'средней оценки']\n",
    "    # categorical column ['Именительный падеж', 'для кого / чего']\n",
    "    # Распределение долей по городу и тарифу с нормализацией по городу\n",
    "    , genre = ['Жанр', 'жанра']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим накладывающиеся гистограммы для нужных числовых переменных в рарзрезе нужных категорий   \n",
    "в `histograms_stacked` есть `mode` со значениями`step` и `normal`  \n",
    "Если у нас категория имеет мало значений, то можно normal  \n",
    "Если у нас категория имеет много значений, то step  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас числовая переменная разбита на несколько столбцов, то сначала мелтим ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем melt для преобразования данных\n",
    "value_vars = ['critic_score', 'user_score']\n",
    "melted_df = pd.melt(df, # id_vars=df.columns.difference(value_vars), \n",
    "                    value_vars=value_vars,\n",
    "                    var_name='score_type', value_name='score')\n",
    "# Словарь для замены значений\n",
    "region_mapping = {\n",
    "    'critic_score': 'Оценка критиков',\n",
    "    'user_score': 'Оценка пользователей',\n",
    "}\n",
    "# Замена значений в столбце region\n",
    "melted_df['score_type'] = melted_df['score_type'].replace(region_mapping).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    df = df\n",
    "    , cat_var = 'genre'\n",
    "    , num_var = 'avg_score'\n",
    "    , top_n=3\n",
    "    , lower_quantile=0\n",
    "    , upper_quantile=1\n",
    "    , bins=20\n",
    "    , line_width=3\n",
    "    , opacity = 0.6\n",
    ")\n",
    "pagri_data_tools.histograms_stacked(config=config, titles_for_axis=titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим накладывающиеся боксплоты для нужных числовых переменных в рарзрезе нужных категорий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть несколько категориальных переменных и одна из категорий имеет мало значений, то строим в разрезе 2-х категорий  \n",
    "для этого добавляем `legend_var`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    df = df\n",
    "    , cat_var = 'genre'\n",
    "    , num_var = 'avg_score'\n",
    "    , top_n='all'\n",
    ")\n",
    "pagri_data_tools.boxplots_stacked(config=config, titles_for_axis=titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим накладывающиеся violin для нужных числовых переменных в рарзрезе нужных категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    df = df\n",
    "    , cat_var = 'genre'\n",
    "    , num_var = 'avg_score'\n",
    "    , top_n='all'\n",
    ")\n",
    "pagri_data_tools.violins_stacked(config=config, titles_for_axis=titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование корреляционных связей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следим за правильным порядком переменных полученных из времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы подготовить title_for_axis, пишем ии так  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "запомни - total_images = ['Число фотографий', 'числа фотографий', 0], - тут первый элемент списка это общая форма и с большой буквы, второй элемент это форма первого элемента при ответе на вопрос Чего и третий элеент списка это род элемента (0 - средний род, 1 - мужской род, 2 женский род) понятно?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и далее даем список нужных названий колонок в таком виде "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корреляций достаточно просто указать название без рода и склонения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сормируем словарь для подписей осей и названий графиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titles_for_axis= dict(\n",
    "        total_images = 'Число фотографий',\n",
    "        last_price = 'Цена',\n",
    "        total_area = 'Общая площадь',\n",
    "        rooms = 'Число комнат',\n",
    "        ceiling_height = 'Высота потолков',\n",
    "        floors_total = 'Всего этажей',\n",
    "        living_area = 'Жилая площадь',\n",
    "        floor = 'Этаж'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "проверить, что все категориальные переменные по прежнему имеют категориальный тип, чтобы при анализе они не поетрялись"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Изучаем корреляцию на всем периоде данных и на отдельных периодах (например последние N лет, месяцев, дней)  \n",
    "Также нужно посмотреть корреляцию в определенные периоды, для этого разбить нарпимер, на кварталы, сезоны или по другим категориям.  \n",
    "И посмотреть корреляции в каждом срезе.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dict(\n",
    "            df_users = df_users\n",
    "            , df_calls = df_calls\n",
    "            , df_messages = df_messages\n",
    "            , df_internet = df_internet\n",
    "            , df_tariffs = df_tariffs\n",
    "            , df_calls_full = df_calls_full\n",
    "            , df_messages_full = df_messages_full\n",
    "            , df_internet_full = df_internet_full\n",
    "            , df_by_userid_month = df_by_userid_month\n",
    "            , df_arpu = df_arpu).items():\n",
    "    print(key)\n",
    "    display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Топ n значений одного столбца по значениям в другом\n",
    ">Сделать функцию, чтобы в столбцах, где бльше 20 уникльных значений посмотреть топ n значений по другой колонке.  \n",
    ">Например, топ 10 покупателей по сумме покупок и прочее.  \n",
    ">Идея в том, что если  в столбце до 20 уникальных значений, то мы проанализируем комбинации с другими стобцами на графиках.  \n",
    ">А вот если у нас столбец не числовой и в нем больше 20 уникальных значений, то на графике мы не сможем понять топ n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем топ n значений в категориальных столбцах датафрейма, где значений больше порогового, по значению в столбце value_column.  \n",
    ">Тут можно делать разные топы, использовать разные функции.  \n",
    ">Задача изучить то, что мы не сможем изучить на графиках из-за болшого количества занчений в категориальной переменной,  \n",
    ">поэтому мы берем топ n значений.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.top_n_values_gen()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы сравнить метрики между собой мы можем\n",
    "- использовать корреляционный анализ (Пирсена, Спирмена, Кенделла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`heatmap_corr(df)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( r = 1 ): Полная положительная линейная зависимость.  \n",
    "( 0.7 < r < 1 ): Сильная положительная линейная зависимость.  \n",
    "( 0.3 < r \\leq 0.7 ): Умеренная положительная линейная зависимость.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если числовых переменных не много и они входят на один график, то просто строим график"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Посмотреть корреляцию в каждой категории категориальной переменной.  \n",
    "То есть задача взять категориальную переменную и посмотреть корреляцию для каждой категории отедльно.  \n",
    "Это важно, так как во всех категориях суммарно может затеряться зависимости.  \n",
    "Не нужно все их помещать в отчет, наша задача найти важные существенные зависимости и их уже пометсить в отчет.  \n",
    "Но чтобы их найти, нужно смотреть не только на картину в целом, но изучить корреляции в каждой категории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на коэффициенты корреляции между числовыми переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.heatmap_corr(df, titles_for_axis=titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше лишние ячейки убирать, если есть возможность "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.heatmap_corr(df_by_userid_month[['sessions_per_day', 'calls_per_day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нужно быстро просмотреть, то проганяем в цикле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dict(\n",
    "            df_users = df_users\n",
    "            , df_calls = df_calls\n",
    "            , df_messages = df_messages\n",
    "            , df_internet = df_internet\n",
    "            , df_tariffs = df_tariffs\n",
    "            , df_calls_full = df_calls_full\n",
    "            , df_messages_full = df_messages_full\n",
    "            , df_internet_full = df_internet_full\n",
    "            , df_by_userid_month = df_by_userid_month\n",
    "            , df_arpu = df_arpu).items():\n",
    "    print(key)\n",
    "    display(pagri_data_tools.heatmap_corr(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если переменных много и нужно разделить на части, то используем эту функцию "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pagri_data_tools.heatmap_corr_gen(df, part_size=10, titles_for_axis=titles_for_axis)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Использование регрессии и случайного леса для определения влияния переменных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Коэффициенты регрессии позволяют оценить влияние каждой переменной на целевую переменную, учитывая влияние других переменных,  \n",
    ">в то время как важные компоненты в случайном лесе позволяют оценить важность каждой переменной для предсказания целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Используем регрессиию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы построить регрессию и посмотреть стат значимость и коэффициенты удобно использовать модуль statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">VIF означает Variance Inflation Factor (Фактор инфляции дисперсии). Это статистическая метрика,   \n",
    ">используемая для обнаружения мультиколлинеарности (сильной корреляции) между предикторами (фичами) в линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Обычно, VIF интерпретируется следующим образом:\n",
    ">\n",
    "- VIF < 5: слабая мультиколлинеарность\n",
    "- 5 ≤ VIF < 10: умеренная мультиколлинеарность\n",
    "- VIF ≥ 10: сильная мультиколлинеарность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    ">Смотрим R2 (коэффициент детерминации)\n",
    "- использовать коэффициенты у регресси\n",
    ">Мы строим регрессию и смотрим, у каких метрик больше коэффициенты. Таким образом мы поймем какие метрики сильнее зависят с целевой.  \n",
    ">Важно, чтобы независимые переменные некоррелировали по отдельности и вместе (мультиколлиниарность).  \n",
    ">По отдельности смотрим матрицу корреляции.  \n",
    ">Чтобы определить коррелириуют ли вместе, береме независимые переменные,  \n",
    ">и перебираем их выбирая одну из них целевой и смотрим R2.  \n",
    ">Если R2 большой, то значит эта метрика (которая целевая на этом шаге) хорошо описывается другими и ее можно выбросить.\n",
    ">Также не забываем поправки на гетероскедостичность (HC0, HC1, HC2, HC3) в статпакетах.  \n",
    ">Нам нужно ответить на следующие вопросы\n",
    ">    - Влияет ли метрика на целевую?\n",
    ">    Оцениваем коэффициенты в уравнении регресси у каждой метрики.  \n",
    ">    - Как влияет метрика на целевую?\n",
    ">    Смотрим R2 (коэффициент детерминации). И определяем какая часть целевой переменной определяется независимыми метриками.  \n",
    ">    - Коэффициенты при метриках в уравнении статистически значим? При какаом уровне значимости?\n",
    ">    Смотрим в стат пакете p value для каждого коэффициента, что нам говорит значим ли этот коэффициент.  \n",
    ">    То есть мы не просто смотрим его абсолютное значение, а учитываем p value.   \n",
    ">    - Дайте содержательную интерпретацию коэффицентам?\n",
    ">    При увеличении метрики k на 1, целевая метрика увеличивается на $b_{k} * 1$\n",
    ">    То есть нужно перевести коэффициенты в реальное сравнение, насколько увелчисться целевая метрика при изменении определенной метрики на 1\n",
    ">    - Найдите 95 процентный доверительный интервал.\n",
    ">    В стат пакете смотрим значение и оно говорит, что если мы многократно повторим ноши вычисления с новыми данными, то 95 процентов наших  \n",
    ">    полученных коэффицентов будут лежать в этом диапазоне.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим модель и изучаем результат  \n",
    ">`linear_regression_with_vif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.linear_regression_with_vif()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Испльзовать коэффициенты у классификацию    \n",
    ">Строим случайный лес какие метрики сильнее всего влияют на решения модели.   \n",
    ">`plot_feature_importances_classifier`   \n",
    ">`plot_feature_importances_regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Тут нужно подумать как использовать категориальные переменные тоже   \n",
    ">Нужно их перевести в one hot encoding или подобное, чтобы также проверить силу их влияния на целевую перменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    debt = 'долга'\n",
    "    , children = 'Кол-во детей'\n",
    "    , age = 'Возраст'\n",
    "    , total_income = 'Доход'\n",
    ")\n",
    "title = 'График важности признаков для предсказания цены'\n",
    "pagri_data_tools.plot_feature_importances_classifier(df, target='debt', titles_for_axis=titles_for_axis, title=title)\n",
    "pagri_data_tools.plot_feature_importances_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">На основе полученных данных формулируем гипотезы, которые будем проверять в блоке проверки гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> используем быблиотеку `shap`, чтобы определить метрики, которые лучше других помогают предсказывать целевую перемменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавить в dash app возможность сохранять код для ячейки с фильтром (срезом данных).  \n",
    "То есть у нас есть фильтр, мы хотим посмотреть срез данных и фильтруем данные.  \n",
    "И если увидели что-то важное, то мы сохраняем код для создания графика с этими x, y, category и фильтром.  \n",
    "То есть в коде сначала будет фильтрация датафрейма и потом создание графика в 2 строки.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "важно мы не пишем все наблюдения, а только те, которые могут быть важны для анализа, то есть мы смотрим, задаем вопросы данным и   \n",
    "и если ответ важен, то мы записываем наблюдения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "Когда мы видим таблицу или график, то мы придумываем вопросы к результату.  \n",
    "Все возможные вопросы (как, почему, зачем, сколько, как долго, быстро ли, медленно ли, важно ли это, из-за чего это и прочие вопрсоы)\n",
    "И отвечая на эти вопросы мы получаем наблюдения и выводы\n",
    "И чтобы задавать правильные вопросы, мы должны сначала подумать о физике параметров, которые мы видим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас много значений в переменной, то мы агрегируем данные и можем построить бары.  \n",
    "Но если мы агрегируем данные по переменной, в которой много значений и нам это нужно.  \n",
    "То мы не сможем построить бары, и тогда мы строим гистограмму. То есть мы берем, например, для каждой заправки считаем среднее время заправки и так как у нас много заправок,  \n",
    "но мы хотим визуализировать среднее время по ним, и не агрегировать по другому параметру, то мы можем испльзовать гистограмму.  \n",
    "В данном случае гистограмма своего рода агрегация в бины, то есть мы получаем как бы новую переменную из бинов, в каждом бине будет агрегированы данные.  \n",
    "Это работает, когда нам нужно просто посмотреть колечество, так как в бинах будет количество. Таким образом мы получаем сколько у нас заправок имеют определенное среднее вермя заправки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Про размер графиков  \n",
    "> Стандартный размер графиков width=600, height=400  \n",
    "> Для более сложных графиков, когда требуется больше места для отображения данных, можно использовать размеры width=800, height=600 или width=1000, height=800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сравнивать количество элементов нужно в абсолютных и относительных величинах.  \n",
    "> Когда мы сравниваем только в абсолютных величинах, мы не учитываем размеры групп.  \n",
    "> В одной группе может быть элементов больше чем в другой и тогда сравнение будет не совсем точным.  \n",
    "> Если у нас 2 категориальные переменные, то мы можем сравнивать отностельные величины  \n",
    "> по одной переменной, а можем по другой.  \n",
    "> Это как сравнивать суммарный возраст в группах, это не дает полной картины и мы сравниваем средний возраст,  \n",
    "> чтобы размер группы не влиял.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ВАЖНО\n",
    "> Анализ графиков и выводы для них должны полностью перекрывать постановку задачи и цель.  \n",
    "> Это значит, что если цель проанализировать зависимость наличия долга, то мы в идеале должны проанализировать  \n",
    "> влиянеие каждой переменной на наличие долга (числовой и категориальной)  \n",
    "> Кончено нужно проанализировать все возможные зависимости.  \n",
    "> Но все зависимости с переменной в постновке задачи мы обязаны проверить и дать выводы. И о наличии и об отсутствие.  \n",
    "> Важные выводы делаем не только о наличие интересных моментов, но и об отсутствие.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сначала раздел графиков  \n",
    "> На основе графиков формируются гипотезы (например, у нас у мужчин зп больше)\n",
    "> И после раздела графиков идет раздел проверки гипотез. Тут мы првоеряем разные гипотезы новые и те, что увидели на графиках.  \n",
    "> Это правильная последовательность сначала изучили графики и потом на основе их сформировали гипоетзы\n",
    "> Перед разделом про графики идет раздел с корреляцией и поиском главных компонет случайного леса.  \n",
    "> Мы выбиарем переменную, для которой мы далее хотим посмотреть разыне зависимости и указываем ее целевой для сучайного леса  \n",
    "> И смотрим какие фичи сильнее влияют.  \n",
    "> И теперь можем построить графики с целевой перменно и этими главными фичами и в выводе можно указать про то что это важные компоненты случаного леса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> На основе полученных данных формулируем гипотезы, которые будем проверять в блоке проверки гипотез\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение зависимостей между числовыми переменными\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим дендогрммы для числовых переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данных много, то делаем сэмплирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df.sample(n=10, random_state=42)  # random_state для воспроизводимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дендограммы можно использовать в анализе данных без машинного обучения для визуализации иерархической структуры данных, определения оптимального числа кластеров и выявления выбросов. Они помогают исследовать скрытые закономерности и взаимосвязи в данных, что делает их полезными в различных контекстах. Рассмотрим основные случаи использования дендограмм в анализе данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Визуализация иерархической структуры:  \n",
    "Дендограммы позволяют визуально представить, как объекты или наблюдения группируются в кластеры на разных уровнях иерархии. Это помогает понять, какие элементы имеют схожие характеристики.\n",
    "- Определение числа кластеров:  \n",
    "Анализ высоты соединений в дендограмме может помочь определить оптимальное количество кластеров. Это особенно полезно, когда заранее неизвестно, сколько кластеров следует выделить.\n",
    "- Анализ расстояний между объектами:  \n",
    "Дендограммы показывают расстояния между кластерами, что позволяет оценить степень сходства или различия между группами данных.\n",
    "- Выявление выбросов:   \n",
    "Дендограммы могут помочь в обнаружении выбросов. Если отдельные наблюдения объединяются с другими на значительно большом расстоянии, это может указывать на их аномальность.\n",
    "- Сравнение различных наборов данных:  \n",
    "Дендограммы могут быть использованы для сравнения различных наборов данных или методов анализа. Это позволяет визуально оценить, как разные данные или методы приводят к различным результатам.\n",
    "- Исследовательский анализ данных:  \n",
    "Дендограммы могут быть полезны в исследовательском анализе данных для выявления скрытых закономерностей и взаимосвязей, что может привести к новым гипотезам и направлениям для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "# Пример данных\n",
    "data = {\n",
    "    'Feature1': [1.0, 2.0, 1.5, 8.0, 8.5, 9.0],\n",
    "    'Feature2': [1.0, 1.5, 1.2, 8.0, 8.5, 9.0],\n",
    "    'Category': ['A', 'A', 'A', 'B', 'B', 'B']  # Категориальный признак\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Выбор числовых признаков\n",
    "numerical_data = df[['Feature1', 'Feature2']]\n",
    "\n",
    "# Стандартизация данных\n",
    "scaler = StandardScaler()\n",
    "numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
    "\n",
    "# Вычисление иерархической структуры для дендограммы\n",
    "linked = linkage(numerical_data_scaled, method='ward')\n",
    "\n",
    "# Построение дендограммы с использованием Plotly\n",
    "fig = ff.create_dendrogram(linked, orientation='bottom')\n",
    "fig.update_layout(title='Dendrogram for Numerical Features',\n",
    "                  xaxis_title='Distance',\n",
    "                  yaxis_title='Observations',\n",
    "                  width=800,\n",
    "                  height=600, \n",
    "                  )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики рассеяния и изучим зависимости.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Изучаем зависимости между числовыми переменными без фильтрации и с фильтрацией.  \n",
    "То есть нужно взять и пройти по каждой категории и посмотреть на зависимости в каждой категории.  \n",
    "Возможно даже в комбинации категорий.  \n",
    "Так как в общей картинке зависимости могут затеряться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО смотрим на выбросы  \n",
    "Мы могли при изучении отдельных столбцов не заметить их, если заметили, то возвращаемся в изучение и предобработку и изучаем их дополнительно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {('total_images', 'last_price'): None, ('total_images', 'floors_total'): {'total_images': [-2.15, 22.45], 'floors_total': [0.51, 28.54]}, ('total_images', 'kitchen_area'): {'total_images': [-1.04, 28.44], 'kitchen_area': [-0.6, 59.26]}, ('total_images', 'parks_nearest'): {'total_images': [np.int64(0), np.int64(50)], 'parks_nearest': [np.float64(1.0), np.float64(3190.0)]}, ('total_images', 'ponds_around3000'): {'total_images': [np.int64(0), np.int64(50)], 'ponds_around3000': [np.float64(0.0), np.float64(3.0)]}, ('total_images', 'living_total_ratio'): {'total_images': [np.int64(0), np.int64(50)], 'living_total_ratio': [np.float64(0.02), np.float64(1.0)]}, ('total_images', 'kitchen_total_ratio'): {'total_images': [np.int64(0), np.int64(50)], 'kitchen_total_ratio': [np.float64(0.03), np.float64(0.79)]}, ('total_images', 'price_per_sqm'): {'total_images': [np.int64(0), np.int64(50)], 'price_per_sqm': [np.int64(7962), np.int64(1907500)]}, ('last_price', 'living_area'): {'last_price': [np.int64(430000), np.int64(763000000)], 'living_area': [np.float64(2.0), np.float64(427.55)]}}\n",
    "pagri_data_tools.pairplot_pairs(df, pairs, coloring=True, horizontal_spacing=0.12, rows=3, cols=3).show(config=dict(displayModeBar=False, dpi=200), renderer=\"png\")\n",
    "# если нужно интерактивый график, то\n",
    "pagri_data_tools.pairplot_pairs(df, pairs, coloring=True, horizontal_spacing=0.12, rows=3, cols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы в dash app выбрать нужные пары для scatterplot   \n",
    "ставим  `_gen_` в месте где хотим чтобы появились ячейки с кодом для постройки графиков      \n",
    "далее используем  `pagri_dash.scatterplot_analysis_dash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "убираем лишние колонки, которые нам не нужно изучать, например, id, и другие числовые переменные, которые будут только тратить место в dash app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_userid_month.drop(['user_id', 'messages_included'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "pagri_dash.scatterplot_analysis_dash(df, \"path/to/notebook/for/save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение зависимостей между категориальными переменными\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы автоматически генерировались подписи осей и заголовок графика для категориальных, временных и числовых с категориальными зависимостейь\n",
    "> , нужно заполшнить такой словарь.  \n",
    "> Первый элемент списка - это подпись оси  \n",
    "> Второй элемент списка - это как это название будет отображаться в заголовке графика  \n",
    "> Для числовых столбцов также указывается род, чтобы правильно выбрать (Середнее, средний, средняя) (0 - средний род, 1 - мужской род, 2 - женский род)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "для долей очень важно отображать количество,  поэтому если входит на график, то отображаем значнеия долей над барами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Когда у нас 2 категории на графике долей, то у нас есть 2 варианта отображения - одна легенда, другая по оси и наоборот.  \n",
    "И также для каждой нормализации.  \n",
    "В итоге у нас для 2 категорий может быть 6 вариантов.  \n",
    "Нужно посмотреть все варианты и решить, какой лучше доносит информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО построить распределение количества по категориальным переменным без разбивки по другим категориям.  \n",
    "То есть например, посмотреть количество новых пользователей по месяцам, по кородам и так далее.  \n",
    "И так все количества, и не только категориальные.  \n",
    "Это важно, так как по этим графикам будет видна общая динамика без разбивки на категории.  \n",
    "И плюс всякие user_id и прочее в dash app не отображается, поэтому нужно это изучить отдельно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Добавить возможность выбирать 1 col и 2 cols  как это в app dash числовые и категориальные  \n",
    "Так как часто полезно посмотреть на распределение количества только в одной категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Среднее / Медианное / Суммарное {numeric} в зависимости от {category} и {category}'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "titles_for_axis далее будет один для всех разделов  \n",
    "поэтому если нужно добавить, то возвращаемся и добавляем сюда, чтобы была одна переменная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бывает полезно посмотреть сравнение по месяцам, дням, годам униклальных значений и всех занчений.  \n",
    "Подумать есть ли у нас подобные ситуации, для которох можно постриоть такой график"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рассмотрим количество выпущенных игр за весь период наблюдений и сравним количество всего и уникальных игр\n",
    "sum_un=df.pivot_table(index='year_of_release', values='name', aggfunc=lambda x: len(x.unique())) #Количество выпускаемых игр\n",
    "sum_total=df.pivot_table(index='year_of_release', values='name', aggfunc='count') #Количество выпускаемых игр с учетом релиза на разных платформах\n",
    "graph=sum_un.merge(sum_total, left_index=True, right_index=True)\n",
    "fig = px.line(graph)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сормируем словарь для подписей осей и названий графиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column ['Именительный падеж', 'мменительный падеж с маленькой буквы', 'род цифорой']\n",
    "    # (0 - средний род, 1 - мужской род, 2 - женский род[) (Середнее образовние, средний доход, средняя температура) )\n",
    "    # для функций count и nunique пишем - Количество <чего / кого количество> - и также с маленькой буквы, цифра 0 в качестве рода\n",
    "    age = ['Возраст', 'возраст', 1]\n",
    "    , using_duration = ['Длительность использования', 'длительность использования', 2]\n",
    "    , mb_used = ['Объем интернет трафика', 'объем интернет трафика', 1]\n",
    "    , revenue = ['Выручка', 'выручка', 2]\n",
    "    # categorical column ['Именительный падеж', 'для кого / чего', 'по кому чему']\n",
    "    # Распределение долей по городу и тарифу с нормализацией по городу\n",
    "    , city = ['Город', 'города', 'городу']\n",
    "    , tariff = ['Тариф', 'тарифа', 'тарифу']\n",
    "    , is_active = ['активный ли клиент', 'активности клиента', 'активности клиента']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно когда мы смотрем очередной график, то задавать не только вопросы к данным, но и думать как можно отфильтровать  \n",
    "данные, чтобы сделать дополнительные полезные выводы.  \n",
    "То есть мы фильтруем данные и потом эти графики поместим в раздел с анализом срезов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы в dash app выбрать нужные пары для scatterplot   \n",
    "ставим  `_gen_` в месте где хотим чтобы появились ячейки с кодом для постройки графиков      \n",
    "далее используем  `pagri_dash.scatterplot_analysis_dash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правильно писать выводы для нормализации по col и row:\n",
    "В dash app нормализация идет по значениям в легенде,   \n",
    "Например, у нас по index - город, а по столбцам - тарифы.\n",
    "- нормализация по index (в dash будет row)  \n",
    "При нормализации по индексам вы получаете долю пользователей каждого тарифа в каждом городе относительно общего числа пользователей в этом городе.\n",
    "то есть если по оси город, а в легенде название тарифа, то нормализация будет по тарифам.  \n",
    "И мы сравниваем \n",
    "А если в легенде город, то нормализация идет по городам, и мы сравниваем по городам.  \n",
    "И можно сделать такие выводы  \n",
    "    - В Москве 60% пользователей выбирают тариф \"Ультра\", что указывает на его популярность среди москвичей.\n",
    "    - В Санкт-Петербурге 70% пользователей предпочитают тариф \"Смарт\", что может говорить о том, что данный тариф более привлекателен для жителей этого города.\n",
    "то ессть при нормализации по городу, мы получаем долю пользователей тарифа в городе.  \n",
    "- нормализация по столбцам (в dash будет col)  \n",
    "При нормализации по столбцам вы получаете долю пользователей каждого города для каждого тарифа относительно общего числа пользователей, выбравших этот тариф.\n",
    "А когда мы нормализуем по тарифу, то мы получаем долю пользователей города в тарифе.      \n",
    "    - Из всех пользователей, выбравших тариф \"Ультра\", 40% приходятся на Москву, что может указывать на то, что этот тариф пользуется спросом именно в этом городе.\n",
    "    - Из всех пользователей, выбравших тариф \"Смарт\", 50% находятся в Санкт-Петербурге, что может свидетельствовать о том, что данный тариф более популярен среди петербуржцев.\n",
    "- Нормализация по всем значениям (в dash all)    \n",
    "При нормализации по всем значениям вы получаете долю пользователей каждого тарифа в каждом городе относительно общего числа пользователей всех тарифов в обоих городах.\n",
    "    - В общем числе всех пользователей (Москва и Санкт-Петербург) 30% выбирают тариф \"Ультра\", что может указывать на его общую популярность.\n",
    "    - Тариф \"Смарт\" составляет 20% от общего числа пользователей, что показывает, что он менее популярен по сравнению с тарифом \"Ультра\" на уровне всей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала смотрим 1_cat, чтобы записать распределение по 1 категории.  \n",
    "Не забываем делеть swap_cols чтобы изучить обе категориальные переменные.  \n",
    "Записываем, если есть различия в долях в категории.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "Если много значений и бары сливаютсю, то включаем heatmap  \n",
    "ВАжно не забывать, что heatmap для этого и нужен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "pagri_dash.category_analysis_dash(df, 'df', \"path/to/notebook/for/save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Строим матрицу тепловой карты для категориальных переменных и изучаем зависимости  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы в dash app выбрать нужные пары для scatterplot   \n",
    "ставим  `_gen_` в месте где хотим чтобы появились ячейки с кодом для постройки графиков      \n",
    "далее используем  `pagri_dash.scatterplot_analysis_dash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "pagri_dash.categorical_heatmap_matrix_dash(df, 'df', \"/home/pagri/git_repos/pagri-projects/quarto/projects/housing-ads-investigation/temp.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим на распределение количества элементов между группами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Нужно подумать как отобразить не только процент от всего количества, но и пороцент в группе  \n",
    "> То есть у нас есть значение в ячейке, сумма всех, сумма по категории на оси x и сумма по категории на оси Y  \n",
    "> Вот нужно как-то отобразить процент от суммы, процент от одной категории и от другой категории\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12 (0.5% of total, 20% of row, 15% of col) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно сделать кнопки, чтобы можно было подсветку делать внури колонок и строк\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно сделать кнопки (процент от общего) (процент от тут указывается название оси x) (аналогично для второй оси)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.categorical_graph_analys_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Строим treemap  \n",
    "> `treemap`  \n",
    "> `treemap_dash`\n",
    ">\n",
    "> ```\n",
    "> app = treemap_dash(df)\n",
    "> if __name__ == '__main__':\n",
    ">    app.run_server(debug=True)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "на treemap очень хорошо заметно выделяющиеся цепочки категорий по количеству.  \n",
    "Важно посмотреть по 3 и более категорий в ряд,  \n",
    "не нужно сильна всматриваться, задача заметить категории которые выделяются (будет явно больше прямоугольник)  \n",
    "И если нашли выделяющиеся важные категории, то сохраняем график и делаем выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.treemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pagri_data_tools.treemap_dash(df)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Строим parallel_categories  \n",
    "> `parallel_categories `  \n",
    "> `parallel_categories_dash `\n",
    ">\n",
    "> ```\n",
    "> app = treemap_dash(df)\n",
    "> if __name__ == '__main__':\n",
    ">    app.run_server(debug=True)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.parallel_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pagri_data_tools.parallel_categories_dash(df)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Строим Sankey  \n",
    "> `sankey `  \n",
    "> `sankey_dash`\n",
    ">\n",
    "> ```\n",
    "> app = treemap_dash(df)\n",
    "> if __name__ == '__main__':\n",
    ">    app.run_server(debug=True)\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.sankey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pagri_data_tools.sankey_dash(df)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение зависимостей между числовыми и категориальными переменными\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим графики для числовых переменных в разрезе категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "добавить слайдер как доп переменную и анимация будет сразу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.gapminder()\n",
    "\n",
    "fig = px.bar(df, x=\"continent\", y=\"pop\", color=\"continent\",\n",
    "  animation_frame=\"year\", animation_group=\"country\", range_y=[0,4000000000], width=900, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно когда мы смотрем очередной график, то задавать не только вопросы к данным, но и думать как можно отфильтровать  \n",
    "данные, чтобы сделать дополнительные полезные выводы.  \n",
    "То есть мы фильтруем данные и потом эти графики поместим в раздел с анализом срезов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно добавить кнопку среднее и количество  \n",
    "> Чтобы можно было посмотртеть распределение по количеству, когда смотрить среднее.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавить в hover количество элементов в группе,  \n",
    "чтобы понимать размер группы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавить возможность перескакивать комбинации.  \n",
    "Если много колонок, то комбинаций очень много и часть может быть просто не нужна для анализа.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучаем следующим образом  \n",
    "- смотрим на график и определяем есть ли взаимодейсвие (то есть отличаются ли значения в разных группах, это будет видно как разная высота баров)\n",
    "- если разницы в барах нет, или она минимальная, то сразу можно пропускать\n",
    "- если разница есть, то думаем важна ли для нас ээта комбинация столбцов\n",
    "- если нет, то пропускаем\n",
    "- если да, то пишем наблюдения и сохраняем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем смотреть 1_cat чтобы изучить отдельную категорию.  \n",
    "То есть график появлился, смотрим на обе категории и на числовую переменную и думаем, нужно ли нам по отдельности изучить  \n",
    "каждую категориальную переменную c числовой. Если уже изучили, то не изучаем.\n",
    "Нужно подумать как сохранять уже изученые комбинации, чтобы не повторяться (может в dash app добавить всплывающее окно, для графиков, для которых уже был вывод, что уже было)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если много переменных, и не все они нужны для анализа,  \n",
    "то смотрим df.columns, выбираем нужные и в dash передаем датафрейм с нужными колонками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "не забываем смотреть sum для переменных типа выручки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "id это такая же числовая переменная, как и все остальные, но ее нужно аггрегировать, используя  \n",
    "`count` и `nunique`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "для графика heatmap   \n",
    "важно смотреть по какой колоноке больше значений и ее делать по оси X  \n",
    "Так как ширина графика больше высоты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если на графика 2 категориальной переменной, то хороший размер 1000 на 450 (width на height)  \n",
    "Если на графике 1 категориальной переменной, то хороший размер 600 на 400 (width на height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у нас только 1 категорилаьная переменная, то добавляем временную и прям эту строку передаем в   \n",
    "`numeric_category_analysis_dash`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assign(temp=pd.Series(1, index=df.index).astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/pagri/git_repos/pagri_private_modules')\n",
    "import pagri_dash\n",
    "pagri_dash.numeric_category_analysis_dash(df, 'df', \"/home/pagri/git_repos/pagri-projects/quarto/projects/housing-ads-investigation/temp.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ временных зависимостей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим графики, представляющие различные временные переменные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Это раздел нужен, чтобы изучить тредны, сезонность и определить какие категории уже свое отжили, а какие перспективные.  \n",
    "Какие категории падают по продажам, может нужно с этим что-то сделать и так далее.\n",
    "Смотрим на графики с временными зависимостями и отвечаем на такие вопросы:\n",
    "- Есть ли категории, которые присутствуют не все время?\n",
    "Например, у нас продажи игр и есть категория платформы, мы построили график суммарных продаж по платформам и по годам. И видим, что явно   \n",
    "заметно, что платформа живет определенное время, так как есть пик продаж и потом продаж мало.\n",
    "- Есить ли тренды, сезонность, циклы?\n",
    "- Какие категории были популярны в прошлом, какие начинают становится популярными, какие показывают устойчивость долгое время\n",
    "- Какие категории будут популяны ближайшее время исходя из того в какой-момент времени они находятся сейчас и какие результаты показывали в прошлом и показывают сейчас. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "Обязательно смотрим heatmap для для всех числовых переменных в разрезе категорий по годам.  \n",
    "Этот график отлично показывает участки, когда категория была активно, динамику во времени и прочее.  \n",
    "По оси X идет время а по оси Y идет категория, и тогда каждая полоска это динами во времени, если например, у нас продажи,  \n",
    "то будет четко видно где спад, а где подъем, когда мы подкрашиваем значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим и из предыдущих разделов копируем все графики с временными переменными и вставляем сюда."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы хотим изучить верменную зависимость, то нам нуно создать новые переменные с обрезанными (trunc or round) значениям, чтобы можно было сгруппировать используя groupby or pivot_table  \n",
    "по этой обрезанной переменной и применить функцию агрегации и построить график, например, среднее время заправки на азс по часам.  \n",
    "Вот когда мы работаем с временем, нам нужно думать какие переменные создать, обрезая текущее время.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Строим когортный анализ, если есть возможность\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если у нас есть даты, то мы можем посмотреть не просто абсолютные значения на каждую дату какой-то метрики,  \n",
    "> а посмотреть относительные значения относительно предыдущего значения.  \n",
    "> Для этого нужно составить таблицу, в которой будет изменение в процентах относительно предыдущего значения.  \n",
    "> И затем визуализировать для каждой даты динамику этого показателя\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть время, то нужно посмотреть среднее время жизни определенных продуктов и прочее.  \n",
    "Тут важно, чтобы категории не жили все время, которое у нас есть в данных, иначе у всех будет одно время.  \n",
    "Это нужно делатЬ, если у нас есть категориальная переменная, занчения которой не всегда присутствуют.\n",
    "Например, у нас данные по годам продаж игр. Нужно взять продажи по годам и выбрать период, когда они активно продавались.  \n",
    "Это можно сделать через квантили или через 2-3 std.  \n",
    "Посчитать средене по всем играм.  \n",
    "Также у нас могут быть категории, например, платформы, тогда мы можем сагрегировать по платформам и посмотреть среднее время жизни платформы. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график времени жизни платформы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_lt = df.groupby('platform').agg({'year_of_release':'nunique'})\n",
    "px.bar(platform_lt, x=platform_lt.index, y='year_of_release')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем общее среднее время жизни платформы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Среднее время жизни платформы', df.groupby('platform').agg({'year_of_release':'nunique'}).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И так мы можем делать со всеми категориальными переменнми, если у нас есть временная переменная.  \n",
    "Схема такая\n",
    "- мы группируем по категорилаьной переменной и считаем уникльное количество нужных нам временных периодов.\n",
    "- строим график\n",
    "- считаем общее среднее время жизни"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И далее мы получаем временной интервал (среднее время жизни), который мы можем использовать для фильтрации.  \n",
    "То есть нам нужно определить перспективные направления в определенной категориальной перменной.  \n",
    "У нас сейчас нарпимер, 2015 год. Мы выяснили что среднее время жизни категории 5 лет.  \n",
    "Тогда мы смотрим сколько на момент 2015 года прожила каждая категория. И далее считаем сколько ей осталось ещё жить.  \n",
    "Сортируем по времени оставшейся жизни. В итоге получаем топ переспективных категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая схема такая\n",
    "- Выбираем категориальную переменную, в которой нам нужно определить перспективные категории.\n",
    "- Строим график для каждой категории ее вермени жизни. Делаем выводы.\n",
    "- Считаем среднее время жизни платформ (в идеале если есть другие категории, которые разделют категории на общие, то использовать расчет внутри подгруп).\n",
    "- Далее Берем актуальные на данный момент категории и считаем сколько они прожили к данному моменту.\n",
    "- Вычитаем среднее время жизни всех платформ и строим график топ по оставшемуся времени жизни.\n",
    "- Делаем выводы, какие категории будут лучше ближайшее время."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если нам нужно определить перспективные категории в будущем,  \n",
    "то нужно использовать среднее время жизни категории. И взять период от текущего момента минус среднее время жизни.  \n",
    "И изучить именно этот период. Так мы получим более точные результаты.  \n",
    "Для выбранного периода строим данные по количеству проданных копий, например, по сумме выручки.   \n",
    "Строим боксплоты или vilon рядом за этот временной период и сравниваем, какие категории дали лучше результаты.  \n",
    "И делаем выводы.  \n",
    "Таким образом важно изучить общие данные и данные за среднее время жизни категории отложенного от текущего момента назад.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Чтобы определить самую перспективную категорию, нужно взять отрезок времени от текущего минус среднее время жизни.  \n",
    "И построить например, график общих продаж по годам в разрезе категории. Таким образом мы увидим у кого прибыль расте, а у кого падает.  \n",
    "И так как мы значем среденее время жизни, то мы можем уже делать выводы о будущем.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Вообще очень важно на графиках, с временными зависимостями смотреть конечную дату и делать выводы, какие категории уже на спаде, а какие сейчас актуальны.    \n",
    "Это можно понять по графику суммарных продаж по годам, суммарной выручки по годам, количествую новых пользователей по годам и так далее.  \n",
    "Нужно делать, например, такие выводы:  \n",
    "    Эти платформы относительно молоды (3-5 лет), свой пик они уже прошли и не показывают потенциальных перспектив роста продаж, но их продажи пока выше остальных и какое-то время они способны продержаться на плаву и заполнить нишу на рынке игровых платформ, ведь геймеры никуда не делись. Мы не видим платформ моложе либо с тенденцией роста к концу 2016 года, поэтому есть смысл сделать ставки на эти три: большинство крупных проектов подошли к своему завершению, и между ними и новыми разработками, которые возможно скоро появятся на рынке, будет явный провал, который надо переждать для \"поддержания штанов\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, смотрим на график (это моежт быть и бары, лини и heatmap в зависимости от количества категорий),  \n",
    "и изучаем динамику. \n",
    "Пишем выводы, что данные категории уже не актуальны, что определенные категории набирают оброты, что другие категории показывают лучшую устойчивость..  \n",
    "Например - \n",
    "- Жанр А был популярен до Х года, но последнее время потерял популярность, это видно по суммарным продажам и количеству новых пользователей.\n",
    "- Жанр Б показвает устойчивый рост, что говрит о том, что он ещё будет определенное время популярным.\n",
    "- Жанр В только появился на рынке и показывает хорошие результаты, то есть он может быть перспективным.\n",
    "И так делаем выводы по каждой категории.  \n",
    "Суть в том, чтобы проанализировать динамику во времени.  \n",
    "Для этого и создается раздел анализ временных зависимостей, чтобы изучить тредны, сезонность и определить какие категории уже свое отжили, а какие перспективные.  \n",
    "Какие категории падают по продажам, может нужно с этим что-то сделать и так далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "пройти просмотреть все графики и где нужно изменить тип на линии  \n",
    "Если на графике динамика чего-то то линия лучше баров.  \n",
    "Если идет сравнение то бары лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Пройти просмотреть все графики  \n",
    "Где только 1 категориальная переменная сделать горизонтальную ориентацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Пройти просмотреть все графики и где нужно проставить числа над барами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАЖНО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Берем все датафреймы, которые анализировали.  \n",
    "- И по очереди выводим все колонки, с указанием категориальная, числовая или другая.  \n",
    "- Собираем все выводы от графиков. \n",
    "- И внимательно думаем, какие зависимости мы пропустили.  \n",
    "- Строим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_userid_month.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ срезов данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Посмотреть графики для каждой категории в нужных категориальных переменных. \n",
    "Например, у нас категориальная переменная регион.  \n",
    "Нужно посмотреть все зависимости для каждого региона отдельно и отобразить графики.  \n",
    "Схема следующая\n",
    "- Нужно выбрать важные категории и числовые переменные, которые мы хотим изучить отдельно.  \n",
    "- Когда изучаем графики, то изучаем всю картину целиком и затем изучаем отдельно каждую категорию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Не нужно для всех категорий строитьотдельные графики.  \n",
    "Тут логика следующая:\n",
    "- Если на одном графике помещются данные по всем топ 5 категорий и можно сразу увдиеть результат по отдельным категоирям, то нет смысла строить отдельно.  \n",
    "- Если же мы смотрим на график и нам охота посмотреть ситуацию по отдельной категории, то лучше простроить ее отдельно.  \n",
    "- Нужно смотреть по ситуации и в зависимости от того, насколько разбивка по категориям на одном графике показывает ситуацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "если у нас по условию задачи нужно сравнить что-то, то нужно построить наложенные гистограамы (в виде каги) каждой категории.  \n",
    "То есть если мы сравниваем тарифы, то нужно наложить гистограммы выручки, количества сообщений, звонков, гигабайт и так далее.  \n",
    "Таким образом мы не только сравниваем аггрегирующие метрики на графике, разбивая метрику по категории, но и   \n",
    "строим накладывающиеся гистограммы по каждой категории. Это очено важно, так как дает более глубокое сравнение.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще если есть время, то в идеале построить накладывющиеся гистограммы для всех важных числовых метрик по всем важным категориям.  \n",
    "То есть берем метрику и категориальную переменную и строим гистограмму.  \n",
    "Нужно сделать отдельную функцию.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас есть странные значения, например нулевая длительность звонков, или что-то подобное,   \n",
    "то это также является срезом, который нужно изучить. Не только при предобработке, когда мы смотрели это по категориям.  \n",
    "Тут мы не только смотрим по категориям на графиках, но ещё и смотрим все метрики и графики для этого среза или срезов.  \n",
    "Таким образом выбросы, пропуски и любые аномальные занчения, которые можно объеденить в группу, являются срезом.  \n",
    "И этот срез нужно отдельно изучить, построив все графики, которые строили для общего датафрейма.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас много пропусков (болше 20 процентов)  \n",
    "То можно создать категориальуню переменную (с пропусками / без пропусков) для каждой колонки с пропусками.  \n",
    "И изучить срезы отдельно. То есть сравнить их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Важно изучать топ N чего-то. Так как нас интересует увеличение результатов, и именно эти топ n уже показали результаты и нужно это изучить. И сделать выводы.  \n",
    "Смотрим на категориальные переменные и числовые переменные в разделе, где мы их изучали.  \n",
    "Отбираем нужные категории и числовые переменные. \n",
    "Категории мы также можем отобрать и в разделе изучения категорий, когда изучаем доли. То есть выбираем топ N не только по числовой переменной,  \n",
    "но и по количествую в категориальной переменной. То есть мы изучим отедльно самые распространенные категории.\n",
    "Выбрать топ 5 значений категориальной переменной по нужной количественной переменной.  \n",
    "И посмотреть их отдельно на одном графике вместе (то есть фильтруем 5 значений категориальной переменной по топ числовой переменной).  \n",
    "И каждую по отдельности.  \n",
    "Причем смотрим и распределения и средние значения и суммы по определенной числовой переменной.\n",
    "Схема такая\n",
    "- когда изучаем общие данные, выбираем категории и числовые переменные, которые можно изучить через топ N.\n",
    "- и в этом разаделе уже смотрим их по отдельности. Даже если мы до этого изучили всю картину и были графики, где эти категории уже есть в разрезе,  \n",
    "то для лучшего понимания картины тут тоже строим графики, но уже для выбранных категорий и далее по отдельности. Можно и распределения построить.  \n",
    "Задача проанализировать чем эти топ N категории отличаются от остальных.  \n",
    "Например у нас данные о продажах игр.  \n",
    "Мы построили график суммарных продаж и увидели, что определнное количество игр имеют болше результат чем другие (не обязательно 5, может быть и 2, 3, тут лучше ориентироваться на то, насколько выбранные отличаются от остальных, наша задача отобрать те, которые явно выделяются)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И так повторяем для всех важных категорий и числовых переменных.  \n",
    "Суть в том, чтобы проаназировать как ведут себя лидеры.  \n",
    "Также можно и изучить топ с самыми худшими результатами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Срезы нужно обязательно сравнить со всем датафреймом.  \n",
    "То есть мы например, изучили центр города и нужно сделать выводы основываясь на сравнении центра и всего города."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно создать 2 генератора и параллельно идти, чтобы сначала выводился срез, а потом уже целый датафрейм.  \n",
    "Тут наша задача не изучать выбросы, дубли и прочее.  \n",
    "Тут задача найти отличия среза от всего датафрейма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно лучше прйти все колонки так попарно, а потом выбрать только те, которые имеют отличия.  \n",
    "И построить только их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Еслиу нас есть временные переменные, то важно посмотреть графики за последние 10, 5, 3 или 1 год, в зависимости от задачи.   \n",
    "Так как важно проанализировать не только всю историю, но и последнее время, так как именно это время актуально.  \n",
    "Берем строим графики, например, суммарные продажи по жанрам за последние 3-5 лет и так далее.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Срезы нужны не только чтобы изучить отдельно часть данных, важно сравнивать срез со всем датафреймом.  \n",
    "Нужно подумать какие срезы будет полезно сравнить со всем датафреймом.  \n",
    "И провести сравнительный анализ. И поместить в отчет то, что имеет отличия и важно для выводов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто когда есть пользователи, то нужно изучить срезы активные и не активные пользователи.  \n",
    "И постараться понять что отличает не активных.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделать приложение dash чтобы можно было выбирать колонки для анализа,  \n",
    "чтобы можно было фильтровать по всем категориальным переменным,  \n",
    "чтобы были слайдеры для фильтрации по числовым переменным,\n",
    "чтобы можно было выбирать типы графиков и строить разные графики.  \n",
    "Это не генератор, а это для ad-hoc анализа.   \n",
    "То есть мы подумали что интересно будет изучить этот срез и эти переменные и изучили.  \n",
    "А потом можно подумать как это автоматиировать, чтобы в цикле строились нужные графики.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ срезов состоит из анализа срезов из одного значения, то есть мы выбираем конкретное значени и по  нему фильтруем.  \n",
    "и анализа срезов из нескольких переменных, когда мы выбираем несколько значений для среза или даже несколько переменных и в них выбираем определенные значения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ срезов по одному значению мы просто фильтруем по нему и смотрим результат функции `info_gen` или 'info_column'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А анализ срезво по нескольким значениям или переменным будет результатом анализа графиков в dash app.  \n",
    "То есть мы в процессе анализа фильтруем данные и после работы в dahs app мы фильтрованные графики помещаюем в этот раздел.  \n",
    "Чтобы разделить срезы и полный анализ.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Чтобы изучить активных и неактивных пользователей, нужно создать признак 'is_acitve'  \n",
    "И внимательно посмотреть на графики с временными зависимостями, где во времени идет сранвение по 'is_active'  \n",
    "Таким образом мы как бы посмотрим в прошлое, как вели себя пользователи, которые стали неактивными, и как вели себя активные пользователи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно подумать как лучше изучать срезы.  \n",
    "В данном разделе лучше изучить срезы отдельных значений, то есть отдельный город, отдельный пол и прочее.  \n",
    "То есть мы фильтруем по одному значению и его изучаем в функцией `info`  \n",
    "А изучение срезов данных, которые состоят из набора значений (например изучить цену в топ 10 городах), это уже будет сделано  \n",
    "в анализе графиков.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут мы изучаем подготовленный набор данных в разрезе разных категориальных переменных.  \n",
    "Задача посмотреть на отдельные срезы и найти закономерности в данных.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например у нас есть данные о продажах квартир, мы создали новые категориальные перменные, обогатили данные  \n",
    "И теперь хотим посмотреть какое распределение цены только в центре, или какая площадь квартир возле парков и прочее.  \n",
    "То есть мы тут изучаем отдельно переменные в разрезе категорий, то есть строим срезы.  \n",
    "ВАжно, что тут мы изучаем отедльные переменные, срезы в зависимостях переменных будем строить в разаделе визуализации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определить цель. Прежде чем начинать анализ срезов, важно четко определить, какие вопросы вы хотите ответить или какие гипотезы хотите проверить. Это может включать:\n",
    "- Сравнение различных групп (например, по возрасту, полу, региону).\n",
    "- Изучение влияния определенных факторов на целевую переменную.\n",
    "- Выявление аномалий или неожиданных паттернов в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор переменных для срезов. Выберите переменные, по которым вы хотите сделать срезы. Это могут быть как категориальные, так и количественные переменные. Примеры:\n",
    "- Категориальные переменные: пол, категория товара, регион, уровень образования.\n",
    "- Количественные переменные: возраст, доход, количество покупок (то есть мы можем просто взять срез с зарплатой до 100 тысяч и прочее, не обязательно иметь категорию для создания срезов, причем у нас может быть категория доходов, но срез мы можем взять в другом диапазоне)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно когда мы выбрали параметры по которым хотим сделать срез, то далее нужно выбрать условие по которому мы будем создавать срез.  \n",
    "Срез это фильтрация или группировка, то есть должна быть либо функция аггрегации или значения по которым мы будем фильтровть.  \n",
    "Например мы для среза выбрали параметр города. Теперь нам нужно отобрать города для среза.  \n",
    "Мы выбираем параметр количество объявлений (все зависит от цели, можно было выбрать и количество населения, значение других параметров, все что поможет нам создать топ)\n",
    "И далее по нему фильтруем или аггрегируем.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Срезы данных можно создавать различными способами. Вот несколько подходов:\n",
    "- Фильтрация данных: Используйте условия для выбора подмножеств данных.  \n",
    "Например, выберите только тех клиентов, которые находятся в определенном регионе или имеют доход выше определенного порога.  \n",
    "- Группировка данных: Используйте функции группировки (например, groupby в pandas для Python) для агрегирования данных по выбранным переменным.   \n",
    "Это позволяет вам получить сводные статистики по группам.\n",
    "- Кросс-табуляция: Для категориальных переменных создайте кросс-таблицы, чтобы увидеть взаимосвязи между переменными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ срезов. После создания срезов данных проведите анализ:\n",
    "- Статистический анализ: Рассчитайте основные статистики (среднее, медиана, стандартное отклонение) для каждой группы или среза. Это поможет вам понять, как различаются группы по ключевым показателям.\n",
    "- Визуализация: Постройте графики для визуального представления данных. Это могут быть:  \n",
    "Гистограммы для распределения количественных переменных.  \n",
    "Столбчатые графики для сравнения категориальных переменных.  \n",
    "Ящики с усами (boxplots) для визуализации разброса и выявления аномалий.  \n",
    "- Сравнительный анализ: Сравните срезы между собой. Например, как различается средний доход мужчин и женщин или как меняется поведение клиентов в зависимости от региона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы для среза выбрали одно значение (например конкретный город), то мы просто посмотреть результат функции`info` и проанализировать его  \n",
    "Но если мы выбрали для среза набор значений, то нам нужно уже построить графики для сравнения стат параметров или других аггреигующих параметров  \n",
    "для каждого занчения в срезе. То есть нам нужно выбрать параметры по которым мы будем сравнивать значения в срезе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильруем датасет по определенному значению и далее либо изучаем по отедльным столбцам, либо по всем испоьзуя генератор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть мы изучаем срез по одному значению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Созадем 2 генератора (или больше, если хотим сравнить несколько срезов), для среза и всего датафрейма и идем изучаем их вместе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно сделать отдельный генератор, чтобы в нем не было информации про пропуски, нули и прочее,   \n",
    "И организовать так, чтобы было удобно сравнивать.  \n",
    "Также гистограммы нужно сделать на одном графике, чтобы накладывлись друг на друга и сделать прозрачность.    \n",
    "Это очень удобно и если гистограммы будут накладываться друг на друга, то можно будет увидеть сразу отличия средних и мод на графике.    \n",
    "В идеале сделать, чтобы были не столбцы, а типа каги, то есть линия со ступеньками, так удобнее сравнивать гистограммы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "- в наблюдения пишем обязательно диапазон значений столбца.  \n",
    "Рынок жилья представлен объектами общей площадью от 12 до 900 кв.м. \n",
    "- пишем медианное занчение и по гистограмме и по квантилям определяем оснвоной диапазон.  \n",
    "В основном это жилье от 30 до 100 кв.м. с пиком в сегменте 30-75 кв.м  \n",
    "Это все нужно, чтобы потом сформулировать вот такой вывод (в оснвоном выводе отчета), то есть мы для разных столбцов пишем диапазоны,  \n",
    "основной дипазаон, медианы, моды, а потом уже собираем это в 1 или несколько выводов,  \n",
    "Например.  \n",
    "Рынок жилья представлен объектами общей площадью от 12 до 900 кв.м. В основном это жилье от 30 до 100 кв.м. с пиком в сегменте 30-75 кв.м. В жилой площади квартиры преобладает диапазон 15-50 кв.м. Размер площади кухни-от 5 до 15 кв.м., с пиком 9 кв.м. Это стандартные небольшие квартиры эконом-класса. Подавляющее большинство квартир- 1-3 комнатные, с высотой потолка 2,6-2,7 м., но встречаются редкие варианты до 19 комнат и высотой потолка до 20 кв.м. (либо ошибка, либо свободная планировка с возможностью многоуровневости).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы сраним диапазоны, моды, медианы в срезе и во всем датафйреме.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было бы идеально определить отличия в срезе и в общей картине, не просто сухими цифрами,  \n",
    "а собрать все наблюдения вместе и расписать это в подобном виде-   \n",
    "Рынок недвижимости центральной части города представлен несколько более широким по площади диапазоном : основная масса- это жилье от 30 до 150 кв.м с пиком в сегменте 45-80 кв.м. При этом жилая площадь занимает большую долю, чем среднестатистическая квартира: в центре СПб большое количество домов старой застройки, в которой пространство \"сдвинуто\" в пользу жилой площади. Особенностью этой части города является то, что большинство квартир, предлагаемых на продажу,- 2-3 комнатные: здесь в общей массе достаточно низкая доля 1-комнатного жилья и выше доля 4-комнатных квартир. Наибольшее количество предложений в абсолютном выражении (цена за объект) приходится на диапазон 5-15 млн.руб. с пиком 5-8 млн.руб.(маленькие квартиры эконом-класса), но есть и уникальные объекты стоимостью до 35 млн.руб. Стоимость квадратного метра недвижимости в основном варьируется от 70 до 150 тыс.руб. с пиком в 100 тыс.руб. Наряду с типовыми предложениями на продажу выставлено жилье со стоимостью 1 кв.м. до 266 тыс.руб за кв.м. В целом цены жилья центра города выше по цене, чем аналогичное в других районах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sliced = df[df.location_zone == 'Центр']\n",
    "gen_slice = pagri_data_tools.info_gen(df_sliced)\n",
    "gen = pagri_data_tools.info_gen(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(gen_slice)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если есть что-то важное и есть отличия, по которым можно сделать выводы, то строим отдельно в отчет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Центр города')\n",
    "pagri_data_tools.info_column(df_sliced, 'last_price')\n",
    "print('Весь датафрейм')\n",
    "pagri_data_tools.info_column(df, 'last_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**  \n",
    "- пишем тут наблюдения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Сравниваем не только отдельные столбцы с общей картиной.  \n",
    "Нужно взять срез и посмотреть на корреляцию, зависимости между числовыми, категориальными и т.д.  \n",
    "Как это делали для всего датафрейма, только в укороченной версии, то есть можно взять общей картины, что мы нашли интересного  \n",
    "(то есть взять названия столбцов) и посмотреть на эти же графики, но уже в срезах.  \n",
    "Если есть время, то можно и полностью прогнать все необходимые срезы по всем столбцам как для всего датафрейма.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезно изучить топ определенного столбца.  \n",
    "То есть нам нужно выбрать параметр по которому мы отберем топ значений для категорий.  \n",
    "Затем выбрать параметр для которого мы будем считать топ значений (числовая переменная)\n",
    "И построить топ.  \n",
    "Например, топ цен квартир в 10 городах с максимальным количеством объявлений.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cities = df.groupby('locality_name').size().rename('count').sort_values(ascending=False).to_frame().head(10)\n",
    "selected_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cities = selected_cities.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    df = df[df.locality_name.isin(selected_cities)]\n",
    "    , x = 'locality_name'\n",
    "    , x_axis_label = 'Название населённого пункта'\n",
    "    , y = 'price_per_sqm'\n",
    "    , y_axis_label = 'Цена квадратного метра'\n",
    "    , title = 'Цена кв метра в зависимости от населенного пункта'\n",
    "    , func = 'mean'\n",
    "    , width = None\n",
    "    , height = None\n",
    "    , orientation = 'v'\n",
    ")\n",
    "pagri_data_tools.bar(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Когортный анализ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим данные по когортам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "при когортном анализе мы строим матрицу, но обязательно посчитать среднее по когортам.  \n",
    "То есть берем например 6 месяцев (или другое количество lt, чтобы было достаточно когорт проживших такое время)   \n",
    "И усредняем по когортам. В итоге мы получим динамику метрики по времени жизни средней когорты.  \n",
    "И также нужно посчитать просто среднее значение. И можно делать выводы, используя все эти значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забывать про когортный анализ. Если у нас есть параметр, по которому мы можем наши данные разбить на когорты, то  \n",
    "> нужно разложить на когорты и посмотреть динамику по когортам.  \n",
    "> Когорты это например, пользователи пришедшие в одни день или месяц.  \n",
    "> Если мы объеденим пользователей в когорты и посмотрим динамику какого-то параметра по месяцам например, то увидим как изменяется.  \n",
    "> Тут также нужно помнить, что если значение например за 3 месяц больше значения за 4 месяц, то это ничего не значит само по себе.  \n",
    "> Так как мы имеем дело с выборкой, то нам нужно проверить статистически значимая это разница.  \n",
    "> Тут нам понядобятся стат тесты.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для когортного анализа нам нужно \n",
    "- сгруппировать по временному периоду\n",
    "- выбрать нужные метрики (одна или несколько), которые мы хотим расчитать для каждой когорты\n",
    "- аггрегировать данные по когортам и рассчитать аггрегированные метрики\n",
    "- если хотим посмотреть в разрезе каких-то категорий, то к аггрегации по когортам добавляем аггрегацию по этим категориям  \n",
    "При чем этими каетегориями могут быть не только время прощедшее с регистрации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каких метрик можно строить когортный анализ\n",
    "- выручка, количество заказов, количество клиентов, количество транзакций, средний чек, arpu, arppu и другие метрики\n",
    "- mau, dau, wau, retention rate, churn rate и другие метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы группируем по времени прощелшем с регистрации (или другой даты, по которой создана когорта), то периоды будут lifetime.  \n",
    "И можно сказать так - Retention Rate на нулевой месяц lifetime составит 100%  \n",
    "ВАЖНО   \n",
    "перед словом lifetime должна идти еденица измерения (день, месяц, год)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retantion rate и Churn rate можно считать относительно стартовой даты  \n",
    "churn rate = (активные в текущем месяце / активные в начальный месяц - 1) * 100  \n",
    "А можно считать относительно предыдущего месяца  \n",
    "churn rate = (активные в текущем месяце / активные в предыдущий месяц - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_activity_date = user_activity.groupby(['user_id'])['activity_date'].min()\n",
    "first_activity_date.name = 'first_activity_date'\n",
    "user_activity = user_activity.join(first_activity_date,on='user_id') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы группировать когорты по неделям, лучше всего использовать день начала недели, его можно рассчитать так"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим день начала недели, за которую произошло событие. Он станет идентификатором недели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit использоуется для подстраховки\n",
    "user_activity['activity_week'] = pd.to_datetime(\n",
    "    user_activity['activity_date'], unit='d'\n",
    ") - pd.to_timedelta(user_activity['activity_date'].dt.dayofweek, unit='d')\n",
    "user_activity['first_activity_week'] = pd.to_datetime(\n",
    "    user_activity['first_activity_date'], unit='d'\n",
    ") - pd.to_timedelta(\n",
    "    user_activity['first_activity_date'].dt.dayofweek, unit='d'\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для каждой строки датафрейма посчитаем lifetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity['cohort_lifetime'] = (\n",
    "    user_activity['activity_week'] - user_activity['first_activity_week']\n",
    ")\n",
    "user_activity['cohort_lifetime'] = user_activity[\n",
    "    'cohort_lifetime'\n",
    "] / np.timedelta64(1, 'W')\n",
    "user_activity['cohort_lifetime'] = user_activity['cohort_lifetime'].astype(\n",
    "    'int'\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгруппируем данные по когорте и lifetime. Посчитаем для каждой когорты количество активных пользователей на определённую «неделю жизни»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts = user_activity.groupby(['first_activity_week','cohort_lifetime']).agg({'user_id':'nunique'}).reset_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём исходное количество пользователей в когорте. Возьмём их число на нулевую неделю:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_users_count = cohorts[cohorts['cohort_lifetime'] == 0][\n",
    "    ['first_activity_week', 'user_id']\n",
    "]\n",
    "initial_users_count = initial_users_count.rename(columns={'user_id':'cohort_users'}) \n",
    "cohorts = cohorts.merge(initial_users_count,on='first_activity_week') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "рассчитаем Retention Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts['retention'] = cohorts['user_id']/cohorts['cohort_users'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найти Churn Rate просто — достаточно определить, на сколько пользователей в когорте становится меньше в сравнении с предыдущим периодом. Чтобы рассчитать этот показатель, вызовем метод pct_change() (от англ. percentage change, «процентное изменение»). Он позволяет вычислить процентное изменение значения в столбце относительно предыдущей строки датафрейма. Если применить его с группировкой, метод сработает внутри группы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию он сравнивает значения в строках, что полезно для анализа временных рядов. Вы можете указ ить ось для вычисления изменения по столбцам или задать период для расчета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts['churn_rate'] = cohorts.groupby(['first_activity_week'])['user_id'].pct_change() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также нужно построить churn rate относителльно стартового периода.  \n",
    "(текущее / стартовое - 1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поведенческие когорты  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это когортный анализ в разрезе каких-то категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суть в том, что нам нужно разбить пользователей на когорты (по сути тут просто категории) и для каждой из них сделать когортный анализ,  \n",
    "то есть создать когорты уже по времени действия для каждой категории и потом сравнить результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы провести поведенческий анализ, необходимо разделить пользователй по какому-то признаку и для каждой группы построить когортную матрицу,   \n",
    "или просто столбец (если мы просто хотим для каждой когорты получить аггрегированную метрики без разбивки по какой-то категории)   \n",
    "и далее визуализировать. Если матрица, то используем heatmap, если столбец, то используем barplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, у нас есть логи пользователей и категориальная переменная их действий (то есть где была активность)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем поведенческую когорту по типу события help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По каждому пользователю выделим дату совершения первого события и добавим её к датафрейму events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_event_datetime = events.groupby(['user_id'])['event_datetime'].min()\n",
    "min_event_datetime.name = 'min_event_datetime'\n",
    "events = events.join(min_event_datetime,on='user_id') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем пользовательскую когорту на основе события, совершаемого в первую неделю жизни пользователя в сервисе. Нужно рассчитать параметр, который позволит для каждого события определить, через какое время после первого события оно произошло.\n",
    "Создадим новый столбец time_to_event, содержащий время между событием и первым событием пользователя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['time_to_event'] = events['event_datetime'] - events['min_event_datetime'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужны лишь события типа help и только те, у которых после первого события прошло меньше 7 дней. Обратите внимание на применение среза по timedelta: можно просто указать количество дней. Это работает и с другими единицами измерения времени. Например, с минутами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_events = events[(events['event_type'] == 'help') & (events['time_to_event'] < '7 days')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгруппируем датафрейм по пользователям и подсчитаем количество совершённых действий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_events_by_users = filtered_events.groupby(['user_id']).agg({'event_datetime':'count'}).reset_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём медианное количество переходов в «Помощь» за первую неделю:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_events_by_users['event_datetime'].median()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим пользователей по целевому поведению, установив 5 обращений как рубеж:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_events_by_users['is_target_behavior'] = (\n",
    "    count_events_by_users['event_datetime'] > 5\n",
    ")\n",
    "\n",
    "user_ids_with_target_behavior = count_events_by_users[\n",
    "    count_events_by_users['is_target_behavior']\n",
    "]['user_id'].unique()\n",
    "user_ids_without_target_behavior = count_events_by_users[\n",
    "    ~count_events_by_users['is_target_behavior']\n",
    "]['user_id'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.loc[\n",
    "    events['user_id'].isin(user_ids_with_target_behavior),\n",
    "    'is_in_behavioral_cohort',\n",
    "] = 'yes'\n",
    "events.loc[\n",
    "    events['user_id'].isin(user_ids_without_target_behavior),\n",
    "    'is_in_behavioral_cohort',\n",
    "] = 'no'\n",
    "events['is_in_behavioral_cohort'] = events['is_in_behavioral_cohort'].fillna(\n",
    "    'no_behavior'\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как разделилось число пользователей между группами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.groupby('is_in_behavioral_cohort')['user_id'].nunique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем, как для каждой поведенческой когорты изменяется Retention Rate с течением времени. Выделим недельные когорты и подсчитаем относительную неделю lifetime пользователя в мобильном приложении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['event_week'] = pd.to_datetime(\n",
    "    events['event_datetime'].dt.date\n",
    ") - pd.to_timedelta(events['event_datetime'].dt.dayofweek, unit='d')\n",
    "events['min_event_week'] = pd.to_datetime(\n",
    "    events['min_event_datetime'].dt.date\n",
    ") - pd.to_timedelta(events['min_event_datetime'].dt.dayofweek, unit='d')\n",
    "\n",
    "events['cohort_lifetime'] = events['event_week'] - events['min_event_week']\n",
    "events['cohort_lifetime'] = events['cohort_lifetime'] / np.timedelta64(1, 'W')\n",
    "events['cohort_lifetime'] = events['cohort_lifetime'].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию расчёта и вывода Retention Rate в зависимости от lifetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRetentionRate(df):\n",
    "cohorts = df.groupby(['min_event_week','cohort_lifetime'],as_index=False).agg({'user_id':'nunique'}).sort_values(['min_event_week','cohort_lifetime'])\n",
    "\n",
    "inital_users_count = cohorts[cohorts['cohort_lifetime'] == 0][['min_event_week','user_id']]\n",
    "inital_users_count = inital_users_count.rename(columns={'user_id':'cohort_users'})\n",
    "\n",
    "cohorts = cohorts.merge(inital_users_count,on='min_event_week')\n",
    "\n",
    "cohorts['retention'] = cohorts['user_id']/cohorts['cohort_users']\n",
    "\n",
    "\n",
    "print (cohorts.groupby(['cohort_lifetime'])['retention'].mean())\n",
    "cohorts.groupby(['cohort_lifetime'])['retention'].mean().plot.bar() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь для каждой категории проведем когортный анализ и сравним категории между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printRetentionRate(events[events['is_in_behavioral_cohort'] == 'no_behavior']) \n",
    "printRetentionRate(events[events['is_in_behavioral_cohort'] == 'yes']) \n",
    "printRetentionRate(events[events['is_in_behavioral_cohort'] == 'no']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры вывыодов для когортного анализа когортной матрицы   \n",
    "После первого месяца количество покупателей в когорте снижается.  \n",
    "В некоторых когортах число покупателей периодически начинает расти. Например, в когорте 2010-12-01.  \n",
    "Количество покупателей уменьшается во всех когортах в декабре 2011. Возможно, это связано с сезонностью.  \n",
    "Пользователи когорты декабря 2010 года продолжают составлять большую долю покупателей даже спустя год. В ноябре 2011 года их 445.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отслеживание абсолютных показателей по месяцам позволяет исследовать изменения с течением времени. А также заметить общие черты в поведении всех когорт — например, обнаружить сезонное снижение числа пользователей. Можно сделать и вывод о доле каждой когорты в общем количестве покупателей месяца.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы строим когорты по месяцам, то количество дней в месяцах разное и при делениии на np.timedelta64(1, 'M') могут быть дробные числа, поэтому округляем до целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_grouped_by_cohorts['cohort_lifetime'] = orders_grouped_by_cohorts[\n",
    "    'cohort_lifetime'\n",
    "] / np.timedelta64(1, 'M')\n",
    "orders_grouped_by_cohorts['cohort_lifetime'] = (\n",
    "    orders_grouped_by_cohorts['cohort_lifetime'].round().astype('int')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим в данных о месяце первого заказа только год и месяц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_grouped_by_cohorts['first_order_month'] = orders_grouped_by_cohorts[\n",
    "    'first_order_month'\n",
    "].dt.strftime('%Y-%m') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "когортную матирцу изучаем целиком, делаем выводы, а потом находим значение метрик средней когорты,  \n",
    "для этого просто береме среднее занчение для каждого периода жизни когорты, то есть у нас есть певый месяц жизни для всех когорт,  \n",
    "это столбик в матрице чаще всего, вот мы его успредняем и в итоге у нас будет значение lifetime и значение метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFM анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_analysis = pd.DataFrame()\n",
    "# Recency (from calls)\n",
    "recency = calls.groupby('user_id')['call_date'].max()\n",
    "# Frequency\n",
    "frequency = calls.groupby('user_id')['id'].count()\n",
    "# Monetary (можно использовать duration или mb_used как прокси)\n",
    "monetary = calls.groupby('user_id')['duration'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы собрать все наблюдения используем это  \n",
    "нужно поставить `_pagristart_` где начало и `_pagriend_` где конец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем удалить метки `_pagristart_` и `_pagriend_` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.collect_observations(notebook_path, '/home/pagri/git_repos/pagri-projects/quarto/projects/prospective_tariff_for_telecom/temp_for_report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "пройти и отсортировать графики с одинаковыми числовыми переменными  \n",
    "То есть, чтобы 1 числовая переменная в разрезе разных категорий шли подряд.  \n",
    "То есть чтобы все графики с выручкой шли подряд, чтобы все графики по количеству звонков в разрезе разных категорий шли подряд.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "подумать для каждого раздела в визуализации (временные, числовые, категориальные и числовые с категориальными)  \n",
    "какие закономерности не проверил.  \n",
    "убедиться, что все зависимости, которые были в задании изучили.  \n",
    "Это самый важный моменты, тут лучше остановится и тщательно подумать,  \n",
    "так как могут быть изучены не все зависимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "Убедиться, что сетки по осям стоят где нужно, часто для вертикальных или горизонатльных графиков лишняя сетка вдоль баров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЧЕНЬ ВАЖНО  \n",
    "Когда построили все графики и собрали все выводы, то проходим снова и смотрим все графика, зная все выводы, и думаем какие выводы ещё можно сделать.  \n",
    "Так как в этом случае можно сделать выводы, на основе уже имеющихся, их объединяя или даже заметить что-то новое.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формулирование и провера гипотез\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формулирование гипотез\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Когда смотрим графики и не видим явных различий, то нельзя сразу пропускать график, нужно подумать важная ли это зависимость для нас.  \n",
    "Если нам это важно и значения не прям идеально ровно расположены, то сохраняем график и сразу пишем в temp.ipynb для гипотезы вывод.\n",
    "Гипотезы формулируем для случаев, когда на графике нет явных различие числовой переменной по категории.  \n",
    "Если различия явные, то нет смысла  проводить тест."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Если у нас числовая перменная разбита на 2 столбца, то также нужно проверить гипотезы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "это редко бывает, но нужно об этом помнить  \n",
    "Когда мы хотим проверить какую-то гипотезу на основе среднего или другой статистики, то нужно подумать нет ли сильного разделения на группы  \n",
    "по какой-нибудь категориальной переменной.  \n",
    "Если у нас есть такое разделение, то нужно использовать стратифицированную выборку.  \n",
    "То есть мы должны взять выборку из каждой группы пропорционально её размеру.  \n",
    "Считаем коэффициенты каждой группы (ее размер делим на количество всей выборки) и умнажаем их на количество нужных элементов.  \n",
    "То есть мы из каждой страты возьмем прпорциональное количество элементов.  \n",
    "Нарпимер, мы хотим сравнить средние значения дохода в двух компаниях.  \n",
    "И берем по 100 сотрудников из каждой. Без стратификации у нас редкие сотрудники могут не попасть.  \n",
    "Поэтому мы берем категориальную переменную (например должность) и делим выборку на группы. И из каждой берем пропорциональное количество элементов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим выводы раздела визуализации взаимосвязей и из них формулируем гипотезы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И далее думаем какие гипотезы можно ещё проверить, которых у нас нет в выводах.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе проведенного анализа данных сформулирем следующие гипотезы:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Гипотеза 1: Нет зависимость между наличием детей и возвратом кредита в срок.  \n",
    "- Гипотеза 2: У мужчин средний доход выше  \n",
    "- Гипотеза 3: Цель получения кредита не зависит от среднего ежемесяченого доход  \n",
    "- Гипотеза 4: Средний доход по семейному статусу одинаковый, но у вдовцов отличается  \n",
    "- Гипотеза 5: У должников в среднем больше детей  \n",
    "- Гипотеза 6: У должников средний возраст ниже  \n",
    "- Гипотеза 7: Медианный доход у должников и не должников не отличаетс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Не забываем что гипотезы можно проверять и между 2 категориальными переменными.  \n",
    "> Проверять есть ли между ними зависимости.  \n",
    "> Также если мы на графиках определили, что есть между 2 категориальными перменными связь, то тут можем это проверить\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка гипотез\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "принято в выводе писать положительный результат  \n",
    "то есть пишем что гипотеза подтвердилась и указваем какая гипотеза.  \n",
    "То если мы опровергли нулевую гипотезу, то пишем альтернативную гипотезу и пишем что она подтвердилась.  \n",
    "Если у нас нет оснований отвергнуть нулевую гипотезу, то пишем нулевую гипотезу и пишем что нет оснований ее отвергнуть.  \n",
    "То есть если мы отвергаем, то формулируем вывод как положительный, чтобы не было путаницы, а если нет оснований, то так и пишем.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Алгоритм проверки статистических гипотез\n",
    "\n",
    "- постановка задачи\n",
    "  > - Сформулировать, что мы хотим узнать о выборках с точки зрения бизнес задачи (равны ли средние доходы в группах)\n",
    "  > - перевод бизнес-вопроса на язык статистики: средний доход в группах - проверка равенства средних значений\n",
    "- формулировка гипотез\n",
    "  > - формулировка нулевой гипотезы - с т.зр. равенства стат прараметров оцениваемых выборок  \n",
    "  >   (Н0: Средние траты клиентов по группе А равны средним тратам клинентов по группе В)\n",
    "  > - формулировка альтернативной гипотезы - с точки зрения неравенства параметров  \n",
    "  >   (Н1: Средние траты клиентов по группе А не равны средним тратам клинентов по группе В)\n",
    "- выбор критерия alpha (почему 0.05 или 0.01)\n",
    "  > - цена ошибки первого рода (при большой цене ошибки - в мед исследованиях, потенциальном ущербе ) - значение может быть больше, например 0.1\n",
    "  > - в ежедневных бизнес задачах, обычно - 0.05\n",
    "- анализ распределения\n",
    "  > - визуальная оценка\n",
    "  > - следим за выбросами\n",
    "  > - проверка гипотез о типе распредеделения (например критерий Шапиро-Уилка)\n",
    "  > - если распределение не нормальное и размер выборки достаточный (больше 30-50 элементов)  \n",
    "  >   может быть использован t-test именно для проверки гипотезы о равенстве средних.  \n",
    "  >   Согласно ЦПТ (центральная предельная теорема) средние этих выборок будут распределены нормально. См. статью Зотова\n",
    "- выбор критерия\n",
    "  > - при оценке равенства средних T-test или Welch T-test (если есть сомнения, то лучше Уэлча)\n",
    "  >   - при рвенстве дисперсий используем обычный т тест\n",
    "  >   - если дисперсии в выборках разные, то используем т теста Уэлча\n",
    "- получение результата\n",
    "  > - расчет p-value\n",
    "- интерпретация p-value\n",
    "  > - сравнение p-value и alpha\n",
    "  > - если альфа > p-value - отвергаем нулевую гипотезу\n",
    "  > - если альфа < p-value - не можем отвергнуть нулевую гипотезу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Какая у нас задача\n",
    "\n",
    "- Исследовать взаимосвязь между 2 переменными\n",
    "  > - обе переменные наминативные\n",
    "  >   - Хи-квадрат Пирсона (не чувствителен к гетероскедастичности) (нормальность не обязательна)\n",
    "  > - обе переменные количественные\n",
    "  >   - Коэффициент корреляции Пирсона (параметрика) (чувствителен к выбросам) (только непрерывные переменные)\n",
    "  >   - Коэффициент корреляции Спирмена (чувствителен к выбросам) / Кендалла (менее чувствителен к выбросам) (непараметрика) (непрерывные переменные и порядковые категориальные переменные)\n",
    "  > - одна переменная номинативная (принимает 2 занчения), вторая количественная\n",
    "  >   - значения\n",
    "  >     - Т-критерий Стьюдента (параметрика) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    "  >       - если дисперсии равны (тест левена, барлета) и количество в группах равно (тест на равенство пропорций), то используем обычный т тест (эта формула более точно даст результат для этого случая)\n",
    "  >       - если дисперсии не равны (тест левена, барлета) или количество в группах не равно (тест на равенство пропорций), то используем тест Уэлча (эта формула использует больше неопределенности и лучше подходит для этого случая)\n",
    "  >     - U-критерий Манна-Уитни (непараметрика) (нормальность не обязательна) (не чувствителен к гетероскедастичности)\n",
    "  >       Если тестируемая фича полностью сдвигает выборку на некий коэффициент theta или масштабирует выборку на некий параметр theta (theta > 0),  \n",
    "  >       то критерий Манна-Уитни применим\n",
    "  >   - доли\n",
    "  >     - Z тест для долей (параметрика) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    "  >     - Chi-square тест для долей (непараметрика) (нормальность не обязательна) (не чувствителен к гетероскедастичности)\n",
    "- Исследовать взаимосвязь между несколькими переменными\n",
    "  > - Дисперсионный анализ (параметрика) (дисперсии в группах должны быть примерно равны) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    "  > - Welch's ANOVA (устройчив к разной дисперсии в группах) (требует более больших размеров групп для точных результатов) (желательно нормальность) (чувствителен к выбросам) (не чувствителен к гетероскедастичности)\n",
    "  > - Критерий Краскела-Уоллиса (непараметрика) (нормальность не обязательна) (не чувствителен к гетероскедастичности)\n",
    "  > - Тест Тьюки (если anova или Краскела-Уоллиса нашил различия) (дисперсии в группах должны быть примерно равны) (параметрика) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    "- Проверить на равенство дисперсий в группах перед anova\n",
    "  > - Levene's test (не требует нормальность) (менее чувствительный)\n",
    "  > - Bartlett's test (требует нормальность) (более чувствительный)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сормируем словарь для подписей осей и названий гистограм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column\n",
    "    children = ['Количество детей', 'количества детей']\n",
    "    , age = ['Возраст', 'возраста']\n",
    "    , total_income = ['Ежемесячный доход', 'ежемесячного дохода']    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры для разных критериев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 категориальные переменные и мы хотим сравнить количество в каждой группе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза 1: Нет зависимость между наличием детей и возвратом кредита в срок**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> H0: Наличие детей не влияет на возврат кредита в срок.  \n",
    "> H1: Наличие детей влияет на возврат кредита в срок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как у нас обе переменных категориальные, то воспользуемся критерием хи-квадрат Пирсона.  \n",
    "Уровень значимости alpha выберем 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что у нас достаточно значнеий в каждой группе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметрических тестов в каждой группе должно быть больше 30 элементов, а для не параметрических тестов больше 10 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_cat\n",
       "старше 60    855\n",
       "до 30        751\n",
       "40-50        587\n",
       "50-60        532\n",
       "30-40        489\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_by_userid_month['age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хи-квадрат Пирсона\n",
      "alpha =  0.05\n",
      "p-value =  1.724356890544321e-05\n",
      "Отклоняем нулевую гипотезу, поскольку p-value меньше уровня значимости\n"
     ]
    }
   ],
   "source": [
    "pagri_data_tools.chi2_pearson(df.has_child, df.debt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    "\n",
    "На уровне значимости 0.05 нулевая гипотеза о том, что наличие детей не влияет на возврат кредита в срок, была отклонена. Это свидетельствует о том, что существует статистически значимое влияние наличия детей на возврат кредита в срок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Одна категориальная переменная и мы хотим проверить отличается ли количество в одной категориальной переменной, то используем chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Он проверяет, насколько наблюдаемое распределение категориальной переменной отличается от ожидаемого равномерного распределения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза 1: Нет зависимости между количеством публикаций и днем недели.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: День недели не влияет на количество объявлений  \n",
    "H1: День недели влияет на количество объявлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publication_weekday\n",
       "Понедельник    3591\n",
       "Вторник        4157\n",
       "Среда          3940\n",
       "Четверг        4270\n",
       "Пятница        3970\n",
       "Суббота        1918\n",
       "Воскресенье    1681\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_counts = df['publication_weekday'].value_counts().sort_index()\n",
    "daily_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что у нас достаточно значнеий в каждой группе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметрических тестов в каждой группе должно быть больше 30 элементов, а для не параметрических тестов больше 10 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_cat\n",
       "старше 60    855\n",
       "до 30        751\n",
       "40-50        587\n",
       "50-60        532\n",
       "30-40        489\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_by_userid_month['age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.chisquare(daily_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    "\n",
    "- На уровне значимости 0.05 нулевая гипотеза о том, что день недели не влияет на количество объявлений, была отклонена. Это указывает на то, что существует статистически значимое влияние дня недели на количество объявлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категориальная с 2 значениями и числовая переменная  (тест манна уитни)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза 2: У мужчин средний доход выше**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: У мужчин средний доход не выше, чем у женщин   \n",
    "H1: У мужчин средний доход выше, чем у женщин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.histogram(df.total_income, titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем вывод о распределении.  \n",
    "Выбираем критерий для проверки гипотезы.  \n",
    "Определяем уровнь значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если распределение не нормальное или много выбросов или просто нет уверености, что параметрика будет хрошо работать, то используем  \n",
    "тест манна уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас значительные выбросы в доходе нужно использовать непараметрический тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем критерий Манна-Уитни  \n",
    "Альтернатива будет - больше  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что у нас достаточно значнеий в каждой группе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметрических тестов в каждой группе должно быть больше 30 элементов, а для не параметрических тестов больше 10 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_cat\n",
       "старше 60    855\n",
       "до 30        751\n",
       "40-50        587\n",
       "50-60        532\n",
       "30-40        489\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_by_userid_month['age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = df[df.gender=='M']['total_income']\n",
    "female = df[df.gender=='F']['total_income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если используем альтернативу, то отсчет идет от первого аргумента функции.  \n",
    "То есть он должен быть больше или меньше, исходя из постановки гипотезы. И исходя из этого выбераем параметр alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.mannwhitneyu(male, female, alternative='l')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    "\n",
    "- На уровне значимости 0.05 нулевая гипотеза о том, что у мужчин средний доход не выше, чем у женщин, была отклонена. Это указывает на то, что доход мужчин статистически значимо выше, чем у женщин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категориальная с 2 значениями и числовая переменная  (т тест)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если используем ттест, то сначала проводим тест на проверку дисперсии\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение близко к нормальному, поэтому будем использовать тест ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим гипотезу, что дисперсии в группах не отличаются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: Дисперсия оценок критиков в разных категориях продаж не отличается.  \n",
    "H1: Дисперсия оценок критиков в разных категориях продаж отличается.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Используем тест Левена\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = df[df.debt=='есть']['age']\n",
    "no = df[df.debt=='нет']['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.levene([yes, no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.levene_df(df[['sales_cat', 'critic_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как дисперсия в группах разная, будем использовать тест Уэлча.  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если используем альтернативу, то отсчет идет от первого аргумента функции.  \n",
    "То есть он должен быть больше или меньше, исходя из постановки гипотезы. И исходя из этого выбераем параметр alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.ttest_ind(yes, no, equal_var=False, alternative='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим доверительный интервал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.confint_t_2samples(yes, no, equal_var=False, alternative='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категориальная переменная, у которой больше 2 значений и числовая (ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза 4: Средний доход по семейному статусу не отличается**  \n",
    "\n",
    "H0: Средний ежемесячный доход не различается между группами по семейному статусу  \n",
    "H1: Средний ежемесячный доход различается между группами по семейному статусу  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посмотрим на распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.histogram(df.total_income, titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем вывод о распределении.  \n",
    "Выбираем критерий для проверки гипотезы.  \n",
    "Определяем уровнь значимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположения ANOVA:\n",
    "- Данные должны быть нормально распределены.\n",
    "- Дисперсии в группах должны быть равны (гомоскедастичность).\n",
    "- Наблюдения должны быть независимыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если хоть одно из этого не выполняется, то лучше использовать kruskal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если распределение не нормальное или много выбросов или просто нет уверености, что параметрика будет хрошо работать, то используем  \n",
    "тест манна уитни"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если эти предположения выполняются, то используем тест ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если используем anova, то сначала проводим тест на проверку дисперсии\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA уже учитывает множественное тестирование в своей структуре.  \n",
    "Поэтому поправка Бонферрони не нужна.   \n",
    "Но если после anova мы хотим сравнить отдельные пары, то будет множественное сравнение, и поправка Бонферрони нужна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если используем anova, то сначала проводим тест на проверку дисперсии\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Проверим гипотезу, что дисперсии в группах не отличаются\n",
    "\n",
    "H0: У должников и не должников дисперсия не отличается  \n",
    "H1: У должников и не должников дисперсия отличается\n",
    "\n",
    "Используем тест Левена\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gropu_a = df[df.debt=='a']['age']\n",
    "gropu_b = df[df.debt=='b']['age']\n",
    "gropu_c = df[df.debt=='c']['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.levene([gropu_a, gropu_b, gropu_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.levene_df(df[['sales_cat', 'critic_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как дисперсия в группах разная, будем использовать тест Уэлча.  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что у нас достаточно значнеий в каждой группе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметрических тестов в каждой группе должно быть больше 30 элементов, а для не параметрических тестов больше 10 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_cat\n",
       "старше 60    855\n",
       "до 30        751\n",
       "40-50        587\n",
       "50-60        532\n",
       "30-40        489\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_by_userid_month['age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если дисперсии не отличаютс, то проводим обычный ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.anova_oneway_df(df[['family_status', 'total_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если гипотеза о равенстве дисперсий была отклонена, то используем ANOVA Welch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.anova_oneway_welch_df(df[['family_status', 'total_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нулевая гипотеза отклонилась, то можно определить в каких парах есть различия.  \n",
    "Можно использовать множественное сравнение и т тест или мана уитни, но обязательно использовать поправку бонферони.  \n",
    "Или можно использовать тест Тьюки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем тест Тьюки, чтобы определить различия между группами  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тест Тьюки уже учитывает множественное тестирование в своей структуре.  \n",
    "Поэтому поправка Бонферрони не нужна. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.tukey_hsd_df(df[['family_status', 'total_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим в каких парах гипотеза отвергается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что гипотеза отвергается в парах где есть вдова / вдовец\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    "\n",
    "- На уровне значимости 0.05 нулевая гипотеза о том, что средний ежемесячный доход не различается между группами по семейному статусу, была отклонена.  \n",
    "Это указывает на то, что семейный статус оказывает статистически значимое влияние на ежемесячный доход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Категориальная переменная, у которой больше 2 значений и числовая (Kruskal-Wallis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если распределение не нормальное или много выбросов или просто нет уверености, что параметрика будет хрошо работать, то используем  непараметрические методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем критерий Краскела-Уоллиса  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся, что у нас достаточно значнеий в каждой группе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для параметрических тестов в каждой группе должно быть больше 30 элементов, а для не параметрических тестов больше 10 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_cat\n",
       "старше 60    855\n",
       "до 30        751\n",
       "40-50        587\n",
       "50-60        532\n",
       "30-40        489\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_by_userid_month['age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "критерий Краскела-Уоллиса уже учитывает множественное тестирование в своей структуре.  \n",
    "Поэтому поправка Бонферрони не нужна.   \n",
    "Но если после критерия Краскела-Уоллиса мы хотим сравнить отдельные пары, то будет множественное сравнение, и поправка Бонферрони нужна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.kruskal_df(df[['family_status', 'total_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нулевая гипотеза отклонилась, то можно определить в каких парах есть различия.  \n",
    "Можно использовать множественное сравнение и т тест или мана уитни, но обязательно использовать поправку бонферони.  \n",
    "Или можно использовать тест Тьюки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем тест Тьюки, чтобы определить различия между группами  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тест Тьюки уже учитывает множественное тестирование в своей структуре.  \n",
    "Поэтому поправка Бонферрони не нужна. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.tukey_hsd_df(df[['family_status', 'total_income']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим в каких парах гипотеза отвергается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что гипотеза отвергается в парах где есть вдова / вдовец\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    "\n",
    "- На уровне значимости 0.05 нулевая гипотеза о том, что средний ежемесячный доход не различается между группами по семейному статусу, была отклонена.  \n",
    "Это указывает на то, что семейный статус оказывает статистически значимое влияние на ежемесячный доход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Бутстреп (категориальная переменная имеет 2 значения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы не хотим использовать параметрику или не параметрику или нам нужно проверить гипотезу не по среднему, например, медиана или какой-то перцинтиль,  \n",
    "то используем бутстреп"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если категориальная переменная имеет 2 занчения.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо теста манна уитни, когда нет уверености в т тесте, можно использовать бутстреп"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза 7:  Медианный доход у должников и не должников не отличается**  \n",
    "\n",
    "H0: Медианный доход у должников и не должников не отличается  \n",
    "H1: Медианный доход у должников и не должников отличается\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем бутстреп для проверке гипотезы  \n",
    "Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы сравниваем две группы в бутстрепе, мы можем просто посмотреть, находится ли 0 внутри доверительного интервала, чтобы определить, существует ли статистически значимое различие между группами.   \n",
    "Если 0 лежит вне доверительного интервала, то мы можем сказать, что существует статистически значимое различие между группами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = df[df.debt=='есть']['total_income']\n",
    "no = df[df.debt=='нет']['total_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pagri_data_tools.bootstrap_diff_2sample(yes, no, stat_func=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    "\n",
    "- На уровне значимости 0.05 нулевая гипотеза о том, что медианный доход у должников и не должников не отличается, была отклонена.  \n",
    "Это указывает на то, что существует статистически значимая разница между медианным доходом должников и не должников.  \n",
    "95 % доверительный интервал разницы между медианным доходом должников и не должников равен (-2648.05, 179.34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Бутстреп (категориальная переменная больше 2 значений)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда у нас больше двух групп, способ определения результата по позиции нуля от разности внутри или вне доверительного интервала не работает, поскольку мы имеем несколько доверительных интервалов для каждой пары сравнений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы сравнить средние значения зарплаты между тремя и более группами, мы можем использовать бутстрэп. Алгоритм бутстрэпа будет следующим:\n",
    "\n",
    "- Создаем выборку с заменой из исходных данных.\n",
    "- Вычисляем средние значения зарплаты для каждой группы в выборке.\n",
    "- Вычисляем разности средних между группами (например, разность между Молодым и Взрослым, между Взрослым и Старым и т.д.).\n",
    "- Повторяем шаги 1-3 many times (например, 1000 раз).\n",
    "- Строим гистограмму распределения разностей средних, полученных на шаге 3.\n",
    "- Определяем p-value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поправка Бонферрони заключается в том, что для значимости результата необходимо, чтобы p-value для каждого сравнения было меньше уровня значимости, разделенного на количество сравнений. Например, если уровень значимости равен 0.05, а мы делаем три сравнения, то необходимо, чтобы p-value для каждого сравнения было меньше 0.05/3 = 0.0167.\n",
    "\n",
    "В случае использования бутстрэпа, мы можем применить поправку Бонферрони следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Вычисляем разности средних для каждой пары сравнений.\n",
    "- Вычисляем p-value для каждой пары сравнений, используя гистограмму распределения разностей средних.\n",
    "- Применяем поправку Бонферрони, разделяя уровень значимости на количество сравнений.\n",
    "- Если p-value для какой-либо пары сравнений меньше поправленного уровня значимости, то считаем, что различие между группами статистически значимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем примере, если мы применяем поправку Бонферрони, то необходимо, чтобы p-value для каждого сравнения было меньше 0.05/3 = 0.0167. Если мы получили следующие результаты:\n",
    "\n",
    "- Разность между Молодым и Взрослым: 8000 (p-value: 0.01)\n",
    "- Разность между Взрослым и Старым: 3000 (p-value: 0.04)\n",
    "- Разность между Молодым и Старым: 11000 (p-value: 0.001)\n",
    "- Тогда мы можем заключить, что средняя зарплата у Старых статистически значимо выше, чем у Молодых и Взрослых (поскольку p-value для этого сравнения меньше поправленного уровня значимости). Для остальных сравнений мы не можем сделать выводы о статистической значимости, поскольку p-value больше поправленного уровня значимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Для проверки дисперсии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.levene_df\n",
    "pagri_data_tools.levene\n",
    "pagri_data_tools.bartlett_df\n",
    "pagri_data_tools.bartlett"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Выбираем критерий\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.chi2_pearson\n",
    "pagri_data_tools.ttest_ind_df\n",
    "pagri_data_tools.ttest_ind\n",
    "pagri_data_tools.mannwhitneyu_df\n",
    "pagri_data_tools.mannwhitneyu\n",
    "pagri_data_tools.proportion_ztest_1sample\n",
    "pagri_data_tools.proportions_ztest_2sample\n",
    "pagri_data_tools.proportions_ztest_column_2sample\n",
    "pagri_data_tools.proportions_chi2\n",
    "pagri_data_tools.proportions_chi2_column\n",
    "pagri_data_tools.anova_oneway_df\n",
    "pagri_data_tools.anova_oneway\n",
    "pagri_data_tools.tukey_hsd_df\n",
    "pagri_data_tools.anova_oneway_welch_df\n",
    "pagri_data_tools.kruskal_df\n",
    "pagri_data_tools.kruskal\n",
    "pagri_data_tools.bootstrap_diff_2sample # важно, сохраняем fig и в следующей ячейке делаем fig.shwo(), иначе на google colab работает некорректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если отклоняем гипотезу, то строим доверитлеьный интервал\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.confint_t_2samples\n",
    "pagri_data_tools.confint_t_2samples_df\n",
    "pagri_data_tools.confint_proportion_ztest_2sample\n",
    "pagri_data_tools.confint_proportion_ztest_column_2sample\n",
    "pagri_data_tools.confint_proportion_2sample_statsmodels\n",
    "pagri_data_tools.confint_proportion_coluns_2sample_statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сделать опцию в бутстреп функции, чтобы строился только доверительный интервал\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Также сделать функцию для доверилеьных интервалов для мана уитни через  \n",
    "> the Hodges-Lehmann estimation, which provides a point estimate and a confidence interval for the difference in medians.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Perform the Mann-Whitney U test and calculate the confidence interval\n",
    "mw_test = pg.mwu(x, y, tail='two-sided', confidence=0.95)\n",
    "\n",
    "# Print the results\n",
    "print(mw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "\n",
    "# Calculate the Hodges-Lehmann estimation\n",
    "hl_est = np.median(np.array([x_i - y_j for x_i in x for y_j in y]))\n",
    "\n",
    "# Calculate the confidence interval\n",
    "ci = stats.t.interval(0.95, len(x) + len(y) - 2, loc=hl_est, scale=stats.sem(np.array([x_i - y_j for x_i in x for y_j in y])))\n",
    "\n",
    "# Print the results\n",
    "print('Hodges-Lehmann estimation:', hl_est)\n",
    "print('Confidence interval:', ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Подход следуюищй - мы до раздела проверка гипотез, когда изучаем данные (разделы пропусков, выбросов, дубликатов, зависиместей между перменными и графики),  \n",
    "> то мы делаем выводы и формируем наблюдеия.  \n",
    "> Вот эти наблюдения и выводы нужно проверить в проверке гипотез.  \n",
    "> И потом в основном выводе уже писать не просто, что у нас мужчин больше чем женьшин, а писать, что на уровен значисомти таком то у нас мужчина больше чем  \n",
    "> женщин с таким то доверительным интервалом.  \n",
    "> Таким образом выводы по вомзожности должны проходить через этап проверки гипотез, тогда эти выводы становятся более существенными.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Гипотезы появляются, когда мы задаем вопросы данным. Мы изучили данные, преобработали и теперь начинаем задавать вопросы.\n",
    "- Выдвигаем гипотезу (заметили что-то необычное и хотим проверить), далее формулируем ее и далее проверяем.\n",
    "- Не забываем формулировать гипотезы словами. Пишем что является гипотезой H0, а что гипотезой H1\n",
    "- Формулируем все гипотезы, которые хотим проверить. Если будет 100 гипотез, то все 100 нужно сформулировать и потом проверить и сделать вывод.\n",
    "- Гипотезы могут быть и простыми вопросами без гипотез H0 и H1, такие гипотезы мы проверяем графиками или анализируя таблицу.\n",
    "- Восновном, когда мы собиаремся применить стат аппарат для проверки гипотезы, то мы должны записать ее через H0 и H1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Отличная статья про доверительные интервалы для разных статистик  \n",
    "> https://habr.com/ru/articles/807051/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bootstrapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> В бутстрепе, если мы хотим сравнить две выборки, то нельзя смотреть  \n",
    "> где находится исходная разница средних в бутстрапированной выборке  \n",
    "> Так как мы берем бутстреп из наших выборок и впролне реально.что наша разность  \n",
    "> будет близка к с реднему бутстропированной выборки  \n",
    "> Поэтому p value нужно определять по месту нуля в бутстропированной выборке\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Посмотрим p value для 0 (если различий нет, то разница должна быть 0)\n",
    "> Для этого посчитаем cdf для + и - среднего, чтобы получить 2 значения cdf\n",
    "> а теперь возьмем минимум и умножим на 2, так как альт гипотеза у нас.что\n",
    "> просто не равно 0, значит и справа и слева\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimating the power of a non-parametric test using bootstrapping involves simulating the testing process multiple times to estimate the probability of rejecting the null hypothesis. Here's a general outline of the steps:\n",
    "\n",
    "**Specify the null and alternative hypotheses **: Define the null and alternative hypotheses for your test. For example, the null hypothesis might be that the two groups have the same distribution, and the alternative hypothesis might be that the two groups have different distributions.\n",
    "\n",
    "Generate simulated data: Generate simulated data that reflects the null hypothesis. For example, you could generate two groups of random data from the same distribution.\n",
    "\n",
    "Perform the Mann-Whitney U test: Perform the Mann-Whitney U test on the simulated data to obtain a p-value.\n",
    "\n",
    "Repeat steps 2-3 many times: Repeat steps 2-3 many times (e.g., 1000 times) to generate a distribution of p-values under the null hypothesis.\n",
    "\n",
    "Estimate the power: Estimate the power of the test by calculating the proportion of times the p-value is below a certain significance level (e.g., 0.05) when the alternative hypothesis is true. To do this, you'll need to generate simulated data that reflects the alternative hypothesis and repeat steps 2-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы собрать все наблюдения используем это  \n",
    "нужно поставить `_pagristart_` где начало и `_pagriend_` где конец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем удалить метки `_pagristart_` и `_pagriend_` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.collect_observations(notebook_path, '/home/pagri/git_repos/pagri-projects/quarto/projects/prospective_tariff_for_telecom/temp_for_report.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На уровне значимости 0.05 гипотеза, что есть зависимость между количеством публикаций и днем недели подтвердилась.  \n",
    "- На уровне значимости 0.05 гипотеза, что удаленность от центра влияет на количество публикаций, подтвердилась.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "проверить, что результат проверки гипотез учтен в выводах.  \n",
    "То есть если у нас был промежуточный вывод, но проверка гипотез опровергла этот вывод, то нужно изменить вывод на противоположный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим собираем все промежуточные выводы, вставляем сюда и выбираем важные. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "из промежуточных выводов в изучении данных собрать подобные выводы:  \n",
    "- Рынок жилья представлен объектами общей площадью от 12 до 900 кв.м. В основном это жилье от 30 до 100 кв.м. с пиком в сегменте 30-75 кв.м. В жилой площади квартиры преобладает диапазон 15-50 кв.м. Размер площади кухни-от 5 до 15 кв.м., с пиком 9 кв.м. Это стандартные небольшие квартиры эконом-класса. Подавляющее большинство квартир- 1-3 комнатные, с высотой потолка 2,6-2,7 м., но встречаются редкие варианты до 19 комнат и высотой потолка до 20 кв.м. (либо ошибка, либо свободная планировка с возможностью многоуровневости).\n",
    "- Цены на квартиры в основном находятся в диапазоне 2.5-15 млн.руб. с пиком в области 3-5 млн.руб.(небольшие квартиры эконом-класса), но есть и уникальные объекты стоимостью до 763 млн.руб. Стоимость квадратного метра недвижимости варьируется от 50-130 тыс.руб. с пиком в 90-100 тыс.руб. Наряду с типовыми предложениями на продажу выставлено жилье премиум-класса со стоимостью 1 кв.м. до 1.9 млн.руб.\n",
    "- Общее время продажи жилой недвижимости-до 1618 дней. Половина квартир продается за период до 94 дней, а среднее значение по всему массиву данных -185 дней. При этом можно увидеть, что пик продаж приходится на 45-60 день с момента публикации. Исходя из расчета выбросов можно сказать, что продажи прошли аномально быстро, если сделки были оформлены в период до 16 дней и слишком долго, если до оформления сделки свыше 1134 дней.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это важно, так как дает представление о данных в сжатой и удобной форме.  \n",
    "А далее уже идут выводы о зависимостях.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем ставить 2 пробела после Выводы и другие для quarto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После каждой строки поставить либо перенос, либо 2 пробела для quarto  \n",
    "так как когда следующая строка начинается с дефиса и jupyter это понимает и делает новую строку,   \n",
    "то quarto не сделает новую строку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Долги есть у людей с разным доходом.  \n",
    "- У должников в среднем больше детей.  \n",
    "- У должников среднее количество детей больше у женщин, а у не должников срднее количество детей больше у мужчин  \n",
    "- У должников средний возраст немного ниже для всех категорий семейного положения.  \n",
    "- Медианный доход у должников и не должников практически не отличается  \n",
    "- Должники имеют ниже средний возраст как мужчины так и женщины. Ситуация сохраняется во всех группах дохода.  \n",
    "- Цель получения кредита практически не зависит от среднего ежемесяченого дохода.  \n",
    "- 92 % клиентов не имеют долга.  \n",
    "- Люди от 30 до 50 лет имеют самый высокий средний доход.  \n",
    "- Больше всего кредит берут на цели, связанные с недвижимостью, кроме людей в гражданском браке  \n",
    "- Люди в гражданском браке чаще берут кредит на свадьбу  \n",
    "- Женщины чаще возвращают кредит.  \n",
    "- Анализ значимости признаков для модели случайного леса показал, что доход является самым значимым признаком для предсказания задолженности.  \n",
    "- 58 % клиентов либо женаты, либо замужем. 19 % в гражданском браке. Можно сделать вывод что большинство в браке.  \n",
    "- Большинство клиентов женщины (66 процентов).  \n",
    "- Только 5 процентов клиентов моложе 25 лет. Основная часть клиентов старше 30 лет.  \n",
    "- Чем меньше количество детей, тем больше значений с высоким доходом.  \n",
    "- Болшая часть женатых имеет доход 100-200 тыс  \n",
    "- На всех уровнях образоания, кроме ученой степени, доход у мужчин выше.  \n",
    "- У мужчин, которые в браке или были в браке, количество детей больше, чем у женщин в той же категории.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Аномалии и особенности в данных:**  \n",
    "\n",
    "- В датафрейме есть строки дубликаты. 54 строки. Меньше 1 % от всего датафрейма.  \n",
    "- В столбце с количеством детей есть отрицательные значения. 47 штук. Меньше 1 процента от всего датафрейма. Также есть клиенты с 20 детьми.  \n",
    "- Колонока общий трудовой стаж содержит 74 % отрицаетльных значений. А также максимальное количество дней стажа больше 400 тысяч дней, это больше 1000 лет.  \n",
    "- В колонке возраста 101 нулевое значени.  \n",
    "- Колонка дохода имеет слишком много знаков после запятой.  \n",
    "- В колонке с образованием присутствуют одни и те же знчения с разными регистрами. При этом в колонке с id образования все впрорядке.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "в результаты предобработки добавляем также выводы из раздела про создание новых переменных и обогащение таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты предобработки данных:**  \n",
    "\n",
    "- Удалили колонки с id образования и семейного статуса, так как нам для графиков лучше подойдут названия, а не id.\n",
    "- Колонка со стажем имеет совершенно некорректные данные. Чтобы не внести искажение в анализ, удалим эту колонку.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты проверки гипотез:**  \n",
    "\n",
    "- Гипотеза 1: Средняя выручка с пользователя не зависит от возрастной группы.  \n",
    "**Результат:** На уровне значимости 0.05 гипотеза была отклонена.  \n",
    "Это указывает на то, что возрастная группа оказывает статистически значимое влияние на среднюю выручку с пользователя.\n",
    "- Гипотеза 2: Средняя выручка между тарифами Smart и Ultra не отличается.  \n",
    "**Результат:** На уровне значимости 0.05 гипотеза была отклонена.  \n",
    "Это указывает на то, что выручка от тарифа Smart статистически значимо выше, чем от тарифа Ultra.\n",
    "- Гипотеза 3: Средняя выручка с пользователя не зависит от месяца.  \n",
    "**Результат:** На уровне значимости 0.05 гипотеза была отклонена.  \n",
    "Это указывает на то, что месяц оказывает статистически значимое влияние на среднюю выручку с пользователя.\n",
    "- Гипотеза 4: Средняя выручка пользователей из Москвы не отличается от выручки пользователей из других регионов.  \n",
    "**Результат:** На уровне значимости 0.05 нет оснований отвергнуть гипотезу.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Используем ИИ для формулирования рекомендаций. Сначала кидаем ему описание проекта и цель и далее кидаем общие выводы и просим написать рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекомендации:**  \n",
    "\n",
    "- Добавить контроль данных, чтобы не дублировались значения с разными регистрами в колонке с образованием.\n",
    "- Добавить уникальный идентификатор клиента, чтобы избежать дублирования строк.\n",
    "- Добавить проверку на отрицательные значения и на слишком болшьшие значения в количестве детей при загрузке данных.\n",
    "- Выяснить откуда возникают отрицательные значения в трудовом стаже и добавить контроль ввода невалидных данных.\n",
    "- Выяснить причину нулевых значений в колонке возраста и добавить проверку на нулевые значения при загрузке данных.\n",
    "- Выяснить причину большого количества знаков после запятой в колонке дохода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО   \n",
    "ячейки далее лучше удалить до обработки ноутбука, чтобы не было ошибок  \n",
    "Копировать что нужно можно из шаблона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Что нужно сообщить в выводе\n",
    "\n",
    "- информацию о том, что удалось подтвердить гипотезы (тут пишем только те, которые удалось подтвердить)\n",
    "- всю информацию о датасете, которые важны. Дубликаты, которые несут практическую пользу и рекомендации по ним, пропуски также с рекомендациями\n",
    "  > и остальные моменты по данным и рекомендации. Тут важно указывать именно найденные аномалии, которые имеют практическую пользу, которые нужно исправить и прочее.  \n",
    "  > Пишем, что были найдены выбросы, они были связаны возможно с тем то и тем то.\n",
    "- и в конце обязательно call to action\n",
    "  > написать что необходимо сделать с этими результатами\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Советы по оформлению общего выывод\n",
    "\n",
    "- не нужно вставлять таблицы и графики в вывод.\n",
    "  > В выводе пишем словами самое важное и практически полезное, что мы получили, причем в порядке убывания важности.  \n",
    "  > И когда мы пишем, что увидели то-то, то приводим гиперссылку на график или результат ячейки, где это получено.  \n",
    "  > Так будет компактный вывод и при необходимости человек сможет быстро перейти и посмотреть график или таблицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удалось подтвердить гипотезу** о влиянии различных характеристик клиента на факт погашения кредита в срок. Каждый из рассмотренных параметров оказывает влияние на надёжность заёмщика. Рассмотренные факторы по-разному влияют на надёжность заёмщиков. Например, семейное положение оказалось более значимым фактором, чем уровень дохода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-penny",
   "metadata": {},
   "source": [
    "- В ходе анализа исходного набора данных было проведено (были устранены пропуски в двух колонках с числовыми значениями - 'total_income' и 'days_employed').\n",
    "- После **устранения явных и скрытых дупликатов** и удаления оставшихся после обогащения пропусков объем датасета сократился на 0.05%\n",
    "- Были устранены **выбросы** в колонках 'days_employed' и 'children': в первом случае выбросы возникли в результате системной ошибки (данные были внесены в часах, а не в днях); во втором случае ошибка, вероятнее всего была допущена людьми, вносившими данные в систему\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-strand",
   "metadata": {},
   "source": [
    "**Необходимо**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-worker",
   "metadata": {},
   "source": [
    "> 1.  Запросить в отделе по работе с клиентами информацию о возможности брать кредит без подтверждения дохода.\n",
    ">\n",
    "> 2.  Сообщить коллегам, занимающимся выгрузкой о наличие дубликатов, если вопрос не разрешится, запросить индентификационный номер клиента к датасету.\n",
    ">\n",
    "> 3.  Прописать в задаче на поставку данных формат данных (пол только F и M, положительные значения). Приложить информацию о найденных аномалиях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сначала проверяем орфографические ошибки**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.correct_notebook_text(notebook_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Затем создаем номера у глав и оглавление**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы добавить номера глав и ссылки для оглавления и сделать оглавлнеие  \n",
    "> оглавление добавиться в начало ноутбука\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Сначала можно в режиме `draft` сделать пробный варант, проверить и потом уже запустить в режиме `final`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.make_headers_link_and_toc(notebook_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее создаем ссыки на выводы и аномалии**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем нужные выводы и нужный порядок выводов и добавляем их в список выводов и используем эту функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "conclusions = [\n",
    "    'С ноября 2017 по март 2018 тратилось много денег на компаню с id 3.'\n",
    "    , 'Сумма заказа варируется от 0 до 2633.28 у.е.'\n",
    "]\n",
    "pagri_data_tools.add_conclusions(notebook_path, conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы было удобно искать где вставить якорь для ссылки, названия выводов и аномалий должно точно совпадать  \n",
    "> в итоговом списке аномалий и выводов и в тех местах (то есть в наблюдениях под ячейками), куда мы будем помещать ссылки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы сделать ссылки на выводы и аномалии, нужно  \n",
    "> в тех местах, куда хотим переходить по ссылке вставить текст выводов или аномалий (берем прямо из основных выводов)  \n",
    "> выводы должны начинаться с `_conclusion_`  \n",
    "> аномалии должны начинаться с `_anomalies_`  \n",
    "> Примеры:  \n",
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окончательный текст выводов можно будет потом исправить в выводах всего отчета и поместить их в начало,  \n",
    "важно, выводы не менять до момента, пока мы не создадим ссылки на них.  \n",
    "Чтобы автомтика не нарушилась.  \n",
    "Затем можно будет исправить уже сам текст выводов и это не нарушит ссылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==== _anomalies_ В столбце с количеством детей есть отрицательные значения. 47 штук. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Можно в одной ячейке и выводы и аномалии, с обеих ссылок будет переходить сюда, но назад будет возвращаться только в одно место,  \n",
    "> в то, которое было первым в ячейке\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "разобраться почему когда рядом ставишь 2 вывода или аномалии или 1 вывод плюс 1 аномалия (вместе 2), то появляется  \n",
    "2 ссылки на оглавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем так\n",
    "- Из всех выводов в выбираем те, которые хотим поместить в начале отчета\n",
    "- Собриаем их в отдельном файле (чтобы удобно было копировать) Можно использовать clipboard history\n",
    "- Добавляем в начало вывода _conclusiions_  \n",
    "- Далее по одному выводу полностью копируем, вставляем в поиск и удаляем в начале _conclusions_  \n",
    "при этом в буфере обмена с _conclusions_ \n",
    "- Переходим в нужное место через поиск и вставляем. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==== _conclusion_ Только 5 процентов клиентов моложе 25 лет. Основная часть клиентов старше 30 лет.\n",
    "==== _anomalies_ В колонке возраста 101 нулевое значени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "Проийти просмотреть чтобы не было 2 раза близко \"к оглавлению\"  \n",
    "это может быть из-за того что у нас ссылки на выводы рядом с названием главы или раздела  \n",
    "Или просто могут быть 2 выводы рядом.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Содеражние выводов и аномалий появится в начале ноутбука  \n",
    "> также 2 режима `draft` и `final`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Подумать как сделать удобнее создание выводов  \n",
    "> Пока лучше сначала взять выводы из наблюдений и выбрать из них наиболее важные и интересные, не меняя их.  \n",
    "> Далее берем этот список и поиском находим ячейку с этим выводом и перед графиком помещаем  \n",
    "> _conclusion_ и сам вывод\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Чтобы был нужный порядок в списке выводов и аномалий в начале отчета, нужно передвать словарь со списками выводов и аномалий.  \n",
    "> Переменная order принимает словарь, где ключи `conclusions` и `anomalies`, а значения это соответствующие списки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Примеры списков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = dict(\n",
    "            conclusions =[ 'Женщины чаще возвращают кредит, чем мужчины.']\n",
    "            , anomalies = ['В датафрейме есть строки дубликаты. 54 строки. Меньше 1 % от всего датафрейма.  ']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ставим переносы для булитов там, где их нет**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "notebook_path = \"/\".join(\n",
    "        IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\"))\n",
    "pagri_data_tools.check_observes_new_line(notebook_path, mode='final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "не забываме перенести рекомендации в начало после аномалий  \n",
    "Порядок\n",
    "- главные выводы\n",
    "- аномалии в данных\n",
    "- рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если сильно нужно, создаем ссыки на гипотезы**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> В главе гипотез для каждой гипоетзы, куда будем переходить из оглавления, в начале перед гипотезой ставим _hypothesis_ и пробел\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==== _hypotsis_ **Гипотеза 1: Название гипотезы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Выполняем следующую функцию и в начале отчета появится список гипотез с ссылками  \n",
    "> Далее нужно добавить результат гипотез вручную\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagri_data_tools.add_hypotheses_links_and_toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Финальное размещение ноутбука на git hub с ссылкой на google colab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Комитим на гит хаб финальную версию ноутбука.  \n",
    "> Создаем на гит хаб readme файл проекта, в котором в начале идет ссылка на google colab  \n",
    "> Далее ее открываем и переходим на google colab  \n",
    "> Выполняем все ячейки, смотрим все ли правильно отобразилось.  \n",
    "> Далее в меню File выбираем сохранить копию на гит хаб.  \n",
    "> Не меняем имя, тогда все содержимое ноутбука сохраниться на гит хаб.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pagri-projects-W8_aXYna-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
